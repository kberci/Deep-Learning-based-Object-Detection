{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"12_EfficientDet_TransferLearning.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EgGUDIETgHaZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611335803922,"user_tz":-60,"elapsed":1201,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"b6467718-dd17-47b5-f773-e1003158186f"},"source":["!rm -r /content/sample_data\n","import datetime\n","start_time = datetime.datetime.now().strftime(\"%d %b, %H:%M:%S\")\n","print(start_time)\n","\n","dataset = 1  # 1: hardhat, 2: scratch"],"execution_count":null,"outputs":[{"output_type":"stream","text":["rm: cannot remove '/content/sample_data': No such file or directory\n","22 Jan, 17:16:44\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gN0EUEa3e5Un"},"source":["##change chosen model to deploy different models available in the TF2 object detection zoo\n","MODELS_CONFIG = {\n","    'efficientdet-d0': {\n","        'model_name': 'efficientdet_d0_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","    'efficientdet-d1': {\n","        'model_name': 'efficientdet_d1_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","    'efficientdet-d2': {\n","        'model_name': 'efficientdet_d2_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","        'efficientdet-d3': {\n","        'model_name': 'efficientdet_d3_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n","        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    }\n","}\n","\n","#in this tutorial we implement the lightweight, smallest state of the art efficientdet model\n","#if you want to scale up tot larger efficientdet models you will likely need more compute!\n","chosen_model = 'efficientdet-d0'\n","\n","num_steps = 50000  #The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing. \n","num_eval_steps = 50  #Perform evaluation after so many steps\n","\n","model_name = MODELS_CONFIG[chosen_model]['model_name']\n","pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n","base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n","batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l7EOtpvlLeS0"},"source":["# Install TensorFlow2 Object Detection Dependencies"]},{"cell_type":"code","metadata":{"id":"ypWGYdPlLRUN"},"source":["import os\n","import pathlib\n","\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6QPmVBSlLTzM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611337255635,"user_tz":-60,"elapsed":10458,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"256c2ac3-d509-4e41-8123-c5e43c00831f"},"source":["# Install the Object Detection API\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Processing /content/models/research\n","Requirement already satisfied: avro-python3 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.10.1)\n","Requirement already satisfied: apache-beam in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.27.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.5)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.2)\n","Requirement already satisfied: lvis in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.5)\n","Requirement already satisfied: tf-models-official in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.4.0)\n","Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n","Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n","Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n","Requirement already satisfied: future<1.0.0,>=0.18.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.18.2)\n","Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Requirement already satisfied: mock<3.0.0,>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.0.0)\n","Requirement already satisfied: fastavro<2,>=0.21.4 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n","Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n","Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n","Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.5.8)\n","Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.11.2)\n","Requirement already satisfied: pyarrow<3.0.0,>=0.15.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.0.0)\n","Requirement already satisfied: numpy<2,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (51.3.3)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.10)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8)\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.3)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.5.1.48)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (7.0.0)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.2.2)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.1.95)\n","Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.7.12)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.1)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.4.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n","Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock<3.0.0,>=1.0.1->apache-beam->object-detection==0.1) (5.5.1)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.6)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.41.1)\n","Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n","Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n","Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.17.2)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.1.5)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (20.3.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.26.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.0)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.10.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12.1)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.3.3)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.36.2)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.16.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.0)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.52.0)\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.7.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.4.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.1.0)\n","Building wheels for collected packages: object-detection\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1613294 sha256=2ddf17d6cc9115cee8f03becf34ad0e1459eda11243f6c5b7ff53ab712fb006e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-awb5q2a3/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n","Successfully built object-detection\n","Installing collected packages: object-detection\n","  Found existing installation: object-detection 0.1\n","    Uninstalling object-detection-0.1:\n","      Successfully uninstalled object-detection-0.1\n","Successfully installed object-detection-0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wHfsJ5nWLWh9"},"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import os\n","import random\n","import io\n","import imageio\n","import glob\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","from IPython.display import display, Javascript\n","from IPython.display import Image as IPyImage\n","\n","import tensorflow as tf\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.utils import colab_utils\n","from object_detection.builders import model_builder\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wh_HPMOqWH9z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611337291237,"user_tz":-60,"elapsed":33820,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"7083a930-d327-41b2-ff65-c93b814fb7d0"},"source":["#run model builder test\n","!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-01-22 17:40:58.840631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","Running tests under Python 3.6.9: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model\n","2021-01-22 17:41:01.746018: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-01-22 17:41:01.747463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2021-01-22 17:41:01.753932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:41:01.754542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s\n","2021-01-22 17:41:01.754578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 17:41:01.761203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n","2021-01-22 17:41:01.761277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n","2021-01-22 17:41:01.763182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-01-22 17:41:01.763573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-01-22 17:41:01.769038: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-01-22 17:41:01.773621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n","2021-01-22 17:41:01.777996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n","2021-01-22 17:41:01.778139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:41:01.778811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:41:01.779362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-01-22 17:41:01.779698: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-01-22 17:41:01.779855: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-01-22 17:41:01.779991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:41:01.780568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s\n","2021-01-22 17:41:01.780600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 17:41:01.780648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n","2021-01-22 17:41:01.780674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n","2021-01-22 17:41:01.780698: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-01-22 17:41:01.780725: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-01-22 17:41:01.780752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-01-22 17:41:01.780776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n","2021-01-22 17:41:01.780799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n","2021-01-22 17:41:01.780876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:41:01.781490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:41:01.782025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-01-22 17:41:01.782070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 17:41:02.607482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-01-22 17:41:02.607546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2021-01-22 17:41:02.607570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2021-01-22 17:41:02.607795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:41:02.608482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:41:02.609083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:41:02.609717: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-01-22 17:41:02.609777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12387 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 4.09s\n","I0122 17:41:05.601188 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 4.09s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0122 17:41:05.602694 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.05s\n","I0122 17:41:05.657827 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.05s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n","I0122 17:41:05.684612 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n","I0122 17:41:05.712720 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.19s\n","I0122 17:41:05.906715 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.19s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n","I0122 17:41:06.081062 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.19s\n","I0122 17:41:06.272452 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.19s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.17s\n","I0122 17:41:06.438851 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.17s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.17s\n","I0122 17:41:06.611502 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.17s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n","I0122 17:41:06.665342 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0122 17:41:07.146775 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0122 17:41:07.146971 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n","I0122 17:41:07.147049 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n","I0122 17:41:07.153556 140437838358400 efficientnet_model.py:147] round_filter input=32 output=32\n","I0122 17:41:07.173299 140437838358400 efficientnet_model.py:147] round_filter input=32 output=32\n","I0122 17:41:07.173473 140437838358400 efficientnet_model.py:147] round_filter input=16 output=16\n","I0122 17:41:07.237651 140437838358400 efficientnet_model.py:147] round_filter input=16 output=16\n","I0122 17:41:07.237845 140437838358400 efficientnet_model.py:147] round_filter input=24 output=24\n","I0122 17:41:07.406645 140437838358400 efficientnet_model.py:147] round_filter input=24 output=24\n","I0122 17:41:07.406838 140437838358400 efficientnet_model.py:147] round_filter input=40 output=40\n","I0122 17:41:07.568734 140437838358400 efficientnet_model.py:147] round_filter input=40 output=40\n","I0122 17:41:07.568924 140437838358400 efficientnet_model.py:147] round_filter input=80 output=80\n","I0122 17:41:07.831259 140437838358400 efficientnet_model.py:147] round_filter input=80 output=80\n","I0122 17:41:07.831468 140437838358400 efficientnet_model.py:147] round_filter input=112 output=112\n","I0122 17:41:08.076027 140437838358400 efficientnet_model.py:147] round_filter input=112 output=112\n","I0122 17:41:08.076265 140437838358400 efficientnet_model.py:147] round_filter input=192 output=192\n","I0122 17:41:08.416369 140437838358400 efficientnet_model.py:147] round_filter input=192 output=192\n","I0122 17:41:08.416581 140437838358400 efficientnet_model.py:147] round_filter input=320 output=320\n","I0122 17:41:08.493782 140437838358400 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0122 17:41:08.524796 140437838358400 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0122 17:41:08.608546 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0122 17:41:08.608724 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 88\n","I0122 17:41:08.608808 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 4\n","I0122 17:41:08.613544 140437838358400 efficientnet_model.py:147] round_filter input=32 output=32\n","I0122 17:41:08.630010 140437838358400 efficientnet_model.py:147] round_filter input=32 output=32\n","I0122 17:41:08.630143 140437838358400 efficientnet_model.py:147] round_filter input=16 output=16\n","I0122 17:41:08.762738 140437838358400 efficientnet_model.py:147] round_filter input=16 output=16\n","I0122 17:41:08.762920 140437838358400 efficientnet_model.py:147] round_filter input=24 output=24\n","I0122 17:41:09.011399 140437838358400 efficientnet_model.py:147] round_filter input=24 output=24\n","I0122 17:41:09.011606 140437838358400 efficientnet_model.py:147] round_filter input=40 output=40\n","I0122 17:41:09.256512 140437838358400 efficientnet_model.py:147] round_filter input=40 output=40\n","I0122 17:41:09.256709 140437838358400 efficientnet_model.py:147] round_filter input=80 output=80\n","I0122 17:41:09.601914 140437838358400 efficientnet_model.py:147] round_filter input=80 output=80\n","I0122 17:41:09.602124 140437838358400 efficientnet_model.py:147] round_filter input=112 output=112\n","I0122 17:41:09.933654 140437838358400 efficientnet_model.py:147] round_filter input=112 output=112\n","I0122 17:41:09.933845 140437838358400 efficientnet_model.py:147] round_filter input=192 output=192\n","I0122 17:41:10.474931 140437838358400 efficientnet_model.py:147] round_filter input=192 output=192\n","I0122 17:41:10.475143 140437838358400 efficientnet_model.py:147] round_filter input=320 output=320\n","I0122 17:41:10.638251 140437838358400 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0122 17:41:10.667858 140437838358400 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0122 17:41:10.761838 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0122 17:41:10.762029 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 112\n","I0122 17:41:10.762113 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 5\n","I0122 17:41:10.766900 140437838358400 efficientnet_model.py:147] round_filter input=32 output=32\n","I0122 17:41:10.783830 140437838358400 efficientnet_model.py:147] round_filter input=32 output=32\n","I0122 17:41:10.783967 140437838358400 efficientnet_model.py:147] round_filter input=16 output=16\n","I0122 17:41:10.943554 140437838358400 efficientnet_model.py:147] round_filter input=16 output=16\n","I0122 17:41:10.943745 140437838358400 efficientnet_model.py:147] round_filter input=24 output=24\n","I0122 17:41:11.191438 140437838358400 efficientnet_model.py:147] round_filter input=24 output=24\n","I0122 17:41:11.191644 140437838358400 efficientnet_model.py:147] round_filter input=40 output=48\n","I0122 17:41:11.448957 140437838358400 efficientnet_model.py:147] round_filter input=40 output=48\n","I0122 17:41:11.449160 140437838358400 efficientnet_model.py:147] round_filter input=80 output=88\n","I0122 17:41:11.792136 140437838358400 efficientnet_model.py:147] round_filter input=80 output=88\n","I0122 17:41:11.792334 140437838358400 efficientnet_model.py:147] round_filter input=112 output=120\n","I0122 17:41:12.124814 140437838358400 efficientnet_model.py:147] round_filter input=112 output=120\n","I0122 17:41:12.125013 140437838358400 efficientnet_model.py:147] round_filter input=192 output=208\n","I0122 17:41:12.545282 140437838358400 efficientnet_model.py:147] round_filter input=192 output=208\n","I0122 17:41:12.545496 140437838358400 efficientnet_model.py:147] round_filter input=320 output=352\n","I0122 17:41:12.706935 140437838358400 efficientnet_model.py:147] round_filter input=1280 output=1408\n","I0122 17:41:12.736334 140437838358400 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0122 17:41:12.828906 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0122 17:41:12.829099 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 160\n","I0122 17:41:12.829221 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 6\n","I0122 17:41:12.837880 140437838358400 efficientnet_model.py:147] round_filter input=32 output=40\n","I0122 17:41:12.859241 140437838358400 efficientnet_model.py:147] round_filter input=32 output=40\n","I0122 17:41:12.859385 140437838358400 efficientnet_model.py:147] round_filter input=16 output=24\n","I0122 17:41:12.994573 140437838358400 efficientnet_model.py:147] round_filter input=16 output=24\n","I0122 17:41:12.994791 140437838358400 efficientnet_model.py:147] round_filter input=24 output=32\n","I0122 17:41:13.247669 140437838358400 efficientnet_model.py:147] round_filter input=24 output=32\n","I0122 17:41:13.247869 140437838358400 efficientnet_model.py:147] round_filter input=40 output=48\n","I0122 17:41:13.495531 140437838358400 efficientnet_model.py:147] round_filter input=40 output=48\n","I0122 17:41:13.495726 140437838358400 efficientnet_model.py:147] round_filter input=80 output=96\n","I0122 17:41:13.915062 140437838358400 efficientnet_model.py:147] round_filter input=80 output=96\n","I0122 17:41:13.915257 140437838358400 efficientnet_model.py:147] round_filter input=112 output=136\n","I0122 17:41:14.327486 140437838358400 efficientnet_model.py:147] round_filter input=112 output=136\n","I0122 17:41:14.327678 140437838358400 efficientnet_model.py:147] round_filter input=192 output=232\n","I0122 17:41:15.023892 140437838358400 efficientnet_model.py:147] round_filter input=192 output=232\n","I0122 17:41:15.024093 140437838358400 efficientnet_model.py:147] round_filter input=320 output=384\n","I0122 17:41:15.187101 140437838358400 efficientnet_model.py:147] round_filter input=1280 output=1536\n","I0122 17:41:15.216704 140437838358400 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0122 17:41:15.314592 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0122 17:41:15.314785 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 224\n","I0122 17:41:15.314869 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n","I0122 17:41:15.319662 140437838358400 efficientnet_model.py:147] round_filter input=32 output=48\n","I0122 17:41:15.337027 140437838358400 efficientnet_model.py:147] round_filter input=32 output=48\n","I0122 17:41:15.337161 140437838358400 efficientnet_model.py:147] round_filter input=16 output=24\n","I0122 17:41:15.470386 140437838358400 efficientnet_model.py:147] round_filter input=16 output=24\n","I0122 17:41:15.470605 140437838358400 efficientnet_model.py:147] round_filter input=24 output=32\n","I0122 17:41:15.800457 140437838358400 efficientnet_model.py:147] round_filter input=24 output=32\n","I0122 17:41:15.800694 140437838358400 efficientnet_model.py:147] round_filter input=40 output=56\n","I0122 17:41:16.140933 140437838358400 efficientnet_model.py:147] round_filter input=40 output=56\n","I0122 17:41:16.141126 140437838358400 efficientnet_model.py:147] round_filter input=80 output=112\n","I0122 17:41:16.637775 140437838358400 efficientnet_model.py:147] round_filter input=80 output=112\n","I0122 17:41:16.637970 140437838358400 efficientnet_model.py:147] round_filter input=112 output=160\n","I0122 17:41:17.141674 140437838358400 efficientnet_model.py:147] round_filter input=112 output=160\n","I0122 17:41:17.141887 140437838358400 efficientnet_model.py:147] round_filter input=192 output=272\n","I0122 17:41:17.804740 140437838358400 efficientnet_model.py:147] round_filter input=192 output=272\n","I0122 17:41:17.804939 140437838358400 efficientnet_model.py:147] round_filter input=320 output=448\n","I0122 17:41:17.971699 140437838358400 efficientnet_model.py:147] round_filter input=1280 output=1792\n","I0122 17:41:18.001280 140437838358400 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0122 17:41:18.111360 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0122 17:41:18.111578 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 288\n","I0122 17:41:18.111663 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n","I0122 17:41:18.116527 140437838358400 efficientnet_model.py:147] round_filter input=32 output=48\n","I0122 17:41:18.133490 140437838358400 efficientnet_model.py:147] round_filter input=32 output=48\n","I0122 17:41:18.133623 140437838358400 efficientnet_model.py:147] round_filter input=16 output=24\n","I0122 17:41:18.340197 140437838358400 efficientnet_model.py:147] round_filter input=16 output=24\n","I0122 17:41:18.340404 140437838358400 efficientnet_model.py:147] round_filter input=24 output=40\n","I0122 17:41:18.764874 140437838358400 efficientnet_model.py:147] round_filter input=24 output=40\n","I0122 17:41:18.765079 140437838358400 efficientnet_model.py:147] round_filter input=40 output=64\n","I0122 17:41:19.389810 140437838358400 efficientnet_model.py:147] round_filter input=40 output=64\n","I0122 17:41:19.390023 140437838358400 efficientnet_model.py:147] round_filter input=80 output=128\n","I0122 17:41:19.979945 140437838358400 efficientnet_model.py:147] round_filter input=80 output=128\n","I0122 17:41:19.980143 140437838358400 efficientnet_model.py:147] round_filter input=112 output=176\n","I0122 17:41:20.567154 140437838358400 efficientnet_model.py:147] round_filter input=112 output=176\n","I0122 17:41:20.567356 140437838358400 efficientnet_model.py:147] round_filter input=192 output=304\n","I0122 17:41:21.344138 140437838358400 efficientnet_model.py:147] round_filter input=192 output=304\n","I0122 17:41:21.344349 140437838358400 efficientnet_model.py:147] round_filter input=320 output=512\n","I0122 17:41:21.601197 140437838358400 efficientnet_model.py:147] round_filter input=1280 output=2048\n","I0122 17:41:21.631177 140437838358400 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0122 17:41:21.749206 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0122 17:41:21.749397 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n","I0122 17:41:21.749499 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n","I0122 17:41:21.754305 140437838358400 efficientnet_model.py:147] round_filter input=32 output=56\n","I0122 17:41:21.771749 140437838358400 efficientnet_model.py:147] round_filter input=32 output=56\n","I0122 17:41:21.771887 140437838358400 efficientnet_model.py:147] round_filter input=16 output=32\n","I0122 17:41:21.980022 140437838358400 efficientnet_model.py:147] round_filter input=16 output=32\n","I0122 17:41:21.980222 140437838358400 efficientnet_model.py:147] round_filter input=24 output=40\n","I0122 17:41:22.482487 140437838358400 efficientnet_model.py:147] round_filter input=24 output=40\n","I0122 17:41:22.482685 140437838358400 efficientnet_model.py:147] round_filter input=40 output=72\n","I0122 17:41:22.993489 140437838358400 efficientnet_model.py:147] round_filter input=40 output=72\n","I0122 17:41:22.993690 140437838358400 efficientnet_model.py:147] round_filter input=80 output=144\n","I0122 17:41:23.859566 140437838358400 efficientnet_model.py:147] round_filter input=80 output=144\n","I0122 17:41:23.859765 140437838358400 efficientnet_model.py:147] round_filter input=112 output=200\n","I0122 17:41:24.540046 140437838358400 efficientnet_model.py:147] round_filter input=112 output=200\n","I0122 17:41:24.540241 140437838358400 efficientnet_model.py:147] round_filter input=192 output=344\n","I0122 17:41:25.466340 140437838358400 efficientnet_model.py:147] round_filter input=192 output=344\n","I0122 17:41:25.466556 140437838358400 efficientnet_model.py:147] round_filter input=320 output=576\n","I0122 17:41:25.710735 140437838358400 efficientnet_model.py:147] round_filter input=1280 output=2304\n","I0122 17:41:25.744327 140437838358400 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0122 17:41:25.875450 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0122 17:41:25.875645 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n","I0122 17:41:25.875731 140437838358400 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n","I0122 17:41:25.880522 140437838358400 efficientnet_model.py:147] round_filter input=32 output=64\n","I0122 17:41:25.897440 140437838358400 efficientnet_model.py:147] round_filter input=32 output=64\n","I0122 17:41:25.897570 140437838358400 efficientnet_model.py:147] round_filter input=16 output=32\n","I0122 17:41:26.172536 140437838358400 efficientnet_model.py:147] round_filter input=16 output=32\n","I0122 17:41:26.172732 140437838358400 efficientnet_model.py:147] round_filter input=24 output=48\n","I0122 17:41:26.750964 140437838358400 efficientnet_model.py:147] round_filter input=24 output=48\n","I0122 17:41:26.751166 140437838358400 efficientnet_model.py:147] round_filter input=40 output=80\n","I0122 17:41:27.341096 140437838358400 efficientnet_model.py:147] round_filter input=40 output=80\n","I0122 17:41:27.341293 140437838358400 efficientnet_model.py:147] round_filter input=80 output=160\n","I0122 17:41:28.168453 140437838358400 efficientnet_model.py:147] round_filter input=80 output=160\n","I0122 17:41:28.168649 140437838358400 efficientnet_model.py:147] round_filter input=112 output=224\n","I0122 17:41:29.212923 140437838358400 efficientnet_model.py:147] round_filter input=112 output=224\n","I0122 17:41:29.213129 140437838358400 efficientnet_model.py:147] round_filter input=192 output=384\n","I0122 17:41:30.303140 140437838358400 efficientnet_model.py:147] round_filter input=192 output=384\n","I0122 17:41:30.303338 140437838358400 efficientnet_model.py:147] round_filter input=320 output=640\n","I0122 17:41:30.629463 140437838358400 efficientnet_model.py:147] round_filter input=1280 output=2560\n","I0122 17:41:30.671465 140437838358400 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.15s\n","I0122 17:41:30.818212 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.15s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0122 17:41:30.825309 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0122 17:41:30.827101 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0122 17:41:30.827619 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0122 17:41:30.829185 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0122 17:41:30.830637 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0122 17:41:30.831085 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0122 17:41:30.832154 140437838358400 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 20 tests in 29.331s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VA7Zbo3RLt3W"},"source":["def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: a file path.\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)\n","\n","def plot_detections(image_np,\n","                    boxes,\n","                    classes,\n","                    scores,\n","                    category_index,\n","                    figsize=(12, 16),\n","                    image_name=None):\n","  \"\"\"Wrapper function to visualize detections.\n","\n","  Args:\n","    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n","    boxes: a numpy array of shape [N, 4]\n","    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n","      and match the keys in the label map.\n","    scores: a numpy array of shape [N] or None.  If scores=None, then\n","      this function assumes that the boxes to be plotted are groundtruth\n","      boxes and plot all boxes as black with no classes or scores.\n","    category_index: a dict containing category dictionaries (each holding\n","      category index `id` and category name `name`) keyed by category indices.\n","    figsize: size for the figure.\n","    image_name: a name for the image file.\n","  \"\"\"\n","  image_np_with_annotations = image_np.copy()\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_annotations,\n","      boxes,\n","      classes,\n","      scores,\n","      category_index,\n","      use_normalized_coordinates=True,\n","      min_score_thresh=0.8)\n","  if image_name:\n","    plt.imsave(image_name, image_np_with_annotations)\n","  else:\n","    plt.imshow(image_np_with_annotations)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gO7CnjNHvulO","executionInfo":{"status":"ok","timestamp":1611335829074,"user_tz":-60,"elapsed":5907,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"f02803e8-a14a-4cb4-b543-d9bd9b98bf34"},"source":["from google_drive_downloader import GoogleDriveDownloader as gdd\r\n","\r\n","%cd /content\r\n","\r\n","if dataset == 1:\r\n","  drive_id = '1HQfrA9eHaIrqohTtNpSu8vCSLaZNpZbn'  # Hardhat\r\n","else:\r\n","  drive_id = '1a8CavWcehN_aYGOrSS8VM4iC_VEkyW2P'  # Scratch\r\n","\r\n","gdd.download_file_from_google_drive(file_id=drive_id,\r\n","                                    dest_path='./dataset.zip',\r\n","                                    unzip=True)\r\n","\r\n","!rm dataset.zip\r\n","\r\n","!mv data_tfrecord data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","Downloading 1HQfrA9eHaIrqohTtNpSu8vCSLaZNpZbn into ./dataset.zip... Done.\n","Unzipping...Done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QcHJuaurS_AO"},"source":["#Downloading data from Roboflow\n","#UPDATE THIS LINK - get our data from Roboflow\n","# %cd /content\n","# !curl -L \"https://public.roboflow.com/ds/ub0NLZ3ABo?key=G7EycgLLK6\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YUd2wtfrqedy"},"source":["# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n","test_record_fname = '/content/data/data_test.tfrecord'\n","valid_record_fname = '/content/data/data_valid.tfrecord'\n","train_record_fname = '/content/data/data_train.tfrecord'\n","label_map_pbtxt_fname = '/content/data/label_map.pbtxt'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I2MAcgJ53STW"},"source":["# Configure Custom TensorFlow2 Object Detection Training Configuration\n","\n","\n","\n","\n","> In this section you can specify any model in the [TF2 OD model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) and set up your training configuration.\n","\n"]},{"cell_type":"code","metadata":{"id":"kG4TmJUVrYQ7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611290523121,"user_tz":-60,"elapsed":42109,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"964b565d-c5a7-4c44-8a5b-034dc7f30565"},"source":["#download pretrained weights\n","%mkdir /content/models/research/deploy/\n","%cd /content/models/research/deploy/\n","import tarfile\n","download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n","\n","!wget {download_tar}\n","tar = tarfile.open(pretrained_checkpoint)\n","tar.extractall()\n","tar.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/deploy\n","--2021-01-22 04:42:01--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.119.128, 2a00:1450:4013:c00::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.119.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 30736482 (29M) [application/x-tar]\n","Saving to: ‘efficientdet_d0_coco17_tpu-32.tar.gz’\n","\n","efficientdet_d0_coc 100%[===================>]  29.31M  33.6MB/s    in 0.9s    \n","\n","2021-01-22 04:42:02 (33.6 MB/s) - ‘efficientdet_d0_coco17_tpu-32.tar.gz’ saved [30736482/30736482]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c-nqYZtdtsgG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611290523535,"user_tz":-60,"elapsed":42511,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"bad95754-25ed-4724-b970-7be9314d0b82"},"source":["#download base training configuration file\n","%cd /content/models/research/deploy\n","download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n","!wget {download_config}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/deploy\n","--2021-01-22 04:42:03--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4630 (4.5K) [text/plain]\n","Saving to: ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config’\n","\n","ssd_efficientdet_d0 100%[===================>]   4.52K  --.-KB/s    in 0s      \n","\n","2021-01-22 04:42:03 (60.1 MB/s) - ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config’ saved [4630/4630]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b_ki9jOqxn7V"},"source":["#prepare\n","pipeline_fname = '/content/models/research/deploy/' + base_pipeline_file\n","fine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n","\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5eA5ht3_yukT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611335844449,"user_tz":-60,"elapsed":674,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"545f0156-dfb7-4da2-8d34-be77a8c3855f"},"source":["#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n","\n","import re\n","\n","%cd /content/models/research/deploy\n","print('writing custom configuration file')\n","\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open('pipeline_file.config', 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(valid_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    \n","    #fine-tune checkpoint type\n","    s = re.sub(\n","        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n","        \n","    f.write(s)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/deploy\n","writing custom configuration file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HEsOLOMHzBqF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611335848435,"user_tz":-60,"elapsed":943,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"80c37282-b50b-4323-cf1d-183155b91d9f"},"source":["%cat /content/models/research/deploy/pipeline_file.config"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" # SSD with EfficientNet-b0 + BiFPN feature extractor,\n","# shared box predictor and focal loss (a.k.a EfficientDet-d0).\n","# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070\n","# See Lin et al, https://arxiv.org/abs/1708.02002\n","# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.\n","#\n","# Train on TPU-8\n","\n","model {\n","  ssd {\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    num_classes: 3\n","    add_background_class: false\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    encode_background_as_zeros: true\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 4.0\n","        aspect_ratios: [1.0, 2.0, 0.5]\n","        scales_per_octave: 3\n","      }\n","    }\n","    image_resizer {\n","      keep_aspect_ratio_resizer {\n","        min_dimension: 512\n","        max_dimension: 512\n","        pad_to_max_dimension: true\n","        }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        depth: 64\n","        class_prediction_bias_init: -4.6\n","        conv_hyperparams {\n","          force_use_bias: true\n","          activation: SWISH\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              stddev: 0.01\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            scale: true\n","            decay: 0.99\n","            epsilon: 0.001\n","          }\n","        }\n","        num_layers_before_predictor: 3\n","        kernel_size: 3\n","        use_depthwise: true\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_efficientnet-b0_bifpn_keras'\n","      bifpn {\n","        min_level: 3\n","        max_level: 7\n","        num_iterations: 3\n","        num_filters: 64\n","      }\n","      conv_hyperparams {\n","        force_use_bias: true\n","        activation: SWISH\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          scale: true,\n","          decay: 0.99,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          alpha: 0.25\n","          gamma: 1.5\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    normalize_loc_loss_by_codesize: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  fine_tune_checkpoint: \"/content/models/research/deploy/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint_type: \"detection\"\n","  batch_size: 16\n","  sync_replicas: true\n","  startup_delay_steps: 0\n","  replicas_to_aggregate: 8\n","  use_bfloat16: true\n","  num_steps: 50000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_scale_crop_and_pad_to_square {\n","      output_size: 512\n","      scale_min: 0.1\n","      scale_max: 2.0\n","    }\n","  }\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: 8e-2\n","          total_steps: 300000\n","          warmup_learning_rate: .001\n","          warmup_steps: 2500\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/data/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/data/data_train.tfrecord\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 16;\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/data/data_valid.tfrecord\"\n","  }\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GMlaN3rs3zLe"},"source":["pipeline_file = '/content/models/research/deploy/pipeline_file.config'\n","model_dir = '/content/training/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XxPj_QV43qD5"},"source":["# Train Custom TF2 Object Detector\n","\n","* pipeline_file: defined above in writing custom training configuration\n","* model_dir: the location tensorboard logs and saved model checkpoints will save to\n","* num_train_steps: how long to train for\n","* num_eval_steps: perform eval on validation set after this many steps\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMPFd_C8qoTU","executionInfo":{"status":"ok","timestamp":1611290524067,"user_tz":-60,"elapsed":42970,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"d35da011-86b7-436c-cee8-d35fa63f1bde"},"source":["print(chosen_model)\r\n","print(num_steps)\r\n","print(num_eval_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["efficientdet-d0\n","50000\n","50\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tQTfZChVzzpZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611330565906,"user_tz":-60,"elapsed":24724799,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"b31b3a55-fe46-4fd0-9e81-a942d5513f04"},"source":["!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_file} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --sample_1_of_n_eval_examples=1 \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-01-22 04:42:04.206519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 04:42:07.016445: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-01-22 04:42:07.017533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2021-01-22 04:42:07.043597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 04:42:07.044262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s\n","2021-01-22 04:42:07.044304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 04:42:07.045911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n","2021-01-22 04:42:07.046007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n","2021-01-22 04:42:07.047734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-01-22 04:42:07.048104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-01-22 04:42:07.050171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-01-22 04:42:07.051478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n","2021-01-22 04:42:07.055371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n","2021-01-22 04:42:07.055522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 04:42:07.056170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 04:42:07.056794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-01-22 04:42:07.057153: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-01-22 04:42:07.057308: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-01-22 04:42:07.057443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 04:42:07.058081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s\n","2021-01-22 04:42:07.058110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 04:42:07.058151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n","2021-01-22 04:42:07.058181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n","2021-01-22 04:42:07.058210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-01-22 04:42:07.058236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-01-22 04:42:07.058260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-01-22 04:42:07.058285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n","2021-01-22 04:42:07.058330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n","2021-01-22 04:42:07.058428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 04:42:07.059193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 04:42:07.059814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-01-22 04:42:07.059858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 04:42:07.843516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-01-22 04:42:07.843585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2021-01-22 04:42:07.843608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2021-01-22 04:42:07.843841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 04:42:07.844571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 04:42:07.845210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 04:42:07.845806: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-01-22 04:42:07.845859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14753 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0122 04:42:07.847664 139716735563648 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 50000\n","I0122 04:42:07.853058 139716735563648 config_util.py:552] Maybe overwriting train_steps: 50000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0122 04:42:07.853283 139716735563648 config_util.py:552] Maybe overwriting use_bfloat16: False\n","I0122 04:42:07.875363 139716735563648 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0122 04:42:07.875567 139716735563648 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n","I0122 04:42:07.875648 139716735563648 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n","I0122 04:42:07.885867 139716735563648 efficientnet_model.py:147] round_filter input=32 output=32\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 04:42:07.918107 139716735563648 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 04:42:07.927856 139716735563648 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 04:42:07.931827 139716735563648 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 04:42:07.932807 139716735563648 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 04:42:07.939561 139716735563648 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 04:42:07.943104 139716735563648 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 04:42:07.948658 139716735563648 efficientnet_model.py:147] round_filter input=32 output=32\n","I0122 04:42:07.948776 139716735563648 efficientnet_model.py:147] round_filter input=16 output=16\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 04:42:07.964939 139716735563648 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 04:42:07.965943 139716735563648 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 04:42:07.967471 139716735563648 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 04:42:07.968297 139716735563648 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0122 04:42:08.043369 139716735563648 efficientnet_model.py:147] round_filter input=16 output=16\n","I0122 04:42:08.043561 139716735563648 efficientnet_model.py:147] round_filter input=24 output=24\n","I0122 04:42:08.290158 139716735563648 efficientnet_model.py:147] round_filter input=24 output=24\n","I0122 04:42:08.290349 139716735563648 efficientnet_model.py:147] round_filter input=40 output=40\n","I0122 04:42:08.541025 139716735563648 efficientnet_model.py:147] round_filter input=40 output=40\n","I0122 04:42:08.541215 139716735563648 efficientnet_model.py:147] round_filter input=80 output=80\n","I0122 04:42:08.901873 139716735563648 efficientnet_model.py:147] round_filter input=80 output=80\n","I0122 04:42:08.902062 139716735563648 efficientnet_model.py:147] round_filter input=112 output=112\n","I0122 04:42:09.284883 139716735563648 efficientnet_model.py:147] round_filter input=112 output=112\n","I0122 04:42:09.285062 139716735563648 efficientnet_model.py:147] round_filter input=192 output=192\n","I0122 04:42:09.776187 139716735563648 efficientnet_model.py:147] round_filter input=192 output=192\n","I0122 04:42:09.776372 139716735563648 efficientnet_model.py:147] round_filter input=320 output=320\n","I0122 04:42:09.893247 139716735563648 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0122 04:42:09.941669 139716735563648 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py:523: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0122 04:42:10.011250 139716735563648 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py:523: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/data/data_train.tfrecord']\n","I0122 04:42:10.025089 139716735563648 dataset_builder.py:148] Reading unweighted datasets: ['/content/data/data_train.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/data/data_train.tfrecord']\n","I0122 04:42:10.025333 139716735563648 dataset_builder.py:77] Reading record datasets for input file: ['/content/data/data_train.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0122 04:42:10.025459 139716735563648 dataset_builder.py:78] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0122 04:42:10.025551 139716735563648 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W0122 04:42:10.034585 139716735563648 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0122 04:42:10.063689 139716735563648 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0122 04:42:17.000216 139716735563648 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0122 04:42:21.410617 139716735563648 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2021-01-22 04:42:23.757974: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n","2021-01-22 04:42:23.767530: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2000140000 Hz\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","2021-01-22 04:42:56.738596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n","2021-01-22 04:42:57.626075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists\n","W0122 04:43:04.067948 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._groundtruth_lists\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor\n","W0122 04:43:04.068364 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n","W0122 04:43:04.068486 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head\n","W0122 04:43:04.068566 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads\n","W0122 04:43:04.068637 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._sorted_head_names\n","W0122 04:43:04.068711 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._sorted_head_names\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers\n","W0122 04:43:04.068788 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads\n","W0122 04:43:04.068857 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers\n","W0122 04:43:04.068922 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers\n","W0122 04:43:04.068986 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background\n","W0122 04:43:04.069051 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.0\n","W0122 04:43:04.069121 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.1\n","W0122 04:43:04.069204 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.2\n","W0122 04:43:04.069272 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.3\n","W0122 04:43:04.069356 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.4\n","W0122 04:43:04.069432 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings\n","W0122 04:43:04.069499 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background\n","W0122 04:43:04.069563 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower\n","W0122 04:43:04.069658 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower\n","W0122 04:43:04.069737 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0\n","W0122 04:43:04.069832 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers\n","W0122 04:43:04.069900 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0\n","W0122 04:43:04.069985 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1\n","W0122 04:43:04.070053 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2\n","W0122 04:43:04.070125 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3\n","W0122 04:43:04.070194 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4\n","W0122 04:43:04.070261 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0\n","W0122 04:43:04.070327 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1\n","W0122 04:43:04.070425 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2\n","W0122 04:43:04.070514 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3\n","W0122 04:43:04.070581 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4\n","W0122 04:43:04.070649 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0\n","W0122 04:43:04.070745 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1\n","W0122 04:43:04.070814 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2\n","W0122 04:43:04.070883 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0\n","W0122 04:43:04.070952 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1\n","W0122 04:43:04.071020 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2\n","W0122 04:43:04.071089 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.depthwise_kernel\n","W0122 04:43:04.071233 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.pointwise_kernel\n","W0122 04:43:04.071304 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.bias\n","W0122 04:43:04.071385 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0\n","W0122 04:43:04.071497 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1\n","W0122 04:43:04.071568 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.2\n","W0122 04:43:04.071647 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4\n","W0122 04:43:04.071717 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.5\n","W0122 04:43:04.071788 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7\n","W0122 04:43:04.071858 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.8\n","W0122 04:43:04.071928 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1\n","W0122 04:43:04.071996 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.2\n","W0122 04:43:04.072085 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4\n","W0122 04:43:04.072161 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.5\n","W0122 04:43:04.072234 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7\n","W0122 04:43:04.072303 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.8\n","W0122 04:43:04.072371 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1\n","W0122 04:43:04.072454 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.2\n","W0122 04:43:04.072522 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4\n","W0122 04:43:04.072589 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.5\n","W0122 04:43:04.072656 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7\n","W0122 04:43:04.072724 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.8\n","W0122 04:43:04.072790 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1\n","W0122 04:43:04.072857 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.2\n","W0122 04:43:04.072924 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4\n","W0122 04:43:04.072990 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.5\n","W0122 04:43:04.073056 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7\n","W0122 04:43:04.151262 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.8\n","W0122 04:43:04.151500 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1\n","W0122 04:43:04.151622 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.2\n","W0122 04:43:04.151723 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4\n","W0122 04:43:04.151832 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.5\n","W0122 04:43:04.151927 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7\n","W0122 04:43:04.152021 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.8\n","W0122 04:43:04.152125 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1\n","W0122 04:43:04.152224 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.2\n","W0122 04:43:04.152320 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4\n","W0122 04:43:04.152433 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.5\n","W0122 04:43:04.152534 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7\n","W0122 04:43:04.152636 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.8\n","W0122 04:43:04.152748 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1\n","W0122 04:43:04.152839 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.2\n","W0122 04:43:04.152942 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4\n","W0122 04:43:04.153026 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.5\n","W0122 04:43:04.153146 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7\n","W0122 04:43:04.153247 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.8\n","W0122 04:43:04.153339 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1\n","W0122 04:43:04.153451 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.2\n","W0122 04:43:04.153549 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4\n","W0122 04:43:04.153641 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.5\n","W0122 04:43:04.153733 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7\n","W0122 04:43:04.153825 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.8\n","W0122 04:43:04.153918 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1\n","W0122 04:43:04.154009 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.2\n","W0122 04:43:04.154100 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4\n","W0122 04:43:04.154207 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.5\n","W0122 04:43:04.154299 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7\n","W0122 04:43:04.154391 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.8\n","W0122 04:43:04.154505 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1\n","W0122 04:43:04.154599 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.2\n","W0122 04:43:04.154692 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4\n","W0122 04:43:04.154784 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.5\n","W0122 04:43:04.154877 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7\n","W0122 04:43:04.154989 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.8\n","W0122 04:43:04.155083 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.depthwise_kernel\n","W0122 04:43:04.155192 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.pointwise_kernel\n","W0122 04:43:04.155289 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.bias\n","W0122 04:43:04.155385 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.depthwise_kernel\n","W0122 04:43:04.155507 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.pointwise_kernel\n","W0122 04:43:04.155620 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.bias\n","W0122 04:43:04.155713 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.depthwise_kernel\n","W0122 04:43:04.155805 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.pointwise_kernel\n","W0122 04:43:04.155898 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.bias\n","W0122 04:43:04.155989 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.depthwise_kernel\n","W0122 04:43:04.156080 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.pointwise_kernel\n","W0122 04:43:04.156196 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.bias\n","W0122 04:43:04.156283 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.depthwise_kernel\n","W0122 04:43:04.156371 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.pointwise_kernel\n","W0122 04:43:04.156479 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.bias\n","W0122 04:43:04.156569 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.depthwise_kernel\n","W0122 04:43:04.156677 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.pointwise_kernel\n","W0122 04:43:04.156769 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.bias\n","W0122 04:43:04.156860 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.depthwise_kernel\n","W0122 04:43:04.156988 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.pointwise_kernel\n","W0122 04:43:04.157089 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.bias\n","W0122 04:43:04.157197 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.axis\n","W0122 04:43:04.157292 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.gamma\n","W0122 04:43:04.157385 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.beta\n","W0122 04:43:04.157498 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_mean\n","W0122 04:43:04.157579 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_variance\n","W0122 04:43:04.157669 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.axis\n","W0122 04:43:04.157746 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.gamma\n","W0122 04:43:04.157832 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.beta\n","W0122 04:43:04.157921 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_mean\n","W0122 04:43:04.158011 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_variance\n","W0122 04:43:04.158121 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.axis\n","W0122 04:43:04.158212 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.gamma\n","W0122 04:43:04.158298 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.beta\n","W0122 04:43:04.158383 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_mean\n","W0122 04:43:04.158492 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_variance\n","W0122 04:43:04.158580 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.axis\n","W0122 04:43:04.158690 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.gamma\n","W0122 04:43:04.158788 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.beta\n","W0122 04:43:04.158890 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_mean\n","W0122 04:43:04.158980 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_variance\n","W0122 04:43:04.159071 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.axis\n","W0122 04:43:04.159193 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.gamma\n","W0122 04:43:04.159287 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.beta\n","W0122 04:43:04.159381 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_mean\n","W0122 04:43:04.159505 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_variance\n","W0122 04:43:04.159619 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.axis\n","W0122 04:43:04.159715 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.gamma\n","W0122 04:43:04.159818 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.beta\n","W0122 04:43:04.159910 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_mean\n","W0122 04:43:04.160001 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_variance\n","W0122 04:43:04.160092 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.axis\n","W0122 04:43:04.160195 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.gamma\n","W0122 04:43:04.160286 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.beta\n","W0122 04:43:04.160376 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_mean\n","W0122 04:43:04.160487 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_variance\n","W0122 04:43:04.160581 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.axis\n","W0122 04:43:04.160673 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.gamma\n","W0122 04:43:04.160765 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.beta\n","W0122 04:43:04.160856 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_mean\n","W0122 04:43:04.160946 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_variance\n","W0122 04:43:04.161037 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.axis\n","W0122 04:43:04.161137 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.gamma\n","W0122 04:43:04.161232 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.beta\n","W0122 04:43:04.161323 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_mean\n","W0122 04:43:04.161431 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_variance\n","W0122 04:43:04.161531 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.axis\n","W0122 04:43:04.161622 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.gamma\n","W0122 04:43:04.161711 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.beta\n","W0122 04:43:04.161788 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_mean\n","W0122 04:43:04.161864 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_variance\n","W0122 04:43:04.161939 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.axis\n","W0122 04:43:04.162022 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.gamma\n","W0122 04:43:04.162119 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.beta\n","W0122 04:43:04.162214 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_mean\n","W0122 04:43:04.162309 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_variance\n","W0122 04:43:04.162394 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.axis\n","W0122 04:43:04.162522 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.gamma\n","W0122 04:43:04.162625 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.beta\n","W0122 04:43:04.162733 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_mean\n","W0122 04:43:04.162823 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_variance\n","W0122 04:43:04.162913 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.axis\n","W0122 04:43:04.163551 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.gamma\n","W0122 04:43:04.163692 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.beta\n","W0122 04:43:04.163791 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_mean\n","W0122 04:43:04.163869 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_variance\n","W0122 04:43:04.163944 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.axis\n","W0122 04:43:04.164014 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.gamma\n","W0122 04:43:04.164084 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.beta\n","W0122 04:43:04.164167 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_mean\n","W0122 04:43:04.164235 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_variance\n","W0122 04:43:04.164304 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.axis\n","W0122 04:43:04.164382 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.gamma\n","W0122 04:43:04.164461 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.beta\n","W0122 04:43:04.164542 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_mean\n","W0122 04:43:04.164623 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_variance\n","W0122 04:43:04.164730 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.axis\n","W0122 04:43:04.164822 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.gamma\n","W0122 04:43:04.164914 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.beta\n","W0122 04:43:04.165006 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.moving_mean\n","W0122 04:43:04.165098 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.moving_variance\n","W0122 04:43:04.165210 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.axis\n","W0122 04:43:04.165305 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.gamma\n","W0122 04:43:04.165397 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.beta\n","W0122 04:43:04.165508 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.moving_mean\n","W0122 04:43:04.165611 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.moving_variance\n","W0122 04:43:04.165706 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.axis\n","W0122 04:43:04.165798 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.gamma\n","W0122 04:43:04.165891 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.beta\n","W0122 04:43:04.166008 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.moving_mean\n","W0122 04:43:04.166100 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.moving_variance\n","W0122 04:43:04.166210 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.axis\n","W0122 04:43:04.166303 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.gamma\n","W0122 04:43:04.166396 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.beta\n","W0122 04:43:04.166518 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.moving_mean\n","W0122 04:43:04.166613 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.moving_variance\n","W0122 04:43:04.166706 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.axis\n","W0122 04:43:04.166803 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.gamma\n","W0122 04:43:04.166895 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.beta\n","W0122 04:43:04.166986 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.moving_mean\n","W0122 04:43:04.167079 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.moving_variance\n","W0122 04:43:04.167181 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.axis\n","W0122 04:43:04.167274 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.gamma\n","W0122 04:43:04.167366 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.beta\n","W0122 04:43:04.167474 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.moving_mean\n","W0122 04:43:04.167568 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.moving_variance\n","W0122 04:43:04.167661 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.axis\n","W0122 04:43:04.167752 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.gamma\n","W0122 04:43:04.167844 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.beta\n","W0122 04:43:04.167935 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.moving_mean\n","W0122 04:43:04.168026 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.moving_variance\n","W0122 04:43:04.168124 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.axis\n","W0122 04:43:04.168225 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.gamma\n","W0122 04:43:04.168312 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.beta\n","W0122 04:43:04.168400 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.moving_mean\n","W0122 04:43:04.168525 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.moving_variance\n","W0122 04:43:04.168619 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.axis\n","W0122 04:43:04.168711 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.gamma\n","W0122 04:43:04.168819 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.beta\n","W0122 04:43:04.168911 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.moving_mean\n","W0122 04:43:04.169003 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.moving_variance\n","W0122 04:43:04.169093 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.axis\n","W0122 04:43:04.169197 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.gamma\n","W0122 04:43:04.169289 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.beta\n","W0122 04:43:04.169382 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.moving_mean\n","W0122 04:43:04.169491 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.moving_variance\n","W0122 04:43:04.169599 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.axis\n","W0122 04:43:04.169697 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.gamma\n","W0122 04:43:04.169788 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.beta\n","W0122 04:43:04.169881 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.moving_mean\n","W0122 04:43:04.169970 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.moving_variance\n","W0122 04:43:04.170063 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.axis\n","W0122 04:43:04.170166 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.gamma\n","W0122 04:43:04.170257 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.beta\n","W0122 04:43:04.170348 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.moving_mean\n","W0122 04:43:04.170456 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.moving_variance\n","W0122 04:43:04.170549 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.axis\n","W0122 04:43:04.170640 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.gamma\n","W0122 04:43:04.170731 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.beta\n","W0122 04:43:04.170822 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.moving_mean\n","W0122 04:43:04.170925 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.moving_variance\n","W0122 04:43:04.171011 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.axis\n","W0122 04:43:04.171097 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.gamma\n","W0122 04:43:04.171226 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.beta\n","W0122 04:43:04.171313 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.moving_mean\n","W0122 04:43:04.171399 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.moving_variance\n","W0122 04:43:04.171527 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.axis\n","W0122 04:43:04.171620 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.gamma\n","W0122 04:43:04.171711 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.beta\n","W0122 04:43:04.171802 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.moving_mean\n","W0122 04:43:04.171894 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.moving_variance\n","W0122 04:43:04.171986 139716735563648 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.moving_variance\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","W0122 04:43:04.172148 139716735563648 util.py:169] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n","W0122 04:43:14.572982 139716023969536 utils.py:83] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0122 04:43:15.695974 139716023969536 deprecation.py:537] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n","W0122 04:43:27.527459 139716023969536 utils.py:83] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n","INFO:tensorflow:Step 100 per-step time 0.823s loss=1.038\n","I0122 04:45:04.823265 139716735563648 model_lib_v2.py:651] Step 100 per-step time 0.823s loss=1.038\n","INFO:tensorflow:Step 200 per-step time 0.709s loss=0.785\n","I0122 04:46:26.175071 139716735563648 model_lib_v2.py:651] Step 200 per-step time 0.709s loss=0.785\n","INFO:tensorflow:Step 300 per-step time 0.821s loss=0.483\n","I0122 04:47:47.814165 139716735563648 model_lib_v2.py:651] Step 300 per-step time 0.821s loss=0.483\n","INFO:tensorflow:Step 400 per-step time 0.770s loss=0.530\n","I0122 04:49:09.874422 139716735563648 model_lib_v2.py:651] Step 400 per-step time 0.770s loss=0.530\n","INFO:tensorflow:Step 500 per-step time 0.845s loss=0.530\n","I0122 04:50:31.219552 139716735563648 model_lib_v2.py:651] Step 500 per-step time 0.845s loss=0.530\n","INFO:tensorflow:Step 600 per-step time 0.736s loss=0.554\n","I0122 04:51:53.153437 139716735563648 model_lib_v2.py:651] Step 600 per-step time 0.736s loss=0.554\n","INFO:tensorflow:Step 700 per-step time 0.815s loss=0.523\n","I0122 04:53:14.782822 139716735563648 model_lib_v2.py:651] Step 700 per-step time 0.815s loss=0.523\n","INFO:tensorflow:Step 800 per-step time 0.817s loss=0.403\n","I0122 04:54:35.697660 139716735563648 model_lib_v2.py:651] Step 800 per-step time 0.817s loss=0.403\n","INFO:tensorflow:Step 900 per-step time 0.794s loss=0.387\n","I0122 04:55:57.049533 139716735563648 model_lib_v2.py:651] Step 900 per-step time 0.794s loss=0.387\n","INFO:tensorflow:Step 1000 per-step time 0.797s loss=0.492\n","I0122 04:57:17.195861 139716735563648 model_lib_v2.py:651] Step 1000 per-step time 0.797s loss=0.492\n","INFO:tensorflow:Step 1100 per-step time 0.831s loss=0.387\n","I0122 04:58:39.759256 139716735563648 model_lib_v2.py:651] Step 1100 per-step time 0.831s loss=0.387\n","INFO:tensorflow:Step 1200 per-step time 0.786s loss=0.386\n","I0122 05:00:00.151421 139716735563648 model_lib_v2.py:651] Step 1200 per-step time 0.786s loss=0.386\n","INFO:tensorflow:Step 1300 per-step time 0.754s loss=0.400\n","I0122 05:01:20.983083 139716735563648 model_lib_v2.py:651] Step 1300 per-step time 0.754s loss=0.400\n","INFO:tensorflow:Step 1400 per-step time 0.853s loss=0.494\n","I0122 05:02:41.016556 139716735563648 model_lib_v2.py:651] Step 1400 per-step time 0.853s loss=0.494\n","INFO:tensorflow:Step 1500 per-step time 0.816s loss=0.408\n","I0122 05:04:00.949613 139716735563648 model_lib_v2.py:651] Step 1500 per-step time 0.816s loss=0.408\n","INFO:tensorflow:Step 1600 per-step time 0.776s loss=0.414\n","I0122 05:05:20.926356 139716735563648 model_lib_v2.py:651] Step 1600 per-step time 0.776s loss=0.414\n","INFO:tensorflow:Step 1700 per-step time 0.747s loss=0.490\n","I0122 05:06:40.081057 139716735563648 model_lib_v2.py:651] Step 1700 per-step time 0.747s loss=0.490\n","INFO:tensorflow:Step 1800 per-step time 0.730s loss=0.404\n","I0122 05:08:02.379760 139716735563648 model_lib_v2.py:651] Step 1800 per-step time 0.730s loss=0.404\n","INFO:tensorflow:Step 1900 per-step time 0.814s loss=0.457\n","I0122 05:09:23.036834 139716735563648 model_lib_v2.py:651] Step 1900 per-step time 0.814s loss=0.457\n","INFO:tensorflow:Step 2000 per-step time 0.872s loss=0.410\n","I0122 05:10:42.617631 139716735563648 model_lib_v2.py:651] Step 2000 per-step time 0.872s loss=0.410\n","INFO:tensorflow:Step 2100 per-step time 0.823s loss=0.541\n","I0122 05:12:03.972270 139716735563648 model_lib_v2.py:651] Step 2100 per-step time 0.823s loss=0.541\n","INFO:tensorflow:Step 2200 per-step time 0.776s loss=0.320\n","I0122 05:13:24.923763 139716735563648 model_lib_v2.py:651] Step 2200 per-step time 0.776s loss=0.320\n","INFO:tensorflow:Step 2300 per-step time 0.822s loss=0.367\n","I0122 05:14:45.338856 139716735563648 model_lib_v2.py:651] Step 2300 per-step time 0.822s loss=0.367\n","INFO:tensorflow:Step 2400 per-step time 0.840s loss=0.349\n","I0122 05:16:05.816151 139716735563648 model_lib_v2.py:651] Step 2400 per-step time 0.840s loss=0.349\n","INFO:tensorflow:Step 2500 per-step time 0.805s loss=0.378\n","I0122 05:17:26.103522 139716735563648 model_lib_v2.py:651] Step 2500 per-step time 0.805s loss=0.378\n","INFO:tensorflow:Step 2600 per-step time 0.881s loss=0.419\n","I0122 05:18:46.924148 139716735563648 model_lib_v2.py:651] Step 2600 per-step time 0.881s loss=0.419\n","INFO:tensorflow:Step 2700 per-step time 0.837s loss=0.477\n","I0122 05:20:06.452593 139716735563648 model_lib_v2.py:651] Step 2700 per-step time 0.837s loss=0.477\n","INFO:tensorflow:Step 2800 per-step time 0.838s loss=0.384\n","I0122 05:21:26.576780 139716735563648 model_lib_v2.py:651] Step 2800 per-step time 0.838s loss=0.384\n","INFO:tensorflow:Step 2900 per-step time 0.742s loss=0.408\n","I0122 05:22:47.744509 139716735563648 model_lib_v2.py:651] Step 2900 per-step time 0.742s loss=0.408\n","INFO:tensorflow:Step 3000 per-step time 0.883s loss=0.362\n","I0122 05:24:07.923032 139716735563648 model_lib_v2.py:651] Step 3000 per-step time 0.883s loss=0.362\n","INFO:tensorflow:Step 3100 per-step time 0.849s loss=0.404\n","I0122 05:25:28.020368 139716735563648 model_lib_v2.py:651] Step 3100 per-step time 0.849s loss=0.404\n","INFO:tensorflow:Step 3200 per-step time 0.730s loss=0.375\n","I0122 05:26:47.421826 139716735563648 model_lib_v2.py:651] Step 3200 per-step time 0.730s loss=0.375\n","INFO:tensorflow:Step 3300 per-step time 0.789s loss=0.333\n","I0122 05:28:07.278084 139716735563648 model_lib_v2.py:651] Step 3300 per-step time 0.789s loss=0.333\n","INFO:tensorflow:Step 3400 per-step time 0.760s loss=0.520\n","I0122 05:29:26.590068 139716735563648 model_lib_v2.py:651] Step 3400 per-step time 0.760s loss=0.520\n","INFO:tensorflow:Step 3500 per-step time 0.697s loss=0.526\n","I0122 05:30:46.550488 139716735563648 model_lib_v2.py:651] Step 3500 per-step time 0.697s loss=0.526\n","INFO:tensorflow:Step 3600 per-step time 0.713s loss=0.512\n","I0122 05:32:06.358849 139716735563648 model_lib_v2.py:651] Step 3600 per-step time 0.713s loss=0.512\n","INFO:tensorflow:Step 3700 per-step time 0.844s loss=0.293\n","I0122 05:33:26.809406 139716735563648 model_lib_v2.py:651] Step 3700 per-step time 0.844s loss=0.293\n","INFO:tensorflow:Step 3800 per-step time 0.767s loss=0.390\n","I0122 05:34:46.807057 139716735563648 model_lib_v2.py:651] Step 3800 per-step time 0.767s loss=0.390\n","INFO:tensorflow:Step 3900 per-step time 0.832s loss=0.416\n","I0122 05:36:06.606386 139716735563648 model_lib_v2.py:651] Step 3900 per-step time 0.832s loss=0.416\n","INFO:tensorflow:Step 4000 per-step time 0.811s loss=0.298\n","I0122 05:37:26.412809 139716735563648 model_lib_v2.py:651] Step 4000 per-step time 0.811s loss=0.298\n","INFO:tensorflow:Step 4100 per-step time 0.815s loss=0.344\n","I0122 05:38:47.090428 139716735563648 model_lib_v2.py:651] Step 4100 per-step time 0.815s loss=0.344\n","INFO:tensorflow:Step 4200 per-step time 0.750s loss=0.329\n","I0122 05:40:06.685934 139716735563648 model_lib_v2.py:651] Step 4200 per-step time 0.750s loss=0.329\n","INFO:tensorflow:Step 4300 per-step time 0.812s loss=0.407\n","I0122 05:41:27.074779 139716735563648 model_lib_v2.py:651] Step 4300 per-step time 0.812s loss=0.407\n","INFO:tensorflow:Step 4400 per-step time 0.779s loss=0.317\n","I0122 05:42:47.152817 139716735563648 model_lib_v2.py:651] Step 4400 per-step time 0.779s loss=0.317\n","INFO:tensorflow:Step 4500 per-step time 0.794s loss=0.516\n","I0122 05:44:06.580497 139716735563648 model_lib_v2.py:651] Step 4500 per-step time 0.794s loss=0.516\n","INFO:tensorflow:Step 4600 per-step time 0.756s loss=0.335\n","I0122 05:45:26.862003 139716735563648 model_lib_v2.py:651] Step 4600 per-step time 0.756s loss=0.335\n","INFO:tensorflow:Step 4700 per-step time 0.714s loss=0.430\n","I0122 05:46:46.722803 139716735563648 model_lib_v2.py:651] Step 4700 per-step time 0.714s loss=0.430\n","INFO:tensorflow:Step 4800 per-step time 0.780s loss=0.314\n","I0122 05:48:06.521566 139716735563648 model_lib_v2.py:651] Step 4800 per-step time 0.780s loss=0.314\n","INFO:tensorflow:Step 4900 per-step time 0.766s loss=0.393\n","I0122 05:49:25.562064 139716735563648 model_lib_v2.py:651] Step 4900 per-step time 0.766s loss=0.393\n","INFO:tensorflow:Step 5000 per-step time 0.775s loss=0.403\n","I0122 05:50:44.722657 139716735563648 model_lib_v2.py:651] Step 5000 per-step time 0.775s loss=0.403\n","INFO:tensorflow:Step 5100 per-step time 0.769s loss=0.290\n","I0122 05:52:05.463588 139716735563648 model_lib_v2.py:651] Step 5100 per-step time 0.769s loss=0.290\n","INFO:tensorflow:Step 5200 per-step time 0.731s loss=0.325\n","I0122 05:53:24.315822 139716735563648 model_lib_v2.py:651] Step 5200 per-step time 0.731s loss=0.325\n","INFO:tensorflow:Step 5300 per-step time 0.831s loss=0.455\n","I0122 05:54:43.224900 139716735563648 model_lib_v2.py:651] Step 5300 per-step time 0.831s loss=0.455\n","INFO:tensorflow:Step 5400 per-step time 0.779s loss=0.328\n","I0122 05:56:03.038348 139716735563648 model_lib_v2.py:651] Step 5400 per-step time 0.779s loss=0.328\n","INFO:tensorflow:Step 5500 per-step time 0.789s loss=0.349\n","I0122 05:57:23.402730 139716735563648 model_lib_v2.py:651] Step 5500 per-step time 0.789s loss=0.349\n","INFO:tensorflow:Step 5600 per-step time 0.776s loss=0.331\n","I0122 05:58:42.791799 139716735563648 model_lib_v2.py:651] Step 5600 per-step time 0.776s loss=0.331\n","INFO:tensorflow:Step 5700 per-step time 0.737s loss=0.425\n","I0122 06:00:02.696250 139716735563648 model_lib_v2.py:651] Step 5700 per-step time 0.737s loss=0.425\n","INFO:tensorflow:Step 5800 per-step time 0.745s loss=0.429\n","I0122 06:01:22.750346 139716735563648 model_lib_v2.py:651] Step 5800 per-step time 0.745s loss=0.429\n","INFO:tensorflow:Step 5900 per-step time 0.793s loss=0.321\n","I0122 06:02:41.760628 139716735563648 model_lib_v2.py:651] Step 5900 per-step time 0.793s loss=0.321\n","INFO:tensorflow:Step 6000 per-step time 0.772s loss=0.345\n","I0122 06:04:00.955796 139716735563648 model_lib_v2.py:651] Step 6000 per-step time 0.772s loss=0.345\n","INFO:tensorflow:Step 6100 per-step time 0.848s loss=0.319\n","I0122 06:05:21.003280 139716735563648 model_lib_v2.py:651] Step 6100 per-step time 0.848s loss=0.319\n","INFO:tensorflow:Step 6200 per-step time 0.736s loss=0.425\n","I0122 06:06:39.700997 139716735563648 model_lib_v2.py:651] Step 6200 per-step time 0.736s loss=0.425\n","INFO:tensorflow:Step 6300 per-step time 0.768s loss=0.320\n","I0122 06:07:58.691661 139716735563648 model_lib_v2.py:651] Step 6300 per-step time 0.768s loss=0.320\n","INFO:tensorflow:Step 6400 per-step time 0.813s loss=0.350\n","I0122 06:09:18.492285 139716735563648 model_lib_v2.py:651] Step 6400 per-step time 0.813s loss=0.350\n","INFO:tensorflow:Step 6500 per-step time 0.763s loss=0.307\n","I0122 06:10:37.305053 139716735563648 model_lib_v2.py:651] Step 6500 per-step time 0.763s loss=0.307\n","INFO:tensorflow:Step 6600 per-step time 0.775s loss=0.302\n","I0122 06:11:57.488833 139716735563648 model_lib_v2.py:651] Step 6600 per-step time 0.775s loss=0.302\n","INFO:tensorflow:Step 6700 per-step time 0.813s loss=0.389\n","I0122 06:13:16.478935 139716735563648 model_lib_v2.py:651] Step 6700 per-step time 0.813s loss=0.389\n","INFO:tensorflow:Step 6800 per-step time 0.773s loss=0.456\n","I0122 06:14:36.300203 139716735563648 model_lib_v2.py:651] Step 6800 per-step time 0.773s loss=0.456\n","INFO:tensorflow:Step 6900 per-step time 0.757s loss=0.306\n","I0122 06:15:56.218305 139716735563648 model_lib_v2.py:651] Step 6900 per-step time 0.757s loss=0.306\n","INFO:tensorflow:Step 7000 per-step time 0.783s loss=0.270\n","I0122 06:17:15.321856 139716735563648 model_lib_v2.py:651] Step 7000 per-step time 0.783s loss=0.270\n","INFO:tensorflow:Step 7100 per-step time 0.775s loss=0.313\n","I0122 06:18:35.226628 139716735563648 model_lib_v2.py:651] Step 7100 per-step time 0.775s loss=0.313\n","INFO:tensorflow:Step 7200 per-step time 0.770s loss=0.319\n","I0122 06:19:54.655843 139716735563648 model_lib_v2.py:651] Step 7200 per-step time 0.770s loss=0.319\n","INFO:tensorflow:Step 7300 per-step time 0.787s loss=0.280\n","I0122 06:21:13.665725 139716735563648 model_lib_v2.py:651] Step 7300 per-step time 0.787s loss=0.280\n","INFO:tensorflow:Step 7400 per-step time 0.773s loss=0.347\n","I0122 06:22:33.351614 139716735563648 model_lib_v2.py:651] Step 7400 per-step time 0.773s loss=0.347\n","INFO:tensorflow:Step 7500 per-step time 0.766s loss=0.378\n","I0122 06:23:52.878142 139716735563648 model_lib_v2.py:651] Step 7500 per-step time 0.766s loss=0.378\n","INFO:tensorflow:Step 7600 per-step time 0.778s loss=0.340\n","I0122 06:25:13.256258 139716735563648 model_lib_v2.py:651] Step 7600 per-step time 0.778s loss=0.340\n","INFO:tensorflow:Step 7700 per-step time 0.823s loss=0.407\n","I0122 06:26:32.162642 139716735563648 model_lib_v2.py:651] Step 7700 per-step time 0.823s loss=0.407\n","INFO:tensorflow:Step 7800 per-step time 0.829s loss=0.378\n","I0122 06:27:52.012001 139716735563648 model_lib_v2.py:651] Step 7800 per-step time 0.829s loss=0.378\n","INFO:tensorflow:Step 7900 per-step time 0.734s loss=0.392\n","I0122 06:29:11.824470 139716735563648 model_lib_v2.py:651] Step 7900 per-step time 0.734s loss=0.392\n","INFO:tensorflow:Step 8000 per-step time 0.707s loss=0.409\n","I0122 06:30:31.324310 139716735563648 model_lib_v2.py:651] Step 8000 per-step time 0.707s loss=0.409\n","INFO:tensorflow:Step 8100 per-step time 0.858s loss=0.309\n","I0122 06:31:52.874846 139716735563648 model_lib_v2.py:651] Step 8100 per-step time 0.858s loss=0.309\n","INFO:tensorflow:Step 8200 per-step time 0.764s loss=0.360\n","I0122 06:33:13.373659 139716735563648 model_lib_v2.py:651] Step 8200 per-step time 0.764s loss=0.360\n","INFO:tensorflow:Step 8300 per-step time 0.828s loss=0.341\n","I0122 06:34:33.674915 139716735563648 model_lib_v2.py:651] Step 8300 per-step time 0.828s loss=0.341\n","INFO:tensorflow:Step 8400 per-step time 0.801s loss=0.328\n","I0122 06:35:53.320625 139716735563648 model_lib_v2.py:651] Step 8400 per-step time 0.801s loss=0.328\n","INFO:tensorflow:Step 8500 per-step time 0.840s loss=0.306\n","I0122 06:37:13.812625 139716735563648 model_lib_v2.py:651] Step 8500 per-step time 0.840s loss=0.306\n","INFO:tensorflow:Step 8600 per-step time 0.796s loss=0.298\n","I0122 06:38:34.510232 139716735563648 model_lib_v2.py:651] Step 8600 per-step time 0.796s loss=0.298\n","INFO:tensorflow:Step 8700 per-step time 0.786s loss=0.268\n","I0122 06:39:54.639773 139716735563648 model_lib_v2.py:651] Step 8700 per-step time 0.786s loss=0.268\n","INFO:tensorflow:Step 8800 per-step time 0.768s loss=0.276\n","I0122 06:41:14.768358 139716735563648 model_lib_v2.py:651] Step 8800 per-step time 0.768s loss=0.276\n","INFO:tensorflow:Step 8900 per-step time 0.773s loss=0.419\n","I0122 06:42:35.396997 139716735563648 model_lib_v2.py:651] Step 8900 per-step time 0.773s loss=0.419\n","INFO:tensorflow:Step 9000 per-step time 0.804s loss=0.295\n","I0122 06:43:55.378704 139716735563648 model_lib_v2.py:651] Step 9000 per-step time 0.804s loss=0.295\n","INFO:tensorflow:Step 9100 per-step time 0.803s loss=0.384\n","I0122 06:45:16.073491 139716735563648 model_lib_v2.py:651] Step 9100 per-step time 0.803s loss=0.384\n","INFO:tensorflow:Step 9200 per-step time 0.784s loss=0.267\n","I0122 06:46:36.255887 139716735563648 model_lib_v2.py:651] Step 9200 per-step time 0.784s loss=0.267\n","INFO:tensorflow:Step 9300 per-step time 0.823s loss=0.305\n","I0122 06:47:56.299336 139716735563648 model_lib_v2.py:651] Step 9300 per-step time 0.823s loss=0.305\n","INFO:tensorflow:Step 9400 per-step time 0.706s loss=0.352\n","I0122 06:49:15.756107 139716735563648 model_lib_v2.py:651] Step 9400 per-step time 0.706s loss=0.352\n","INFO:tensorflow:Step 9500 per-step time 0.865s loss=0.339\n","I0122 06:50:35.839658 139716735563648 model_lib_v2.py:651] Step 9500 per-step time 0.865s loss=0.339\n","INFO:tensorflow:Step 9600 per-step time 0.828s loss=0.304\n","I0122 06:51:55.028475 139716735563648 model_lib_v2.py:651] Step 9600 per-step time 0.828s loss=0.304\n","INFO:tensorflow:Step 9700 per-step time 0.837s loss=0.281\n","I0122 06:53:14.391160 139716735563648 model_lib_v2.py:651] Step 9700 per-step time 0.837s loss=0.281\n","INFO:tensorflow:Step 9800 per-step time 0.849s loss=0.293\n","I0122 06:54:34.253006 139716735563648 model_lib_v2.py:651] Step 9800 per-step time 0.849s loss=0.293\n","INFO:tensorflow:Step 9900 per-step time 0.694s loss=0.342\n","I0122 06:55:54.122899 139716735563648 model_lib_v2.py:651] Step 9900 per-step time 0.694s loss=0.342\n","INFO:tensorflow:Step 10000 per-step time 0.861s loss=0.286\n","I0122 06:57:13.765707 139716735563648 model_lib_v2.py:651] Step 10000 per-step time 0.861s loss=0.286\n","INFO:tensorflow:Step 10100 per-step time 0.841s loss=0.437\n","I0122 06:58:34.437200 139716735563648 model_lib_v2.py:651] Step 10100 per-step time 0.841s loss=0.437\n","INFO:tensorflow:Step 10200 per-step time 0.784s loss=0.304\n","I0122 06:59:53.447828 139716735563648 model_lib_v2.py:651] Step 10200 per-step time 0.784s loss=0.304\n","INFO:tensorflow:Step 10300 per-step time 0.717s loss=0.343\n","I0122 07:01:12.976519 139716735563648 model_lib_v2.py:651] Step 10300 per-step time 0.717s loss=0.343\n","INFO:tensorflow:Step 10400 per-step time 0.829s loss=0.380\n","I0122 07:02:32.635449 139716735563648 model_lib_v2.py:651] Step 10400 per-step time 0.829s loss=0.380\n","INFO:tensorflow:Step 10500 per-step time 0.787s loss=0.325\n","I0122 07:03:51.423802 139716735563648 model_lib_v2.py:651] Step 10500 per-step time 0.787s loss=0.325\n","INFO:tensorflow:Step 10600 per-step time 0.785s loss=0.362\n","I0122 07:05:11.257340 139716735563648 model_lib_v2.py:651] Step 10600 per-step time 0.785s loss=0.362\n","INFO:tensorflow:Step 10700 per-step time 0.774s loss=0.328\n","I0122 07:06:31.223094 139716735563648 model_lib_v2.py:651] Step 10700 per-step time 0.774s loss=0.328\n","INFO:tensorflow:Step 10800 per-step time 0.804s loss=0.256\n","I0122 07:07:51.520750 139716735563648 model_lib_v2.py:651] Step 10800 per-step time 0.804s loss=0.256\n","INFO:tensorflow:Step 10900 per-step time 0.773s loss=0.306\n","I0122 07:09:10.644111 139716735563648 model_lib_v2.py:651] Step 10900 per-step time 0.773s loss=0.306\n","INFO:tensorflow:Step 11000 per-step time 0.831s loss=0.350\n","I0122 07:10:31.388841 139716735563648 model_lib_v2.py:651] Step 11000 per-step time 0.831s loss=0.350\n","INFO:tensorflow:Step 11100 per-step time 0.764s loss=0.365\n","I0122 07:11:52.829956 139716735563648 model_lib_v2.py:651] Step 11100 per-step time 0.764s loss=0.365\n","INFO:tensorflow:Step 11200 per-step time 0.805s loss=0.246\n","I0122 07:13:13.128513 139716735563648 model_lib_v2.py:651] Step 11200 per-step time 0.805s loss=0.246\n","INFO:tensorflow:Step 11300 per-step time 0.751s loss=0.277\n","I0122 07:14:32.752175 139716735563648 model_lib_v2.py:651] Step 11300 per-step time 0.751s loss=0.277\n","INFO:tensorflow:Step 11400 per-step time 0.797s loss=0.322\n","I0122 07:15:52.148987 139716735563648 model_lib_v2.py:651] Step 11400 per-step time 0.797s loss=0.322\n","INFO:tensorflow:Step 11500 per-step time 0.730s loss=0.308\n","I0122 07:17:11.966835 139716735563648 model_lib_v2.py:651] Step 11500 per-step time 0.730s loss=0.308\n","INFO:tensorflow:Step 11600 per-step time 0.798s loss=0.258\n","I0122 07:18:30.955762 139716735563648 model_lib_v2.py:651] Step 11600 per-step time 0.798s loss=0.258\n","INFO:tensorflow:Step 11700 per-step time 0.739s loss=0.353\n","I0122 07:19:50.163965 139716735563648 model_lib_v2.py:651] Step 11700 per-step time 0.739s loss=0.353\n","INFO:tensorflow:Step 11800 per-step time 0.782s loss=0.377\n","I0122 07:21:09.628104 139716735563648 model_lib_v2.py:651] Step 11800 per-step time 0.782s loss=0.377\n","INFO:tensorflow:Step 11900 per-step time 0.833s loss=0.349\n","I0122 07:22:29.339694 139716735563648 model_lib_v2.py:651] Step 11900 per-step time 0.833s loss=0.349\n","INFO:tensorflow:Step 12000 per-step time 0.760s loss=0.303\n","I0122 07:23:48.753583 139716735563648 model_lib_v2.py:651] Step 12000 per-step time 0.760s loss=0.303\n","INFO:tensorflow:Step 12100 per-step time 0.760s loss=0.306\n","I0122 07:25:09.426372 139716735563648 model_lib_v2.py:651] Step 12100 per-step time 0.760s loss=0.306\n","INFO:tensorflow:Step 12200 per-step time 0.747s loss=0.331\n","I0122 07:26:28.890685 139716735563648 model_lib_v2.py:651] Step 12200 per-step time 0.747s loss=0.331\n","INFO:tensorflow:Step 12300 per-step time 0.883s loss=0.297\n","I0122 07:27:49.400762 139716735563648 model_lib_v2.py:651] Step 12300 per-step time 0.883s loss=0.297\n","INFO:tensorflow:Step 12400 per-step time 0.839s loss=0.283\n","I0122 07:29:09.357529 139716735563648 model_lib_v2.py:651] Step 12400 per-step time 0.839s loss=0.283\n","INFO:tensorflow:Step 12500 per-step time 0.831s loss=0.275\n","I0122 07:30:28.775033 139716735563648 model_lib_v2.py:651] Step 12500 per-step time 0.831s loss=0.275\n","INFO:tensorflow:Step 12600 per-step time 0.700s loss=0.286\n","I0122 07:31:48.333273 139716735563648 model_lib_v2.py:651] Step 12600 per-step time 0.700s loss=0.286\n","INFO:tensorflow:Step 12700 per-step time 0.801s loss=0.306\n","I0122 07:33:07.823126 139716735563648 model_lib_v2.py:651] Step 12700 per-step time 0.801s loss=0.306\n","INFO:tensorflow:Step 12800 per-step time 0.746s loss=0.420\n","I0122 07:34:27.808226 139716735563648 model_lib_v2.py:651] Step 12800 per-step time 0.746s loss=0.420\n","INFO:tensorflow:Step 12900 per-step time 0.821s loss=0.291\n","I0122 07:35:47.105507 139716735563648 model_lib_v2.py:651] Step 12900 per-step time 0.821s loss=0.291\n","INFO:tensorflow:Step 13000 per-step time 0.875s loss=0.389\n","I0122 07:37:06.463437 139716735563648 model_lib_v2.py:651] Step 13000 per-step time 0.875s loss=0.389\n","INFO:tensorflow:Step 13100 per-step time 0.802s loss=0.244\n","I0122 07:38:26.107242 139716735563648 model_lib_v2.py:651] Step 13100 per-step time 0.802s loss=0.244\n","INFO:tensorflow:Step 13200 per-step time 0.825s loss=0.273\n","I0122 07:39:45.668006 139716735563648 model_lib_v2.py:651] Step 13200 per-step time 0.825s loss=0.273\n","INFO:tensorflow:Step 13300 per-step time 0.838s loss=0.307\n","I0122 07:41:05.187489 139716735563648 model_lib_v2.py:651] Step 13300 per-step time 0.838s loss=0.307\n","INFO:tensorflow:Step 13400 per-step time 0.715s loss=0.317\n","I0122 07:42:25.051908 139716735563648 model_lib_v2.py:651] Step 13400 per-step time 0.715s loss=0.317\n","INFO:tensorflow:Step 13500 per-step time 0.740s loss=0.384\n","I0122 07:43:44.176338 139716735563648 model_lib_v2.py:651] Step 13500 per-step time 0.740s loss=0.384\n","INFO:tensorflow:Step 13600 per-step time 0.873s loss=0.246\n","I0122 07:45:03.677391 139716735563648 model_lib_v2.py:651] Step 13600 per-step time 0.873s loss=0.246\n","INFO:tensorflow:Step 13700 per-step time 0.846s loss=0.311\n","I0122 07:46:22.788594 139716735563648 model_lib_v2.py:651] Step 13700 per-step time 0.846s loss=0.311\n","INFO:tensorflow:Step 13800 per-step time 0.722s loss=0.343\n","I0122 07:47:41.257793 139716735563648 model_lib_v2.py:651] Step 13800 per-step time 0.722s loss=0.343\n","INFO:tensorflow:Step 13900 per-step time 0.769s loss=0.322\n","I0122 07:49:00.308023 139716735563648 model_lib_v2.py:651] Step 13900 per-step time 0.769s loss=0.322\n","INFO:tensorflow:Step 14000 per-step time 0.809s loss=0.306\n","I0122 07:50:18.368441 139716735563648 model_lib_v2.py:651] Step 14000 per-step time 0.809s loss=0.306\n","INFO:tensorflow:Step 14100 per-step time 0.795s loss=0.473\n","I0122 07:51:39.389786 139716735563648 model_lib_v2.py:651] Step 14100 per-step time 0.795s loss=0.473\n","INFO:tensorflow:Step 14200 per-step time 0.787s loss=0.336\n","I0122 07:52:59.262000 139716735563648 model_lib_v2.py:651] Step 14200 per-step time 0.787s loss=0.336\n","INFO:tensorflow:Step 14300 per-step time 0.847s loss=0.285\n","I0122 07:54:19.624886 139716735563648 model_lib_v2.py:651] Step 14300 per-step time 0.847s loss=0.285\n","INFO:tensorflow:Step 14400 per-step time 0.834s loss=0.370\n","I0122 07:55:40.010636 139716735563648 model_lib_v2.py:651] Step 14400 per-step time 0.834s loss=0.370\n","INFO:tensorflow:Step 14500 per-step time 0.765s loss=0.288\n","I0122 07:56:58.618874 139716735563648 model_lib_v2.py:651] Step 14500 per-step time 0.765s loss=0.288\n","INFO:tensorflow:Step 14600 per-step time 0.860s loss=0.297\n","I0122 07:58:17.817929 139716735563648 model_lib_v2.py:651] Step 14600 per-step time 0.860s loss=0.297\n","INFO:tensorflow:Step 14700 per-step time 0.856s loss=0.329\n","I0122 07:59:37.593609 139716735563648 model_lib_v2.py:651] Step 14700 per-step time 0.856s loss=0.329\n","INFO:tensorflow:Step 14800 per-step time 0.830s loss=0.285\n","I0122 08:00:57.064515 139716735563648 model_lib_v2.py:651] Step 14800 per-step time 0.830s loss=0.285\n","INFO:tensorflow:Step 14900 per-step time 0.758s loss=0.282\n","I0122 08:02:16.388639 139716735563648 model_lib_v2.py:651] Step 14900 per-step time 0.758s loss=0.282\n","INFO:tensorflow:Step 15000 per-step time 0.781s loss=0.337\n","I0122 08:03:35.289479 139716735563648 model_lib_v2.py:651] Step 15000 per-step time 0.781s loss=0.337\n","INFO:tensorflow:Step 15100 per-step time 0.773s loss=0.240\n","I0122 08:04:56.210569 139716735563648 model_lib_v2.py:651] Step 15100 per-step time 0.773s loss=0.240\n","INFO:tensorflow:Step 15200 per-step time 0.781s loss=0.283\n","I0122 08:06:15.331929 139716735563648 model_lib_v2.py:651] Step 15200 per-step time 0.781s loss=0.283\n","INFO:tensorflow:Step 15300 per-step time 0.833s loss=0.288\n","I0122 08:07:34.166430 139716735563648 model_lib_v2.py:651] Step 15300 per-step time 0.833s loss=0.288\n","INFO:tensorflow:Step 15400 per-step time 0.761s loss=0.293\n","I0122 08:08:53.110528 139716735563648 model_lib_v2.py:651] Step 15400 per-step time 0.761s loss=0.293\n","INFO:tensorflow:Step 15500 per-step time 0.823s loss=0.363\n","I0122 08:10:12.109348 139716735563648 model_lib_v2.py:651] Step 15500 per-step time 0.823s loss=0.363\n","INFO:tensorflow:Step 15600 per-step time 0.760s loss=0.297\n","I0122 08:11:30.935571 139716735563648 model_lib_v2.py:651] Step 15600 per-step time 0.760s loss=0.297\n","INFO:tensorflow:Step 15700 per-step time 0.854s loss=0.284\n","I0122 08:12:50.699061 139716735563648 model_lib_v2.py:651] Step 15700 per-step time 0.854s loss=0.284\n","INFO:tensorflow:Step 15800 per-step time 0.831s loss=0.310\n","I0122 08:14:10.369066 139716735563648 model_lib_v2.py:651] Step 15800 per-step time 0.831s loss=0.310\n","INFO:tensorflow:Step 15900 per-step time 0.778s loss=0.350\n","I0122 08:15:30.160154 139716735563648 model_lib_v2.py:651] Step 15900 per-step time 0.778s loss=0.350\n","INFO:tensorflow:Step 16000 per-step time 0.799s loss=0.257\n","I0122 08:16:49.405718 139716735563648 model_lib_v2.py:651] Step 16000 per-step time 0.799s loss=0.257\n","INFO:tensorflow:Step 16100 per-step time 0.799s loss=0.303\n","I0122 08:18:10.768931 139716735563648 model_lib_v2.py:651] Step 16100 per-step time 0.799s loss=0.303\n","INFO:tensorflow:Step 16200 per-step time 0.819s loss=0.435\n","I0122 08:19:31.513113 139716735563648 model_lib_v2.py:651] Step 16200 per-step time 0.819s loss=0.435\n","INFO:tensorflow:Step 16300 per-step time 0.826s loss=0.265\n","I0122 08:20:52.977646 139716735563648 model_lib_v2.py:651] Step 16300 per-step time 0.826s loss=0.265\n","INFO:tensorflow:Step 16400 per-step time 0.804s loss=0.280\n","I0122 08:22:13.907610 139716735563648 model_lib_v2.py:651] Step 16400 per-step time 0.804s loss=0.280\n","INFO:tensorflow:Step 16500 per-step time 0.853s loss=0.275\n","I0122 08:23:35.809831 139716735563648 model_lib_v2.py:651] Step 16500 per-step time 0.853s loss=0.275\n","INFO:tensorflow:Step 16600 per-step time 0.849s loss=0.313\n","I0122 08:24:56.673240 139716735563648 model_lib_v2.py:651] Step 16600 per-step time 0.849s loss=0.313\n","INFO:tensorflow:Step 16700 per-step time 0.908s loss=0.335\n","I0122 08:26:18.670426 139716735563648 model_lib_v2.py:651] Step 16700 per-step time 0.908s loss=0.335\n","INFO:tensorflow:Step 16800 per-step time 0.882s loss=0.288\n","I0122 08:27:39.152358 139716735563648 model_lib_v2.py:651] Step 16800 per-step time 0.882s loss=0.288\n","INFO:tensorflow:Step 16900 per-step time 0.814s loss=0.283\n","I0122 08:28:59.461455 139716735563648 model_lib_v2.py:651] Step 16900 per-step time 0.814s loss=0.283\n","INFO:tensorflow:Step 17000 per-step time 0.825s loss=0.260\n","I0122 08:30:20.586139 139716735563648 model_lib_v2.py:651] Step 17000 per-step time 0.825s loss=0.260\n","INFO:tensorflow:Step 17100 per-step time 0.803s loss=0.241\n","I0122 08:31:41.896435 139716735563648 model_lib_v2.py:651] Step 17100 per-step time 0.803s loss=0.241\n","INFO:tensorflow:Step 17200 per-step time 0.808s loss=0.314\n","I0122 08:33:01.355872 139716735563648 model_lib_v2.py:651] Step 17200 per-step time 0.808s loss=0.314\n","INFO:tensorflow:Step 17300 per-step time 0.844s loss=0.274\n","I0122 08:34:21.113919 139716735563648 model_lib_v2.py:651] Step 17300 per-step time 0.844s loss=0.274\n","INFO:tensorflow:Step 17400 per-step time 0.826s loss=0.229\n","I0122 08:35:40.541391 139716735563648 model_lib_v2.py:651] Step 17400 per-step time 0.826s loss=0.229\n","INFO:tensorflow:Step 17500 per-step time 0.826s loss=0.261\n","I0122 08:37:00.077522 139716735563648 model_lib_v2.py:651] Step 17500 per-step time 0.826s loss=0.261\n","INFO:tensorflow:Step 17600 per-step time 0.822s loss=0.264\n","I0122 08:38:20.170383 139716735563648 model_lib_v2.py:651] Step 17600 per-step time 0.822s loss=0.264\n","INFO:tensorflow:Step 17700 per-step time 0.790s loss=0.310\n","I0122 08:39:39.664790 139716735563648 model_lib_v2.py:651] Step 17700 per-step time 0.790s loss=0.310\n","INFO:tensorflow:Step 17800 per-step time 0.841s loss=0.293\n","I0122 08:40:59.693627 139716735563648 model_lib_v2.py:651] Step 17800 per-step time 0.841s loss=0.293\n","INFO:tensorflow:Step 17900 per-step time 0.770s loss=0.311\n","I0122 08:42:19.826422 139716735563648 model_lib_v2.py:651] Step 17900 per-step time 0.770s loss=0.311\n","INFO:tensorflow:Step 18000 per-step time 0.824s loss=0.338\n","I0122 08:43:40.258860 139716735563648 model_lib_v2.py:651] Step 18000 per-step time 0.824s loss=0.338\n","INFO:tensorflow:Step 18100 per-step time 0.749s loss=0.270\n","I0122 08:45:00.268516 139716735563648 model_lib_v2.py:651] Step 18100 per-step time 0.749s loss=0.270\n","INFO:tensorflow:Step 18200 per-step time 0.752s loss=0.387\n","I0122 08:46:19.086537 139716735563648 model_lib_v2.py:651] Step 18200 per-step time 0.752s loss=0.387\n","INFO:tensorflow:Step 18300 per-step time 0.768s loss=0.337\n","I0122 08:47:37.629363 139716735563648 model_lib_v2.py:651] Step 18300 per-step time 0.768s loss=0.337\n","INFO:tensorflow:Step 18400 per-step time 0.783s loss=0.260\n","I0122 08:48:57.133044 139716735563648 model_lib_v2.py:651] Step 18400 per-step time 0.783s loss=0.260\n","INFO:tensorflow:Step 18500 per-step time 0.850s loss=0.273\n","I0122 08:50:15.947125 139716735563648 model_lib_v2.py:651] Step 18500 per-step time 0.850s loss=0.273\n","INFO:tensorflow:Step 18600 per-step time 0.798s loss=0.288\n","I0122 08:51:36.040815 139716735563648 model_lib_v2.py:651] Step 18600 per-step time 0.798s loss=0.288\n","INFO:tensorflow:Step 18700 per-step time 0.780s loss=0.324\n","I0122 08:52:56.164328 139716735563648 model_lib_v2.py:651] Step 18700 per-step time 0.780s loss=0.324\n","INFO:tensorflow:Step 18800 per-step time 0.824s loss=0.341\n","I0122 08:54:15.869146 139716735563648 model_lib_v2.py:651] Step 18800 per-step time 0.824s loss=0.341\n","INFO:tensorflow:Step 18900 per-step time 0.844s loss=0.286\n","I0122 08:55:35.302317 139716735563648 model_lib_v2.py:651] Step 18900 per-step time 0.844s loss=0.286\n","INFO:tensorflow:Step 19000 per-step time 0.734s loss=0.300\n","I0122 08:56:53.738814 139716735563648 model_lib_v2.py:651] Step 19000 per-step time 0.734s loss=0.300\n","INFO:tensorflow:Step 19100 per-step time 0.789s loss=0.285\n","I0122 08:58:13.263280 139716735563648 model_lib_v2.py:651] Step 19100 per-step time 0.789s loss=0.285\n","INFO:tensorflow:Step 19200 per-step time 0.839s loss=0.287\n","I0122 08:59:32.807138 139716735563648 model_lib_v2.py:651] Step 19200 per-step time 0.839s loss=0.287\n","INFO:tensorflow:Step 19300 per-step time 0.752s loss=0.409\n","I0122 09:00:51.633129 139716735563648 model_lib_v2.py:651] Step 19300 per-step time 0.752s loss=0.409\n","INFO:tensorflow:Step 19400 per-step time 0.789s loss=0.324\n","I0122 09:02:11.507348 139716735563648 model_lib_v2.py:651] Step 19400 per-step time 0.789s loss=0.324\n","INFO:tensorflow:Step 19500 per-step time 0.701s loss=0.350\n","I0122 09:03:30.092946 139716735563648 model_lib_v2.py:651] Step 19500 per-step time 0.701s loss=0.350\n","INFO:tensorflow:Step 19600 per-step time 0.911s loss=0.302\n","I0122 09:04:48.743497 139716735563648 model_lib_v2.py:651] Step 19600 per-step time 0.911s loss=0.302\n","INFO:tensorflow:Step 19700 per-step time 0.784s loss=0.429\n","I0122 09:06:07.008966 139716735563648 model_lib_v2.py:651] Step 19700 per-step time 0.784s loss=0.429\n","INFO:tensorflow:Step 19800 per-step time 0.812s loss=0.334\n","I0122 09:07:26.724505 139716735563648 model_lib_v2.py:651] Step 19800 per-step time 0.812s loss=0.334\n","INFO:tensorflow:Step 19900 per-step time 0.792s loss=0.259\n","I0122 09:08:45.832703 139716735563648 model_lib_v2.py:651] Step 19900 per-step time 0.792s loss=0.259\n","INFO:tensorflow:Step 20000 per-step time 0.801s loss=0.255\n","I0122 09:10:04.650787 139716735563648 model_lib_v2.py:651] Step 20000 per-step time 0.801s loss=0.255\n","INFO:tensorflow:Step 20100 per-step time 0.852s loss=0.312\n","I0122 09:11:24.339024 139716735563648 model_lib_v2.py:651] Step 20100 per-step time 0.852s loss=0.312\n","INFO:tensorflow:Step 20200 per-step time 0.823s loss=0.283\n","I0122 09:12:42.316925 139716735563648 model_lib_v2.py:651] Step 20200 per-step time 0.823s loss=0.283\n","INFO:tensorflow:Step 20300 per-step time 0.770s loss=0.293\n","I0122 09:14:02.632475 139716735563648 model_lib_v2.py:651] Step 20300 per-step time 0.770s loss=0.293\n","INFO:tensorflow:Step 20400 per-step time 0.823s loss=0.294\n","I0122 09:15:22.262099 139716735563648 model_lib_v2.py:651] Step 20400 per-step time 0.823s loss=0.294\n","INFO:tensorflow:Step 20500 per-step time 0.750s loss=0.253\n","I0122 09:16:40.080585 139716735563648 model_lib_v2.py:651] Step 20500 per-step time 0.750s loss=0.253\n","INFO:tensorflow:Step 20600 per-step time 0.744s loss=0.350\n","I0122 09:17:58.450947 139716735563648 model_lib_v2.py:651] Step 20600 per-step time 0.744s loss=0.350\n","INFO:tensorflow:Step 20700 per-step time 0.756s loss=0.219\n","I0122 09:19:16.508175 139716735563648 model_lib_v2.py:651] Step 20700 per-step time 0.756s loss=0.219\n","INFO:tensorflow:Step 20800 per-step time 0.798s loss=0.221\n","I0122 09:20:34.833108 139716735563648 model_lib_v2.py:651] Step 20800 per-step time 0.798s loss=0.221\n","INFO:tensorflow:Step 20900 per-step time 0.770s loss=0.281\n","I0122 09:21:54.004726 139716735563648 model_lib_v2.py:651] Step 20900 per-step time 0.770s loss=0.281\n","INFO:tensorflow:Step 21000 per-step time 0.822s loss=0.215\n","I0122 09:23:12.542562 139716735563648 model_lib_v2.py:651] Step 21000 per-step time 0.822s loss=0.215\n","INFO:tensorflow:Step 21100 per-step time 0.852s loss=0.274\n","I0122 09:24:32.295382 139716735563648 model_lib_v2.py:651] Step 21100 per-step time 0.852s loss=0.274\n","INFO:tensorflow:Step 21200 per-step time 0.781s loss=0.286\n","I0122 09:25:51.434894 139716735563648 model_lib_v2.py:651] Step 21200 per-step time 0.781s loss=0.286\n","INFO:tensorflow:Step 21300 per-step time 0.744s loss=0.246\n","I0122 09:27:09.941262 139716735563648 model_lib_v2.py:651] Step 21300 per-step time 0.744s loss=0.246\n","INFO:tensorflow:Step 21400 per-step time 0.726s loss=0.270\n","I0122 09:28:28.337670 139716735563648 model_lib_v2.py:651] Step 21400 per-step time 0.726s loss=0.270\n","INFO:tensorflow:Step 21500 per-step time 0.700s loss=0.262\n","I0122 09:29:46.479064 139716735563648 model_lib_v2.py:651] Step 21500 per-step time 0.700s loss=0.262\n","INFO:tensorflow:Step 21600 per-step time 0.828s loss=0.267\n","I0122 09:31:05.848301 139716735563648 model_lib_v2.py:651] Step 21600 per-step time 0.828s loss=0.267\n","INFO:tensorflow:Step 21700 per-step time 0.827s loss=0.292\n","I0122 09:32:24.588021 139716735563648 model_lib_v2.py:651] Step 21700 per-step time 0.827s loss=0.292\n","INFO:tensorflow:Step 21800 per-step time 0.781s loss=0.262\n","I0122 09:33:43.611781 139716735563648 model_lib_v2.py:651] Step 21800 per-step time 0.781s loss=0.262\n","INFO:tensorflow:Step 21900 per-step time 0.717s loss=0.321\n","I0122 09:35:01.961341 139716735563648 model_lib_v2.py:651] Step 21900 per-step time 0.717s loss=0.321\n","INFO:tensorflow:Step 22000 per-step time 0.781s loss=0.280\n","I0122 09:36:22.148700 139716735563648 model_lib_v2.py:651] Step 22000 per-step time 0.781s loss=0.280\n","INFO:tensorflow:Step 22100 per-step time 0.855s loss=0.263\n","I0122 09:37:43.643799 139716735563648 model_lib_v2.py:651] Step 22100 per-step time 0.855s loss=0.263\n","INFO:tensorflow:Step 22200 per-step time 0.810s loss=0.265\n","I0122 09:39:03.479114 139716735563648 model_lib_v2.py:651] Step 22200 per-step time 0.810s loss=0.265\n","INFO:tensorflow:Step 22300 per-step time 0.794s loss=0.261\n","I0122 09:40:23.363392 139716735563648 model_lib_v2.py:651] Step 22300 per-step time 0.794s loss=0.261\n","INFO:tensorflow:Step 22400 per-step time 0.747s loss=0.282\n","I0122 09:41:45.029540 139716735563648 model_lib_v2.py:651] Step 22400 per-step time 0.747s loss=0.282\n","INFO:tensorflow:Step 22500 per-step time 0.651s loss=0.252\n","I0122 09:43:05.627233 139716735563648 model_lib_v2.py:651] Step 22500 per-step time 0.651s loss=0.252\n","INFO:tensorflow:Step 22600 per-step time 0.800s loss=0.310\n","I0122 09:44:24.790002 139716735563648 model_lib_v2.py:651] Step 22600 per-step time 0.800s loss=0.310\n","INFO:tensorflow:Step 22700 per-step time 0.779s loss=0.262\n","I0122 09:45:45.029148 139716735563648 model_lib_v2.py:651] Step 22700 per-step time 0.779s loss=0.262\n","INFO:tensorflow:Step 22800 per-step time 0.799s loss=0.286\n","I0122 09:47:03.732138 139716735563648 model_lib_v2.py:651] Step 22800 per-step time 0.799s loss=0.286\n","INFO:tensorflow:Step 22900 per-step time 0.815s loss=0.319\n","I0122 09:48:22.375355 139716735563648 model_lib_v2.py:651] Step 22900 per-step time 0.815s loss=0.319\n","INFO:tensorflow:Step 23000 per-step time 0.735s loss=0.252\n","I0122 09:49:40.990691 139716735563648 model_lib_v2.py:651] Step 23000 per-step time 0.735s loss=0.252\n","INFO:tensorflow:Step 23100 per-step time 0.698s loss=0.255\n","I0122 09:51:00.889710 139716735563648 model_lib_v2.py:651] Step 23100 per-step time 0.698s loss=0.255\n","INFO:tensorflow:Step 23200 per-step time 0.838s loss=0.267\n","I0122 09:52:20.159792 139716735563648 model_lib_v2.py:651] Step 23200 per-step time 0.838s loss=0.267\n","INFO:tensorflow:Step 23300 per-step time 0.752s loss=0.280\n","I0122 09:53:38.703675 139716735563648 model_lib_v2.py:651] Step 23300 per-step time 0.752s loss=0.280\n","INFO:tensorflow:Step 23400 per-step time 0.801s loss=0.351\n","I0122 09:54:58.092524 139716735563648 model_lib_v2.py:651] Step 23400 per-step time 0.801s loss=0.351\n","INFO:tensorflow:Step 23500 per-step time 0.767s loss=0.252\n","I0122 09:56:18.401019 139716735563648 model_lib_v2.py:651] Step 23500 per-step time 0.767s loss=0.252\n","INFO:tensorflow:Step 23600 per-step time 0.709s loss=0.245\n","I0122 09:57:40.394317 139716735563648 model_lib_v2.py:651] Step 23600 per-step time 0.709s loss=0.245\n","INFO:tensorflow:Step 23700 per-step time 0.804s loss=0.271\n","I0122 09:59:02.226459 139716735563648 model_lib_v2.py:651] Step 23700 per-step time 0.804s loss=0.271\n","INFO:tensorflow:Step 23800 per-step time 0.825s loss=0.331\n","I0122 10:00:23.828642 139716735563648 model_lib_v2.py:651] Step 23800 per-step time 0.825s loss=0.331\n","INFO:tensorflow:Step 23900 per-step time 0.809s loss=0.292\n","I0122 10:01:43.033151 139716735563648 model_lib_v2.py:651] Step 23900 per-step time 0.809s loss=0.292\n","INFO:tensorflow:Step 24000 per-step time 0.812s loss=0.305\n","I0122 10:03:02.898933 139716735563648 model_lib_v2.py:651] Step 24000 per-step time 0.812s loss=0.305\n","INFO:tensorflow:Step 24100 per-step time 0.809s loss=0.317\n","I0122 10:04:24.895206 139716735563648 model_lib_v2.py:651] Step 24100 per-step time 0.809s loss=0.317\n","INFO:tensorflow:Step 24200 per-step time 0.834s loss=0.248\n","I0122 10:05:45.725575 139716735563648 model_lib_v2.py:651] Step 24200 per-step time 0.834s loss=0.248\n","INFO:tensorflow:Step 24300 per-step time 0.881s loss=0.295\n","I0122 10:07:06.532728 139716735563648 model_lib_v2.py:651] Step 24300 per-step time 0.881s loss=0.295\n","INFO:tensorflow:Step 24400 per-step time 0.780s loss=0.327\n","I0122 10:08:26.935244 139716735563648 model_lib_v2.py:651] Step 24400 per-step time 0.780s loss=0.327\n","INFO:tensorflow:Step 24500 per-step time 0.864s loss=0.331\n","I0122 10:09:46.410983 139716735563648 model_lib_v2.py:651] Step 24500 per-step time 0.864s loss=0.331\n","INFO:tensorflow:Step 24600 per-step time 0.776s loss=0.289\n","I0122 10:11:07.654289 139716735563648 model_lib_v2.py:651] Step 24600 per-step time 0.776s loss=0.289\n","INFO:tensorflow:Step 24700 per-step time 0.802s loss=0.265\n","I0122 10:12:28.388160 139716735563648 model_lib_v2.py:651] Step 24700 per-step time 0.802s loss=0.265\n","INFO:tensorflow:Step 24800 per-step time 0.768s loss=0.302\n","I0122 10:13:49.448817 139716735563648 model_lib_v2.py:651] Step 24800 per-step time 0.768s loss=0.302\n","INFO:tensorflow:Step 24900 per-step time 0.906s loss=0.270\n","I0122 10:15:10.059465 139716735563648 model_lib_v2.py:651] Step 24900 per-step time 0.906s loss=0.270\n","INFO:tensorflow:Step 25000 per-step time 0.742s loss=0.295\n","I0122 10:16:31.473199 139716735563648 model_lib_v2.py:651] Step 25000 per-step time 0.742s loss=0.295\n","INFO:tensorflow:Step 25100 per-step time 0.808s loss=0.240\n","I0122 10:17:52.833347 139716735563648 model_lib_v2.py:651] Step 25100 per-step time 0.808s loss=0.240\n","INFO:tensorflow:Step 25200 per-step time 0.864s loss=0.242\n","I0122 10:19:14.408749 139716735563648 model_lib_v2.py:651] Step 25200 per-step time 0.864s loss=0.242\n","INFO:tensorflow:Step 25300 per-step time 0.853s loss=0.242\n","I0122 10:20:36.599930 139716735563648 model_lib_v2.py:651] Step 25300 per-step time 0.853s loss=0.242\n","INFO:tensorflow:Step 25400 per-step time 0.894s loss=0.252\n","I0122 10:21:59.078753 139716735563648 model_lib_v2.py:651] Step 25400 per-step time 0.894s loss=0.252\n","INFO:tensorflow:Step 25500 per-step time 0.739s loss=0.217\n","I0122 10:23:20.455072 139716735563648 model_lib_v2.py:651] Step 25500 per-step time 0.739s loss=0.217\n","INFO:tensorflow:Step 25600 per-step time 0.787s loss=0.249\n","I0122 10:24:41.960258 139716735563648 model_lib_v2.py:651] Step 25600 per-step time 0.787s loss=0.249\n","INFO:tensorflow:Step 25700 per-step time 0.860s loss=0.309\n","I0122 10:26:03.216314 139716735563648 model_lib_v2.py:651] Step 25700 per-step time 0.860s loss=0.309\n","INFO:tensorflow:Step 25800 per-step time 0.831s loss=0.231\n","I0122 10:27:24.405007 139716735563648 model_lib_v2.py:651] Step 25800 per-step time 0.831s loss=0.231\n","INFO:tensorflow:Step 25900 per-step time 0.869s loss=0.256\n","I0122 10:28:45.346299 139716735563648 model_lib_v2.py:651] Step 25900 per-step time 0.869s loss=0.256\n","INFO:tensorflow:Step 26000 per-step time 0.867s loss=0.283\n","I0122 10:30:05.983672 139716735563648 model_lib_v2.py:651] Step 26000 per-step time 0.867s loss=0.283\n","INFO:tensorflow:Step 26100 per-step time 0.766s loss=0.244\n","I0122 10:31:27.674945 139716735563648 model_lib_v2.py:651] Step 26100 per-step time 0.766s loss=0.244\n","INFO:tensorflow:Step 26200 per-step time 0.847s loss=0.263\n","I0122 10:32:48.656118 139716735563648 model_lib_v2.py:651] Step 26200 per-step time 0.847s loss=0.263\n","INFO:tensorflow:Step 26300 per-step time 0.806s loss=0.249\n","I0122 10:34:09.609285 139716735563648 model_lib_v2.py:651] Step 26300 per-step time 0.806s loss=0.249\n","INFO:tensorflow:Step 26400 per-step time 0.759s loss=0.233\n","I0122 10:35:30.191726 139716735563648 model_lib_v2.py:651] Step 26400 per-step time 0.759s loss=0.233\n","INFO:tensorflow:Step 26500 per-step time 0.829s loss=0.314\n","I0122 10:36:50.660759 139716735563648 model_lib_v2.py:651] Step 26500 per-step time 0.829s loss=0.314\n","INFO:tensorflow:Step 26600 per-step time 0.828s loss=0.262\n","I0122 10:38:12.135561 139716735563648 model_lib_v2.py:651] Step 26600 per-step time 0.828s loss=0.262\n","INFO:tensorflow:Step 26700 per-step time 0.805s loss=0.247\n","I0122 10:39:32.890047 139716735563648 model_lib_v2.py:651] Step 26700 per-step time 0.805s loss=0.247\n","INFO:tensorflow:Step 26800 per-step time 0.783s loss=0.242\n","I0122 10:40:53.320840 139716735563648 model_lib_v2.py:651] Step 26800 per-step time 0.783s loss=0.242\n","INFO:tensorflow:Step 26900 per-step time 0.842s loss=0.339\n","I0122 10:42:13.638172 139716735563648 model_lib_v2.py:651] Step 26900 per-step time 0.842s loss=0.339\n","INFO:tensorflow:Step 27000 per-step time 0.688s loss=0.261\n","I0122 10:43:33.829472 139716735563648 model_lib_v2.py:651] Step 27000 per-step time 0.688s loss=0.261\n","INFO:tensorflow:Step 27100 per-step time 0.858s loss=0.292\n","I0122 10:44:55.595944 139716735563648 model_lib_v2.py:651] Step 27100 per-step time 0.858s loss=0.292\n","INFO:tensorflow:Step 27200 per-step time 0.845s loss=0.243\n","I0122 10:46:15.529747 139716735563648 model_lib_v2.py:651] Step 27200 per-step time 0.845s loss=0.243\n","INFO:tensorflow:Step 27300 per-step time 0.864s loss=0.242\n","I0122 10:47:35.759659 139716735563648 model_lib_v2.py:651] Step 27300 per-step time 0.864s loss=0.242\n","INFO:tensorflow:Step 27400 per-step time 0.769s loss=0.319\n","I0122 10:48:56.443973 139716735563648 model_lib_v2.py:651] Step 27400 per-step time 0.769s loss=0.319\n","INFO:tensorflow:Step 27500 per-step time 0.789s loss=0.464\n","I0122 10:50:16.664033 139716735563648 model_lib_v2.py:651] Step 27500 per-step time 0.789s loss=0.464\n","INFO:tensorflow:Step 27600 per-step time 0.812s loss=0.261\n","I0122 10:51:36.080237 139716735563648 model_lib_v2.py:651] Step 27600 per-step time 0.812s loss=0.261\n","INFO:tensorflow:Step 27700 per-step time 0.712s loss=0.263\n","I0122 10:52:55.948624 139716735563648 model_lib_v2.py:651] Step 27700 per-step time 0.712s loss=0.263\n","INFO:tensorflow:Step 27800 per-step time 0.820s loss=0.236\n","I0122 10:54:16.709707 139716735563648 model_lib_v2.py:651] Step 27800 per-step time 0.820s loss=0.236\n","INFO:tensorflow:Step 27900 per-step time 0.804s loss=0.273\n","I0122 10:55:36.530383 139716735563648 model_lib_v2.py:651] Step 27900 per-step time 0.804s loss=0.273\n","INFO:tensorflow:Step 28000 per-step time 0.802s loss=0.296\n","I0122 10:56:56.755393 139716735563648 model_lib_v2.py:651] Step 28000 per-step time 0.802s loss=0.296\n","INFO:tensorflow:Step 28100 per-step time 0.859s loss=0.246\n","I0122 10:58:17.599211 139716735563648 model_lib_v2.py:651] Step 28100 per-step time 0.859s loss=0.246\n","INFO:tensorflow:Step 28200 per-step time 0.818s loss=0.216\n","I0122 10:59:38.536778 139716735563648 model_lib_v2.py:651] Step 28200 per-step time 0.818s loss=0.216\n","INFO:tensorflow:Step 28300 per-step time 0.895s loss=0.284\n","I0122 11:00:59.565186 139716735563648 model_lib_v2.py:651] Step 28300 per-step time 0.895s loss=0.284\n","INFO:tensorflow:Step 28400 per-step time 0.777s loss=0.230\n","I0122 11:02:20.147402 139716735563648 model_lib_v2.py:651] Step 28400 per-step time 0.777s loss=0.230\n","INFO:tensorflow:Step 28500 per-step time 0.782s loss=0.252\n","I0122 11:03:40.955403 139716735563648 model_lib_v2.py:651] Step 28500 per-step time 0.782s loss=0.252\n","INFO:tensorflow:Step 28600 per-step time 0.830s loss=0.305\n","I0122 11:05:02.415700 139716735563648 model_lib_v2.py:651] Step 28600 per-step time 0.830s loss=0.305\n","INFO:tensorflow:Step 28700 per-step time 0.822s loss=0.233\n","I0122 11:06:24.211924 139716735563648 model_lib_v2.py:651] Step 28700 per-step time 0.822s loss=0.233\n","INFO:tensorflow:Step 28800 per-step time 0.878s loss=0.255\n","I0122 11:07:45.096451 139716735563648 model_lib_v2.py:651] Step 28800 per-step time 0.878s loss=0.255\n","INFO:tensorflow:Step 28900 per-step time 0.861s loss=0.276\n","I0122 11:09:06.559276 139716735563648 model_lib_v2.py:651] Step 28900 per-step time 0.861s loss=0.276\n","INFO:tensorflow:Step 29000 per-step time 0.736s loss=0.262\n","I0122 11:10:27.043716 139716735563648 model_lib_v2.py:651] Step 29000 per-step time 0.736s loss=0.262\n","INFO:tensorflow:Step 29100 per-step time 0.869s loss=0.256\n","I0122 11:11:49.932866 139716735563648 model_lib_v2.py:651] Step 29100 per-step time 0.869s loss=0.256\n","INFO:tensorflow:Step 29200 per-step time 0.833s loss=0.327\n","I0122 11:13:10.002340 139716735563648 model_lib_v2.py:651] Step 29200 per-step time 0.833s loss=0.327\n","INFO:tensorflow:Step 29300 per-step time 0.781s loss=0.249\n","I0122 11:14:31.416096 139716735563648 model_lib_v2.py:651] Step 29300 per-step time 0.781s loss=0.249\n","INFO:tensorflow:Step 29400 per-step time 0.847s loss=0.252\n","I0122 11:15:52.440341 139716735563648 model_lib_v2.py:651] Step 29400 per-step time 0.847s loss=0.252\n","INFO:tensorflow:Step 29500 per-step time 0.860s loss=0.232\n","I0122 11:17:13.770814 139716735563648 model_lib_v2.py:651] Step 29500 per-step time 0.860s loss=0.232\n","INFO:tensorflow:Step 29600 per-step time 0.778s loss=0.340\n","I0122 11:18:34.259609 139716735563648 model_lib_v2.py:651] Step 29600 per-step time 0.778s loss=0.340\n","INFO:tensorflow:Step 29700 per-step time 0.888s loss=0.274\n","I0122 11:19:56.046696 139716735563648 model_lib_v2.py:651] Step 29700 per-step time 0.888s loss=0.274\n","INFO:tensorflow:Step 29800 per-step time 0.814s loss=0.229\n","I0122 11:21:18.181361 139716735563648 model_lib_v2.py:651] Step 29800 per-step time 0.814s loss=0.229\n","INFO:tensorflow:Step 29900 per-step time 0.802s loss=0.320\n","I0122 11:22:39.962085 139716735563648 model_lib_v2.py:651] Step 29900 per-step time 0.802s loss=0.320\n","INFO:tensorflow:Step 30000 per-step time 0.801s loss=0.248\n","I0122 11:23:59.934001 139716735563648 model_lib_v2.py:651] Step 30000 per-step time 0.801s loss=0.248\n","INFO:tensorflow:Step 30100 per-step time 0.857s loss=0.219\n","I0122 11:25:20.838811 139716735563648 model_lib_v2.py:651] Step 30100 per-step time 0.857s loss=0.219\n","INFO:tensorflow:Step 30200 per-step time 0.795s loss=0.224\n","I0122 11:26:41.144809 139716735563648 model_lib_v2.py:651] Step 30200 per-step time 0.795s loss=0.224\n","INFO:tensorflow:Step 30300 per-step time 0.751s loss=0.267\n","I0122 11:28:00.596596 139716735563648 model_lib_v2.py:651] Step 30300 per-step time 0.751s loss=0.267\n","INFO:tensorflow:Step 30400 per-step time 0.691s loss=0.279\n","I0122 11:29:20.712784 139716735563648 model_lib_v2.py:651] Step 30400 per-step time 0.691s loss=0.279\n","INFO:tensorflow:Step 30500 per-step time 0.732s loss=0.252\n","I0122 11:30:41.478587 139716735563648 model_lib_v2.py:651] Step 30500 per-step time 0.732s loss=0.252\n","INFO:tensorflow:Step 30600 per-step time 0.847s loss=0.366\n","I0122 11:32:02.367532 139716735563648 model_lib_v2.py:651] Step 30600 per-step time 0.847s loss=0.366\n","INFO:tensorflow:Step 30700 per-step time 0.838s loss=0.339\n","I0122 11:33:23.116662 139716735563648 model_lib_v2.py:651] Step 30700 per-step time 0.838s loss=0.339\n","INFO:tensorflow:Step 30800 per-step time 0.829s loss=0.251\n","I0122 11:34:44.324530 139716735563648 model_lib_v2.py:651] Step 30800 per-step time 0.829s loss=0.251\n","INFO:tensorflow:Step 30900 per-step time 0.826s loss=0.292\n","I0122 11:36:05.275689 139716735563648 model_lib_v2.py:651] Step 30900 per-step time 0.826s loss=0.292\n","INFO:tensorflow:Step 31000 per-step time 0.775s loss=0.282\n","I0122 11:37:26.776357 139716735563648 model_lib_v2.py:651] Step 31000 per-step time 0.775s loss=0.282\n","INFO:tensorflow:Step 31100 per-step time 0.740s loss=0.280\n","I0122 11:38:48.463661 139716735563648 model_lib_v2.py:651] Step 31100 per-step time 0.740s loss=0.280\n","INFO:tensorflow:Step 31200 per-step time 0.839s loss=0.245\n","I0122 11:40:09.516470 139716735563648 model_lib_v2.py:651] Step 31200 per-step time 0.839s loss=0.245\n","INFO:tensorflow:Step 31300 per-step time 0.887s loss=0.282\n","I0122 11:41:31.510889 139716735563648 model_lib_v2.py:651] Step 31300 per-step time 0.887s loss=0.282\n","INFO:tensorflow:Step 31400 per-step time 0.843s loss=0.282\n","I0122 11:42:52.326949 139716735563648 model_lib_v2.py:651] Step 31400 per-step time 0.843s loss=0.282\n","INFO:tensorflow:Step 31500 per-step time 0.918s loss=0.229\n","I0122 11:44:14.043992 139716735563648 model_lib_v2.py:651] Step 31500 per-step time 0.918s loss=0.229\n","INFO:tensorflow:Step 31600 per-step time 0.827s loss=0.267\n","I0122 11:45:35.994778 139716735563648 model_lib_v2.py:651] Step 31600 per-step time 0.827s loss=0.267\n","INFO:tensorflow:Step 31700 per-step time 0.776s loss=0.262\n","I0122 11:46:55.653392 139716735563648 model_lib_v2.py:651] Step 31700 per-step time 0.776s loss=0.262\n","INFO:tensorflow:Step 31800 per-step time 0.869s loss=0.254\n","I0122 11:48:17.365534 139716735563648 model_lib_v2.py:651] Step 31800 per-step time 0.869s loss=0.254\n","INFO:tensorflow:Step 31900 per-step time 0.820s loss=0.307\n","I0122 11:49:39.378431 139716735563648 model_lib_v2.py:651] Step 31900 per-step time 0.820s loss=0.307\n","INFO:tensorflow:Step 32000 per-step time 0.751s loss=0.274\n","I0122 11:51:01.483086 139716735563648 model_lib_v2.py:651] Step 32000 per-step time 0.751s loss=0.274\n","INFO:tensorflow:Step 32100 per-step time 0.804s loss=0.200\n","I0122 11:52:24.157950 139716735563648 model_lib_v2.py:651] Step 32100 per-step time 0.804s loss=0.200\n","INFO:tensorflow:Step 32200 per-step time 0.827s loss=0.257\n","I0122 11:53:44.722707 139716735563648 model_lib_v2.py:651] Step 32200 per-step time 0.827s loss=0.257\n","INFO:tensorflow:Step 32300 per-step time 0.827s loss=0.282\n","I0122 11:55:04.898005 139716735563648 model_lib_v2.py:651] Step 32300 per-step time 0.827s loss=0.282\n","INFO:tensorflow:Step 32400 per-step time 0.812s loss=0.216\n","I0122 11:56:24.875056 139716735563648 model_lib_v2.py:651] Step 32400 per-step time 0.812s loss=0.216\n","INFO:tensorflow:Step 32500 per-step time 0.777s loss=0.238\n","I0122 11:57:44.619587 139716735563648 model_lib_v2.py:651] Step 32500 per-step time 0.777s loss=0.238\n","INFO:tensorflow:Step 32600 per-step time 0.751s loss=0.249\n","I0122 11:59:05.519428 139716735563648 model_lib_v2.py:651] Step 32600 per-step time 0.751s loss=0.249\n","INFO:tensorflow:Step 32700 per-step time 0.855s loss=0.276\n","I0122 12:00:25.203108 139716735563648 model_lib_v2.py:651] Step 32700 per-step time 0.855s loss=0.276\n","INFO:tensorflow:Step 32800 per-step time 0.768s loss=0.248\n","I0122 12:01:45.042715 139716735563648 model_lib_v2.py:651] Step 32800 per-step time 0.768s loss=0.248\n","INFO:tensorflow:Step 32900 per-step time 0.781s loss=0.267\n","I0122 12:03:06.211279 139716735563648 model_lib_v2.py:651] Step 32900 per-step time 0.781s loss=0.267\n","INFO:tensorflow:Step 33000 per-step time 0.855s loss=0.232\n","I0122 12:04:26.783306 139716735563648 model_lib_v2.py:651] Step 33000 per-step time 0.855s loss=0.232\n","INFO:tensorflow:Step 33100 per-step time 0.804s loss=0.328\n","I0122 12:05:47.780306 139716735563648 model_lib_v2.py:651] Step 33100 per-step time 0.804s loss=0.328\n","INFO:tensorflow:Step 33200 per-step time 0.712s loss=0.229\n","I0122 12:07:08.602371 139716735563648 model_lib_v2.py:651] Step 33200 per-step time 0.712s loss=0.229\n","INFO:tensorflow:Step 33300 per-step time 0.676s loss=0.261\n","I0122 12:08:28.466740 139716735563648 model_lib_v2.py:651] Step 33300 per-step time 0.676s loss=0.261\n","INFO:tensorflow:Step 33400 per-step time 0.811s loss=0.282\n","I0122 12:09:48.471376 139716735563648 model_lib_v2.py:651] Step 33400 per-step time 0.811s loss=0.282\n","INFO:tensorflow:Step 33500 per-step time 0.825s loss=0.287\n","I0122 12:11:08.635781 139716735563648 model_lib_v2.py:651] Step 33500 per-step time 0.825s loss=0.287\n","INFO:tensorflow:Step 33600 per-step time 0.828s loss=0.235\n","I0122 12:12:29.265172 139716735563648 model_lib_v2.py:651] Step 33600 per-step time 0.828s loss=0.235\n","INFO:tensorflow:Step 33700 per-step time 0.784s loss=0.269\n","I0122 12:13:49.106903 139716735563648 model_lib_v2.py:651] Step 33700 per-step time 0.784s loss=0.269\n","INFO:tensorflow:Step 33800 per-step time 0.816s loss=0.330\n","I0122 12:15:09.751906 139716735563648 model_lib_v2.py:651] Step 33800 per-step time 0.816s loss=0.330\n","INFO:tensorflow:Step 33900 per-step time 0.774s loss=0.281\n","I0122 12:16:29.872617 139716735563648 model_lib_v2.py:651] Step 33900 per-step time 0.774s loss=0.281\n","INFO:tensorflow:Step 34000 per-step time 0.837s loss=0.230\n","I0122 12:17:49.171363 139716735563648 model_lib_v2.py:651] Step 34000 per-step time 0.837s loss=0.230\n","INFO:tensorflow:Step 34100 per-step time 0.777s loss=0.244\n","I0122 12:19:09.360352 139716735563648 model_lib_v2.py:651] Step 34100 per-step time 0.777s loss=0.244\n","INFO:tensorflow:Step 34200 per-step time 0.771s loss=0.238\n","I0122 12:20:29.469540 139716735563648 model_lib_v2.py:651] Step 34200 per-step time 0.771s loss=0.238\n","INFO:tensorflow:Step 34300 per-step time 0.771s loss=0.255\n","I0122 12:21:48.738172 139716735563648 model_lib_v2.py:651] Step 34300 per-step time 0.771s loss=0.255\n","INFO:tensorflow:Step 34400 per-step time 0.725s loss=0.223\n","I0122 12:23:06.939435 139716735563648 model_lib_v2.py:651] Step 34400 per-step time 0.725s loss=0.223\n","INFO:tensorflow:Step 34500 per-step time 0.813s loss=0.320\n","I0122 12:24:26.914748 139716735563648 model_lib_v2.py:651] Step 34500 per-step time 0.813s loss=0.320\n","INFO:tensorflow:Step 34600 per-step time 0.892s loss=0.261\n","I0122 12:25:46.020132 139716735563648 model_lib_v2.py:651] Step 34600 per-step time 0.892s loss=0.261\n","INFO:tensorflow:Step 34700 per-step time 0.750s loss=0.273\n","I0122 12:27:05.997536 139716735563648 model_lib_v2.py:651] Step 34700 per-step time 0.750s loss=0.273\n","INFO:tensorflow:Step 34800 per-step time 0.814s loss=0.240\n","I0122 12:28:24.506966 139716735563648 model_lib_v2.py:651] Step 34800 per-step time 0.814s loss=0.240\n","INFO:tensorflow:Step 34900 per-step time 0.805s loss=0.243\n","I0122 12:29:44.001993 139716735563648 model_lib_v2.py:651] Step 34900 per-step time 0.805s loss=0.243\n","INFO:tensorflow:Step 35000 per-step time 0.829s loss=0.291\n","I0122 12:31:03.672980 139716735563648 model_lib_v2.py:651] Step 35000 per-step time 0.829s loss=0.291\n","INFO:tensorflow:Step 35100 per-step time 0.757s loss=0.247\n","I0122 12:32:24.336817 139716735563648 model_lib_v2.py:651] Step 35100 per-step time 0.757s loss=0.247\n","INFO:tensorflow:Step 35200 per-step time 0.833s loss=0.236\n","I0122 12:33:43.506083 139716735563648 model_lib_v2.py:651] Step 35200 per-step time 0.833s loss=0.236\n","INFO:tensorflow:Step 35300 per-step time 0.718s loss=0.234\n","I0122 12:35:02.728774 139716735563648 model_lib_v2.py:651] Step 35300 per-step time 0.718s loss=0.234\n","INFO:tensorflow:Step 35400 per-step time 0.774s loss=0.235\n","I0122 12:36:21.957575 139716735563648 model_lib_v2.py:651] Step 35400 per-step time 0.774s loss=0.235\n","INFO:tensorflow:Step 35500 per-step time 0.778s loss=0.259\n","I0122 12:37:40.595614 139716735563648 model_lib_v2.py:651] Step 35500 per-step time 0.778s loss=0.259\n","INFO:tensorflow:Step 35600 per-step time 0.744s loss=0.297\n","I0122 12:39:00.003999 139716735563648 model_lib_v2.py:651] Step 35600 per-step time 0.744s loss=0.297\n","INFO:tensorflow:Step 35700 per-step time 0.791s loss=0.271\n","I0122 12:40:18.873001 139716735563648 model_lib_v2.py:651] Step 35700 per-step time 0.791s loss=0.271\n","INFO:tensorflow:Step 35800 per-step time 0.783s loss=0.287\n","I0122 12:41:37.743684 139716735563648 model_lib_v2.py:651] Step 35800 per-step time 0.783s loss=0.287\n","INFO:tensorflow:Step 35900 per-step time 0.832s loss=0.312\n","I0122 12:42:56.246709 139716735563648 model_lib_v2.py:651] Step 35900 per-step time 0.832s loss=0.312\n","INFO:tensorflow:Step 36000 per-step time 0.785s loss=0.278\n","I0122 12:44:16.186110 139716735563648 model_lib_v2.py:651] Step 36000 per-step time 0.785s loss=0.278\n","INFO:tensorflow:Step 36100 per-step time 0.783s loss=0.241\n","I0122 12:45:36.121489 139716735563648 model_lib_v2.py:651] Step 36100 per-step time 0.783s loss=0.241\n","INFO:tensorflow:Step 36200 per-step time 0.784s loss=0.253\n","I0122 12:46:55.306734 139716735563648 model_lib_v2.py:651] Step 36200 per-step time 0.784s loss=0.253\n","INFO:tensorflow:Step 36300 per-step time 0.822s loss=0.219\n","I0122 12:48:13.335497 139716735563648 model_lib_v2.py:651] Step 36300 per-step time 0.822s loss=0.219\n","INFO:tensorflow:Step 36400 per-step time 0.775s loss=0.293\n","I0122 12:49:32.439639 139716735563648 model_lib_v2.py:651] Step 36400 per-step time 0.775s loss=0.293\n","INFO:tensorflow:Step 36500 per-step time 0.812s loss=0.248\n","I0122 12:50:51.443627 139716735563648 model_lib_v2.py:651] Step 36500 per-step time 0.812s loss=0.248\n","INFO:tensorflow:Step 36600 per-step time 0.810s loss=0.279\n","I0122 12:52:11.198579 139716735563648 model_lib_v2.py:651] Step 36600 per-step time 0.810s loss=0.279\n","INFO:tensorflow:Step 36700 per-step time 0.812s loss=0.250\n","I0122 12:53:30.421255 139716735563648 model_lib_v2.py:651] Step 36700 per-step time 0.812s loss=0.250\n","INFO:tensorflow:Step 36800 per-step time 0.872s loss=0.267\n","I0122 12:54:49.184593 139716735563648 model_lib_v2.py:651] Step 36800 per-step time 0.872s loss=0.267\n","INFO:tensorflow:Step 36900 per-step time 0.748s loss=0.246\n","I0122 12:56:07.871006 139716735563648 model_lib_v2.py:651] Step 36900 per-step time 0.748s loss=0.246\n","INFO:tensorflow:Step 37000 per-step time 0.764s loss=0.228\n","I0122 12:57:27.492772 139716735563648 model_lib_v2.py:651] Step 37000 per-step time 0.764s loss=0.228\n","INFO:tensorflow:Step 37100 per-step time 0.827s loss=0.225\n","I0122 12:58:47.188912 139716735563648 model_lib_v2.py:651] Step 37100 per-step time 0.827s loss=0.225\n","INFO:tensorflow:Step 37200 per-step time 0.721s loss=0.233\n","I0122 13:00:05.988743 139716735563648 model_lib_v2.py:651] Step 37200 per-step time 0.721s loss=0.233\n","INFO:tensorflow:Step 37300 per-step time 0.733s loss=0.227\n","I0122 13:01:24.484249 139716735563648 model_lib_v2.py:651] Step 37300 per-step time 0.733s loss=0.227\n","INFO:tensorflow:Step 37400 per-step time 0.773s loss=0.253\n","I0122 13:02:43.871423 139716735563648 model_lib_v2.py:651] Step 37400 per-step time 0.773s loss=0.253\n","INFO:tensorflow:Step 37500 per-step time 0.777s loss=0.229\n","I0122 13:04:03.179969 139716735563648 model_lib_v2.py:651] Step 37500 per-step time 0.777s loss=0.229\n","INFO:tensorflow:Step 37600 per-step time 0.813s loss=0.267\n","I0122 13:05:21.267669 139716735563648 model_lib_v2.py:651] Step 37600 per-step time 0.813s loss=0.267\n","INFO:tensorflow:Step 37700 per-step time 0.891s loss=0.248\n","I0122 13:06:40.587335 139716735563648 model_lib_v2.py:651] Step 37700 per-step time 0.891s loss=0.248\n","INFO:tensorflow:Step 37800 per-step time 0.767s loss=0.288\n","I0122 13:07:58.225357 139716735563648 model_lib_v2.py:651] Step 37800 per-step time 0.767s loss=0.288\n","INFO:tensorflow:Step 37900 per-step time 0.761s loss=0.255\n","I0122 13:09:16.838528 139716735563648 model_lib_v2.py:651] Step 37900 per-step time 0.761s loss=0.255\n","INFO:tensorflow:Step 38000 per-step time 0.748s loss=0.248\n","I0122 13:10:34.974274 139716735563648 model_lib_v2.py:651] Step 38000 per-step time 0.748s loss=0.248\n","INFO:tensorflow:Step 38100 per-step time 0.767s loss=0.243\n","I0122 13:11:54.155827 139716735563648 model_lib_v2.py:651] Step 38100 per-step time 0.767s loss=0.243\n","INFO:tensorflow:Step 38200 per-step time 0.805s loss=0.240\n","I0122 13:13:12.831063 139716735563648 model_lib_v2.py:651] Step 38200 per-step time 0.805s loss=0.240\n","INFO:tensorflow:Step 38300 per-step time 0.816s loss=0.230\n","I0122 13:14:31.328807 139716735563648 model_lib_v2.py:651] Step 38300 per-step time 0.816s loss=0.230\n","INFO:tensorflow:Step 38400 per-step time 0.782s loss=0.197\n","I0122 13:15:49.712482 139716735563648 model_lib_v2.py:651] Step 38400 per-step time 0.782s loss=0.197\n","INFO:tensorflow:Step 38500 per-step time 0.855s loss=0.248\n","I0122 13:17:08.693355 139716735563648 model_lib_v2.py:651] Step 38500 per-step time 0.855s loss=0.248\n","INFO:tensorflow:Step 38600 per-step time 0.713s loss=0.410\n","I0122 13:18:27.423754 139716735563648 model_lib_v2.py:651] Step 38600 per-step time 0.713s loss=0.410\n","INFO:tensorflow:Step 38700 per-step time 0.815s loss=0.263\n","I0122 13:19:46.484735 139716735563648 model_lib_v2.py:651] Step 38700 per-step time 0.815s loss=0.263\n","INFO:tensorflow:Step 38800 per-step time 0.869s loss=0.296\n","I0122 13:21:05.226269 139716735563648 model_lib_v2.py:651] Step 38800 per-step time 0.869s loss=0.296\n","INFO:tensorflow:Step 38900 per-step time 0.823s loss=0.312\n","I0122 13:22:24.348525 139716735563648 model_lib_v2.py:651] Step 38900 per-step time 0.823s loss=0.312\n","INFO:tensorflow:Step 39000 per-step time 0.783s loss=0.243\n","I0122 13:23:43.169159 139716735563648 model_lib_v2.py:651] Step 39000 per-step time 0.783s loss=0.243\n","INFO:tensorflow:Step 39100 per-step time 0.794s loss=0.252\n","I0122 13:25:02.693325 139716735563648 model_lib_v2.py:651] Step 39100 per-step time 0.794s loss=0.252\n","INFO:tensorflow:Step 39200 per-step time 0.793s loss=0.194\n","I0122 13:26:20.673712 139716735563648 model_lib_v2.py:651] Step 39200 per-step time 0.793s loss=0.194\n","INFO:tensorflow:Step 39300 per-step time 0.828s loss=0.296\n","I0122 13:27:39.954685 139716735563648 model_lib_v2.py:651] Step 39300 per-step time 0.828s loss=0.296\n","INFO:tensorflow:Step 39400 per-step time 0.758s loss=0.220\n","I0122 13:28:58.980022 139716735563648 model_lib_v2.py:651] Step 39400 per-step time 0.758s loss=0.220\n","INFO:tensorflow:Step 39500 per-step time 0.807s loss=0.232\n","I0122 13:30:17.566229 139716735563648 model_lib_v2.py:651] Step 39500 per-step time 0.807s loss=0.232\n","INFO:tensorflow:Step 39600 per-step time 0.735s loss=0.229\n","I0122 13:31:37.145015 139716735563648 model_lib_v2.py:651] Step 39600 per-step time 0.735s loss=0.229\n","INFO:tensorflow:Step 39700 per-step time 0.817s loss=0.232\n","I0122 13:32:55.770755 139716735563648 model_lib_v2.py:651] Step 39700 per-step time 0.817s loss=0.232\n","INFO:tensorflow:Step 39800 per-step time 0.854s loss=0.253\n","I0122 13:34:13.106583 139716735563648 model_lib_v2.py:651] Step 39800 per-step time 0.854s loss=0.253\n","INFO:tensorflow:Step 39900 per-step time 0.724s loss=0.267\n","I0122 13:35:31.135696 139716735563648 model_lib_v2.py:651] Step 39900 per-step time 0.724s loss=0.267\n","INFO:tensorflow:Step 40000 per-step time 0.700s loss=0.252\n","I0122 13:36:49.742401 139716735563648 model_lib_v2.py:651] Step 40000 per-step time 0.700s loss=0.252\n","INFO:tensorflow:Step 40100 per-step time 0.797s loss=0.270\n","I0122 13:38:09.164569 139716735563648 model_lib_v2.py:651] Step 40100 per-step time 0.797s loss=0.270\n","INFO:tensorflow:Step 40200 per-step time 0.824s loss=0.289\n","I0122 13:39:27.218213 139716735563648 model_lib_v2.py:651] Step 40200 per-step time 0.824s loss=0.289\n","INFO:tensorflow:Step 40300 per-step time 0.821s loss=0.355\n","I0122 13:40:44.692214 139716735563648 model_lib_v2.py:651] Step 40300 per-step time 0.821s loss=0.355\n","INFO:tensorflow:Step 40400 per-step time 0.825s loss=0.211\n","I0122 13:42:03.123835 139716735563648 model_lib_v2.py:651] Step 40400 per-step time 0.825s loss=0.211\n","INFO:tensorflow:Step 40500 per-step time 0.743s loss=0.247\n","I0122 13:43:20.554368 139716735563648 model_lib_v2.py:651] Step 40500 per-step time 0.743s loss=0.247\n","INFO:tensorflow:Step 40600 per-step time 0.766s loss=0.263\n","I0122 13:44:39.685457 139716735563648 model_lib_v2.py:651] Step 40600 per-step time 0.766s loss=0.263\n","INFO:tensorflow:Step 40700 per-step time 0.741s loss=0.238\n","I0122 13:45:57.719659 139716735563648 model_lib_v2.py:651] Step 40700 per-step time 0.741s loss=0.238\n","INFO:tensorflow:Step 40800 per-step time 0.833s loss=0.226\n","I0122 13:47:16.096467 139716735563648 model_lib_v2.py:651] Step 40800 per-step time 0.833s loss=0.226\n","INFO:tensorflow:Step 40900 per-step time 0.809s loss=0.284\n","I0122 13:48:34.353048 139716735563648 model_lib_v2.py:651] Step 40900 per-step time 0.809s loss=0.284\n","INFO:tensorflow:Step 41000 per-step time 0.788s loss=0.227\n","I0122 13:49:52.031714 139716735563648 model_lib_v2.py:651] Step 41000 per-step time 0.788s loss=0.227\n","INFO:tensorflow:Step 41100 per-step time 0.800s loss=0.296\n","I0122 13:51:10.285666 139716735563648 model_lib_v2.py:651] Step 41100 per-step time 0.800s loss=0.296\n","INFO:tensorflow:Step 41200 per-step time 0.767s loss=0.278\n","I0122 13:52:28.761772 139716735563648 model_lib_v2.py:651] Step 41200 per-step time 0.767s loss=0.278\n","INFO:tensorflow:Step 41300 per-step time 0.713s loss=0.252\n","I0122 13:53:46.347929 139716735563648 model_lib_v2.py:651] Step 41300 per-step time 0.713s loss=0.252\n","INFO:tensorflow:Step 41400 per-step time 0.788s loss=0.254\n","I0122 13:55:04.036561 139716735563648 model_lib_v2.py:651] Step 41400 per-step time 0.788s loss=0.254\n","INFO:tensorflow:Step 41500 per-step time 0.766s loss=0.288\n","I0122 13:56:22.296523 139716735563648 model_lib_v2.py:651] Step 41500 per-step time 0.766s loss=0.288\n","INFO:tensorflow:Step 41600 per-step time 0.840s loss=0.241\n","I0122 13:57:38.985489 139716735563648 model_lib_v2.py:651] Step 41600 per-step time 0.840s loss=0.241\n","INFO:tensorflow:Step 41700 per-step time 0.851s loss=0.231\n","I0122 13:58:56.907181 139716735563648 model_lib_v2.py:651] Step 41700 per-step time 0.851s loss=0.231\n","INFO:tensorflow:Step 41800 per-step time 0.825s loss=0.312\n","I0122 14:00:14.605149 139716735563648 model_lib_v2.py:651] Step 41800 per-step time 0.825s loss=0.312\n","INFO:tensorflow:Step 41900 per-step time 0.788s loss=0.226\n","I0122 14:01:32.289650 139716735563648 model_lib_v2.py:651] Step 41900 per-step time 0.788s loss=0.226\n","INFO:tensorflow:Step 42000 per-step time 0.737s loss=0.233\n","I0122 14:02:50.043465 139716735563648 model_lib_v2.py:651] Step 42000 per-step time 0.737s loss=0.233\n","INFO:tensorflow:Step 42100 per-step time 0.820s loss=0.263\n","I0122 14:04:08.296777 139716735563648 model_lib_v2.py:651] Step 42100 per-step time 0.820s loss=0.263\n","INFO:tensorflow:Step 42200 per-step time 0.760s loss=0.240\n","I0122 14:05:25.666686 139716735563648 model_lib_v2.py:651] Step 42200 per-step time 0.760s loss=0.240\n","INFO:tensorflow:Step 42300 per-step time 0.852s loss=0.255\n","I0122 14:06:43.756270 139716735563648 model_lib_v2.py:651] Step 42300 per-step time 0.852s loss=0.255\n","INFO:tensorflow:Step 42400 per-step time 0.838s loss=0.237\n","I0122 14:08:02.093749 139716735563648 model_lib_v2.py:651] Step 42400 per-step time 0.838s loss=0.237\n","INFO:tensorflow:Step 42500 per-step time 0.755s loss=0.244\n","I0122 14:09:20.171784 139716735563648 model_lib_v2.py:651] Step 42500 per-step time 0.755s loss=0.244\n","INFO:tensorflow:Step 42600 per-step time 0.854s loss=0.216\n","I0122 14:10:38.227090 139716735563648 model_lib_v2.py:651] Step 42600 per-step time 0.854s loss=0.216\n","INFO:tensorflow:Step 42700 per-step time 0.790s loss=0.233\n","I0122 14:11:56.547016 139716735563648 model_lib_v2.py:651] Step 42700 per-step time 0.790s loss=0.233\n","INFO:tensorflow:Step 42800 per-step time 0.776s loss=0.237\n","I0122 14:13:14.935317 139716735563648 model_lib_v2.py:651] Step 42800 per-step time 0.776s loss=0.237\n","INFO:tensorflow:Step 42900 per-step time 0.804s loss=0.252\n","I0122 14:14:32.878238 139716735563648 model_lib_v2.py:651] Step 42900 per-step time 0.804s loss=0.252\n","INFO:tensorflow:Step 43000 per-step time 0.763s loss=0.276\n","I0122 14:15:50.473792 139716735563648 model_lib_v2.py:651] Step 43000 per-step time 0.763s loss=0.276\n","INFO:tensorflow:Step 43100 per-step time 0.746s loss=0.226\n","I0122 14:17:07.498684 139716735563648 model_lib_v2.py:651] Step 43100 per-step time 0.746s loss=0.226\n","INFO:tensorflow:Step 43200 per-step time 0.808s loss=0.230\n","I0122 14:18:25.124526 139716735563648 model_lib_v2.py:651] Step 43200 per-step time 0.808s loss=0.230\n","INFO:tensorflow:Step 43300 per-step time 0.784s loss=0.276\n","I0122 14:19:42.792545 139716735563648 model_lib_v2.py:651] Step 43300 per-step time 0.784s loss=0.276\n","INFO:tensorflow:Step 43400 per-step time 0.828s loss=0.249\n","I0122 14:21:01.160609 139716735563648 model_lib_v2.py:651] Step 43400 per-step time 0.828s loss=0.249\n","INFO:tensorflow:Step 43500 per-step time 0.777s loss=0.227\n","I0122 14:22:17.414801 139716735563648 model_lib_v2.py:651] Step 43500 per-step time 0.777s loss=0.227\n","INFO:tensorflow:Step 43600 per-step time 0.785s loss=0.230\n","I0122 14:23:36.140393 139716735563648 model_lib_v2.py:651] Step 43600 per-step time 0.785s loss=0.230\n","INFO:tensorflow:Step 43700 per-step time 0.813s loss=0.233\n","I0122 14:24:53.630686 139716735563648 model_lib_v2.py:651] Step 43700 per-step time 0.813s loss=0.233\n","INFO:tensorflow:Step 43800 per-step time 0.808s loss=0.318\n","I0122 14:26:12.171774 139716735563648 model_lib_v2.py:651] Step 43800 per-step time 0.808s loss=0.318\n","INFO:tensorflow:Step 43900 per-step time 0.736s loss=0.228\n","I0122 14:27:29.893168 139716735563648 model_lib_v2.py:651] Step 43900 per-step time 0.736s loss=0.228\n","INFO:tensorflow:Step 44000 per-step time 0.809s loss=0.257\n","I0122 14:28:47.400118 139716735563648 model_lib_v2.py:651] Step 44000 per-step time 0.809s loss=0.257\n","INFO:tensorflow:Step 44100 per-step time 0.760s loss=0.192\n","I0122 14:30:05.316184 139716735563648 model_lib_v2.py:651] Step 44100 per-step time 0.760s loss=0.192\n","INFO:tensorflow:Step 44200 per-step time 0.778s loss=0.319\n","I0122 14:31:22.759327 139716735563648 model_lib_v2.py:651] Step 44200 per-step time 0.778s loss=0.319\n","INFO:tensorflow:Step 44300 per-step time 0.733s loss=0.236\n","I0122 14:32:39.400187 139716735563648 model_lib_v2.py:651] Step 44300 per-step time 0.733s loss=0.236\n","INFO:tensorflow:Step 44400 per-step time 0.809s loss=0.333\n","I0122 14:33:56.285017 139716735563648 model_lib_v2.py:651] Step 44400 per-step time 0.809s loss=0.333\n","INFO:tensorflow:Step 44500 per-step time 0.703s loss=0.263\n","I0122 14:35:14.001398 139716735563648 model_lib_v2.py:651] Step 44500 per-step time 0.703s loss=0.263\n","INFO:tensorflow:Step 44600 per-step time 0.826s loss=0.211\n","I0122 14:36:30.045979 139716735563648 model_lib_v2.py:651] Step 44600 per-step time 0.826s loss=0.211\n","INFO:tensorflow:Step 44700 per-step time 0.770s loss=0.190\n","I0122 14:37:47.913061 139716735563648 model_lib_v2.py:651] Step 44700 per-step time 0.770s loss=0.190\n","INFO:tensorflow:Step 44800 per-step time 0.696s loss=0.275\n","I0122 14:39:04.943728 139716735563648 model_lib_v2.py:651] Step 44800 per-step time 0.696s loss=0.275\n","INFO:tensorflow:Step 44900 per-step time 0.821s loss=0.306\n","I0122 14:40:22.792687 139716735563648 model_lib_v2.py:651] Step 44900 per-step time 0.821s loss=0.306\n","INFO:tensorflow:Step 45000 per-step time 0.818s loss=0.225\n","I0122 14:41:40.350110 139716735563648 model_lib_v2.py:651] Step 45000 per-step time 0.818s loss=0.225\n","INFO:tensorflow:Step 45100 per-step time 0.786s loss=0.289\n","I0122 14:42:58.295123 139716735563648 model_lib_v2.py:651] Step 45100 per-step time 0.786s loss=0.289\n","INFO:tensorflow:Step 45200 per-step time 0.704s loss=0.319\n","I0122 14:44:16.379351 139716735563648 model_lib_v2.py:651] Step 45200 per-step time 0.704s loss=0.319\n","INFO:tensorflow:Step 45300 per-step time 0.747s loss=0.266\n","I0122 14:45:34.764733 139716735563648 model_lib_v2.py:651] Step 45300 per-step time 0.747s loss=0.266\n","INFO:tensorflow:Step 45400 per-step time 0.814s loss=0.217\n","I0122 14:46:53.409687 139716735563648 model_lib_v2.py:651] Step 45400 per-step time 0.814s loss=0.217\n","INFO:tensorflow:Step 45500 per-step time 0.667s loss=0.216\n","I0122 14:48:11.340502 139716735563648 model_lib_v2.py:651] Step 45500 per-step time 0.667s loss=0.216\n","INFO:tensorflow:Step 45600 per-step time 0.751s loss=0.235\n","I0122 14:49:29.517666 139716735563648 model_lib_v2.py:651] Step 45600 per-step time 0.751s loss=0.235\n","INFO:tensorflow:Step 45700 per-step time 0.823s loss=0.248\n","I0122 14:50:48.129318 139716735563648 model_lib_v2.py:651] Step 45700 per-step time 0.823s loss=0.248\n","INFO:tensorflow:Step 45800 per-step time 0.759s loss=0.246\n","I0122 14:52:05.791126 139716735563648 model_lib_v2.py:651] Step 45800 per-step time 0.759s loss=0.246\n","INFO:tensorflow:Step 45900 per-step time 0.753s loss=0.230\n","I0122 14:53:22.839394 139716735563648 model_lib_v2.py:651] Step 45900 per-step time 0.753s loss=0.230\n","INFO:tensorflow:Step 46000 per-step time 0.831s loss=0.248\n","I0122 14:54:40.789775 139716735563648 model_lib_v2.py:651] Step 46000 per-step time 0.831s loss=0.248\n","INFO:tensorflow:Step 46100 per-step time 0.805s loss=0.211\n","I0122 14:55:58.316232 139716735563648 model_lib_v2.py:651] Step 46100 per-step time 0.805s loss=0.211\n","INFO:tensorflow:Step 46200 per-step time 0.794s loss=0.247\n","I0122 14:57:16.417418 139716735563648 model_lib_v2.py:651] Step 46200 per-step time 0.794s loss=0.247\n","INFO:tensorflow:Step 46300 per-step time 0.755s loss=0.328\n","I0122 14:58:33.580095 139716735563648 model_lib_v2.py:651] Step 46300 per-step time 0.755s loss=0.328\n","INFO:tensorflow:Step 46400 per-step time 0.717s loss=0.226\n","I0122 14:59:52.384165 139716735563648 model_lib_v2.py:651] Step 46400 per-step time 0.717s loss=0.226\n","INFO:tensorflow:Step 46500 per-step time 0.868s loss=0.291\n","I0122 15:01:11.240194 139716735563648 model_lib_v2.py:651] Step 46500 per-step time 0.868s loss=0.291\n","INFO:tensorflow:Step 46600 per-step time 0.771s loss=0.219\n","I0122 15:02:31.851970 139716735563648 model_lib_v2.py:651] Step 46600 per-step time 0.771s loss=0.219\n","INFO:tensorflow:Step 46700 per-step time 0.844s loss=0.219\n","I0122 15:03:52.661097 139716735563648 model_lib_v2.py:651] Step 46700 per-step time 0.844s loss=0.219\n","INFO:tensorflow:Step 46800 per-step time 0.777s loss=0.227\n","I0122 15:05:16.248603 139716735563648 model_lib_v2.py:651] Step 46800 per-step time 0.777s loss=0.227\n","INFO:tensorflow:Step 46900 per-step time 0.801s loss=0.199\n","I0122 15:06:39.572055 139716735563648 model_lib_v2.py:651] Step 46900 per-step time 0.801s loss=0.199\n","INFO:tensorflow:Step 47000 per-step time 0.845s loss=0.235\n","I0122 15:08:01.960151 139716735563648 model_lib_v2.py:651] Step 47000 per-step time 0.845s loss=0.235\n","INFO:tensorflow:Step 47100 per-step time 0.808s loss=0.259\n","I0122 15:09:25.687111 139716735563648 model_lib_v2.py:651] Step 47100 per-step time 0.808s loss=0.259\n","INFO:tensorflow:Step 47200 per-step time 0.869s loss=0.248\n","I0122 15:10:48.046813 139716735563648 model_lib_v2.py:651] Step 47200 per-step time 0.869s loss=0.248\n","INFO:tensorflow:Step 47300 per-step time 0.894s loss=0.247\n","I0122 15:12:10.785819 139716735563648 model_lib_v2.py:651] Step 47300 per-step time 0.894s loss=0.247\n","INFO:tensorflow:Step 47400 per-step time 0.864s loss=0.229\n","I0122 15:13:33.013066 139716735563648 model_lib_v2.py:651] Step 47400 per-step time 0.864s loss=0.229\n","INFO:tensorflow:Step 47500 per-step time 0.809s loss=0.296\n","I0122 15:14:54.720837 139716735563648 model_lib_v2.py:651] Step 47500 per-step time 0.809s loss=0.296\n","INFO:tensorflow:Step 47600 per-step time 0.853s loss=0.225\n","I0122 15:16:16.595729 139716735563648 model_lib_v2.py:651] Step 47600 per-step time 0.853s loss=0.225\n","INFO:tensorflow:Step 47700 per-step time 0.887s loss=0.237\n","I0122 15:17:40.185564 139716735563648 model_lib_v2.py:651] Step 47700 per-step time 0.887s loss=0.237\n","INFO:tensorflow:Step 47800 per-step time 0.832s loss=0.236\n","I0122 15:19:02.890315 139716735563648 model_lib_v2.py:651] Step 47800 per-step time 0.832s loss=0.236\n","INFO:tensorflow:Step 47900 per-step time 0.858s loss=0.182\n","I0122 15:20:26.117912 139716735563648 model_lib_v2.py:651] Step 47900 per-step time 0.858s loss=0.182\n","INFO:tensorflow:Step 48000 per-step time 0.750s loss=0.292\n","I0122 15:21:48.910755 139716735563648 model_lib_v2.py:651] Step 48000 per-step time 0.750s loss=0.292\n","INFO:tensorflow:Step 48100 per-step time 0.852s loss=0.226\n","I0122 15:23:13.482949 139716735563648 model_lib_v2.py:651] Step 48100 per-step time 0.852s loss=0.226\n","INFO:tensorflow:Step 48200 per-step time 0.795s loss=0.268\n","I0122 15:24:36.055910 139716735563648 model_lib_v2.py:651] Step 48200 per-step time 0.795s loss=0.268\n","INFO:tensorflow:Step 48300 per-step time 0.806s loss=0.299\n","I0122 15:25:57.639322 139716735563648 model_lib_v2.py:651] Step 48300 per-step time 0.806s loss=0.299\n","INFO:tensorflow:Step 48400 per-step time 0.829s loss=0.227\n","I0122 15:27:19.883119 139716735563648 model_lib_v2.py:651] Step 48400 per-step time 0.829s loss=0.227\n","INFO:tensorflow:Step 48500 per-step time 0.829s loss=0.201\n","I0122 15:28:42.008349 139716735563648 model_lib_v2.py:651] Step 48500 per-step time 0.829s loss=0.201\n","INFO:tensorflow:Step 48600 per-step time 0.881s loss=0.295\n","I0122 15:30:03.919395 139716735563648 model_lib_v2.py:651] Step 48600 per-step time 0.881s loss=0.295\n","INFO:tensorflow:Step 48700 per-step time 0.826s loss=0.212\n","I0122 15:31:26.062713 139716735563648 model_lib_v2.py:651] Step 48700 per-step time 0.826s loss=0.212\n","INFO:tensorflow:Step 48800 per-step time 0.821s loss=0.250\n","I0122 15:32:49.843219 139716735563648 model_lib_v2.py:651] Step 48800 per-step time 0.821s loss=0.250\n","INFO:tensorflow:Step 48900 per-step time 0.735s loss=0.254\n","I0122 15:34:11.545340 139716735563648 model_lib_v2.py:651] Step 48900 per-step time 0.735s loss=0.254\n","INFO:tensorflow:Step 49000 per-step time 0.897s loss=0.221\n","I0122 15:35:34.542566 139716735563648 model_lib_v2.py:651] Step 49000 per-step time 0.897s loss=0.221\n","INFO:tensorflow:Step 49100 per-step time 0.784s loss=0.267\n","I0122 15:36:58.020915 139716735563648 model_lib_v2.py:651] Step 49100 per-step time 0.784s loss=0.267\n","INFO:tensorflow:Step 49200 per-step time 0.775s loss=0.222\n","I0122 15:38:19.439424 139716735563648 model_lib_v2.py:651] Step 49200 per-step time 0.775s loss=0.222\n","INFO:tensorflow:Step 49300 per-step time 0.750s loss=0.267\n","I0122 15:39:42.344146 139716735563648 model_lib_v2.py:651] Step 49300 per-step time 0.750s loss=0.267\n","INFO:tensorflow:Step 49400 per-step time 0.836s loss=0.237\n","I0122 15:41:04.320964 139716735563648 model_lib_v2.py:651] Step 49400 per-step time 0.836s loss=0.237\n","INFO:tensorflow:Step 49500 per-step time 0.715s loss=0.261\n","I0122 15:42:28.013490 139716735563648 model_lib_v2.py:651] Step 49500 per-step time 0.715s loss=0.261\n","INFO:tensorflow:Step 49600 per-step time 0.841s loss=0.320\n","I0122 15:43:50.152526 139716735563648 model_lib_v2.py:651] Step 49600 per-step time 0.841s loss=0.320\n","INFO:tensorflow:Step 49700 per-step time 0.893s loss=0.251\n","I0122 15:45:13.062268 139716735563648 model_lib_v2.py:651] Step 49700 per-step time 0.893s loss=0.251\n","INFO:tensorflow:Step 49800 per-step time 0.838s loss=0.322\n","I0122 15:46:35.852049 139716735563648 model_lib_v2.py:651] Step 49800 per-step time 0.838s loss=0.322\n","INFO:tensorflow:Step 49900 per-step time 0.843s loss=0.218\n","I0122 15:47:58.331753 139716735563648 model_lib_v2.py:651] Step 49900 per-step time 0.843s loss=0.218\n","INFO:tensorflow:Step 50000 per-step time 0.854s loss=0.227\n","I0122 15:49:21.432557 139716735563648 model_lib_v2.py:651] Step 50000 per-step time 0.854s loss=0.227\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TI9iCCxoNlAL"},"source":["%load_ext tensorboard\n","%tensorboard --logdir '/content/training/train'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p5MUMPepgEP-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611330575526,"user_tz":-60,"elapsed":16,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"1217f5c3-5872-4fc4-db3a-c5b0fcdcf7c7"},"source":["end_time = datetime.datetime.now().strftime(\"%d %b, %H:%M:%S\")\n","print(start_time)\n","print(end_time)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["22 Jan, 04:40:22\n","22 Jan, 15:49:35\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4Vk2146Ogil3"},"source":["## Exporting a Trained Inference Graph\n","Still to come for TF2 models, we will be updating this Colab notebook accordingly as the functionality is added. "]},{"cell_type":"code","metadata":{"id":"vqaZ4v-vIuDl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611330575871,"user_tz":-60,"elapsed":356,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"80ab6174-79c9-464d-e8c4-043278a4bb8d"},"source":["#see where our model saved weights\n","%ls '/content/training/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["checkpoint                   ckpt-48.index\n","ckpt-45.data-00000-of-00001  ckpt-49.data-00000-of-00001\n","ckpt-45.index                ckpt-49.index\n","ckpt-46.data-00000-of-00001  ckpt-50.data-00000-of-00001\n","ckpt-46.index                ckpt-50.index\n","ckpt-47.data-00000-of-00001  ckpt-51.data-00000-of-00001\n","ckpt-47.index                ckpt-51.index\n","ckpt-48.data-00000-of-00001  \u001b[0m\u001b[01;34mtrain\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YnSEZIzl4M10","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611330698937,"user_tz":-60,"elapsed":123079,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"cf2b4145-4016-4864-d46e-a50c8f0e01d4"},"source":["#run conversion script\n","import re\n","import numpy as np\n","\n","output_directory = '/content/fine_tuned_model'\n","\n","#place the model weights you would like to export here\n","last_model_path = '/content/training/'\n","print(last_model_path)\n","!python /content/models/research/object_detection/exporter_main_v2.py \\\n","    --trained_checkpoint_dir {last_model_path} \\\n","    --output_directory {output_directory} \\\n","    --pipeline_config_path {pipeline_file}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/training/\n","2021-01-22 15:49:36.428940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 15:49:42.676334: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-01-22 15:49:42.791735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2021-01-22 15:49:42.879930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 15:49:42.884017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s\n","2021-01-22 15:49:42.884096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 15:49:42.905327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n","2021-01-22 15:49:42.905488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n","2021-01-22 15:49:42.912587: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-01-22 15:49:42.922726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-01-22 15:49:43.088384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-01-22 15:49:43.179434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n","2021-01-22 15:49:43.383012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n","2021-01-22 15:49:43.383241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 15:49:43.384388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 15:49:43.385307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-01-22 15:49:43.386035: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-01-22 15:49:43.386259: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-01-22 15:49:43.386447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 15:49:43.387347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s\n","2021-01-22 15:49:43.387430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 15:49:43.387507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n","2021-01-22 15:49:43.387552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n","2021-01-22 15:49:43.387586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-01-22 15:49:43.387615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-01-22 15:49:43.387644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-01-22 15:49:43.387675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n","2021-01-22 15:49:43.387705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n","2021-01-22 15:49:43.387822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 15:49:43.388820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 15:49:43.389729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-01-22 15:49:43.389795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 15:49:44.950121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-01-22 15:49:44.950181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2021-01-22 15:49:44.950194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2021-01-22 15:49:44.950494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 15:49:44.951199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 15:49:44.951878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 15:49:44.952477: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-01-22 15:49:44.952535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14753 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n","I0122 15:49:44.966191 140043566118784 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0122 15:49:44.966396 140043566118784 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n","I0122 15:49:44.966499 140043566118784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n","I0122 15:49:44.983152 140043566118784 efficientnet_model.py:147] round_filter input=32 output=32\n","I0122 15:49:45.095005 140043566118784 efficientnet_model.py:147] round_filter input=32 output=32\n","I0122 15:49:45.095194 140043566118784 efficientnet_model.py:147] round_filter input=16 output=16\n","I0122 15:49:45.160033 140043566118784 efficientnet_model.py:147] round_filter input=16 output=16\n","I0122 15:49:45.160205 140043566118784 efficientnet_model.py:147] round_filter input=24 output=24\n","I0122 15:49:45.347273 140043566118784 efficientnet_model.py:147] round_filter input=24 output=24\n","I0122 15:49:45.347481 140043566118784 efficientnet_model.py:147] round_filter input=40 output=40\n","I0122 15:49:45.538965 140043566118784 efficientnet_model.py:147] round_filter input=40 output=40\n","I0122 15:49:45.539167 140043566118784 efficientnet_model.py:147] round_filter input=80 output=80\n","I0122 15:49:45.926256 140043566118784 efficientnet_model.py:147] round_filter input=80 output=80\n","I0122 15:49:45.926533 140043566118784 efficientnet_model.py:147] round_filter input=112 output=112\n","I0122 15:49:46.187239 140043566118784 efficientnet_model.py:147] round_filter input=112 output=112\n","I0122 15:49:46.187514 140043566118784 efficientnet_model.py:147] round_filter input=192 output=192\n","I0122 15:49:46.558977 140043566118784 efficientnet_model.py:147] round_filter input=192 output=192\n","I0122 15:49:46.559165 140043566118784 efficientnet_model.py:147] round_filter input=320 output=320\n","I0122 15:49:46.688390 140043566118784 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0122 15:49:46.722391 140043566118784 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f5d9a7addd8>, because it is not built.\n","W0122 15:50:11.756596 140043566118784 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f5d9a7addd8>, because it is not built.\n","2021-01-22 15:50:42.231804: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I0122 15:51:06.654438 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I0122 15:51:06.654814 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabb70>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabba8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabc88>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I0122 15:51:06.655082 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabb70>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabba8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabc88>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b518>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2bef0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b7f0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I0122 15:51:06.655304 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b518>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2bef0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b7f0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabb70>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabba8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabc88>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I0122 15:51:13.592561 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabb70>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabba8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabc88>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b518>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2bef0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b7f0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I0122 15:51:13.592999 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b518>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2bef0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b7f0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I0122 15:51:13.593300 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I0122 15:51:13.593581 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I0122 15:51:13.593866 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I0122 15:51:13.594159 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","W0122 15:51:17.865520 140043566118784 save.py:241] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 500). These functions will not be directly callable after loading.\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I0122 15:51:18.504192 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I0122 15:51:18.504594 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabb70>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabba8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabc88>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I0122 15:51:18.504842 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabb70>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabba8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabc88>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b518>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2bef0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b7f0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I0122 15:51:18.505038 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b518>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2bef0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b7f0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabb70>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabba8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabc88>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I0122 15:51:18.946983 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabb70>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabba8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabc88>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b518>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2bef0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b7f0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I0122 15:51:18.947343 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b518>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2bef0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b7f0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I0122 15:51:18.947612 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I0122 15:51:18.947816 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I0122 15:51:18.948037 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I0122 15:51:18.948226 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","W0122 15:51:19.957472 140043566118784 save.py:241] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 500). These functions will not be directly callable after loading.\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I0122 15:51:29.181034 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f09e8>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0b00>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e0f0fd0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I0122 15:51:29.181407 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd5c0>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd978>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8e3bd860>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabb70>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabba8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabc88>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","I0122 15:51:29.181904 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabb70>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabba8>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8ddabc88>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], False), {}).\n","INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b518>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2bef0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b7f0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","I0122 15:51:29.182140 140043566118784 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b518>, TensorSpec(shape=(None, 64, 64, 40), dtype=tf.float32, name='feature_pyramid/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2bef0>, TensorSpec(shape=(None, 32, 32, 112), dtype=tf.float32, name='feature_pyramid/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f5d8de2b7f0>, TensorSpec(shape=(None, 16, 16, 320), dtype=tf.float32, name='feature_pyramid/2/1'))], True), {}).\n","INFO:tensorflow:Assets written to: /content/fine_tuned_model/saved_model/assets\n","I0122 15:51:31.192027 140043566118784 builder_impl.py:775] Assets written to: /content/fine_tuned_model/saved_model/assets\n","INFO:tensorflow:Writing pipeline config file to /content/fine_tuned_model/pipeline.config\n","I0122 15:51:33.275795 140043566118784 config_util.py:254] Writing pipeline config file to /content/fine_tuned_model/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E_JaeSRR3No5","executionInfo":{"status":"ok","timestamp":1611335860364,"user_tz":-60,"elapsed":655,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"39109e6c-c460-4f24-d2d8-db8b4d1fc4ab"},"source":["#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\r\n","\r\n","import re\r\n","\r\n","batch_size = 1\r\n","\r\n","%cd /content/models/research/deploy\r\n","print('writing custom configuration file')\r\n","\r\n","with open(pipeline_fname) as f:\r\n","    s = f.read()\r\n","with open('pipeline_file.config', 'w') as f:\r\n","    \r\n","    # fine_tune_checkpoint\r\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\r\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\r\n","    \r\n","    # tfrecord files train and test.\r\n","    s = re.sub(\r\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\r\n","    s = re.sub(\r\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\r\n","\r\n","    # label_map_path\r\n","    s = re.sub(\r\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\r\n","\r\n","    # Set training batch_size.\r\n","    s = re.sub('batch_size: [0-9]+',\r\n","               'batch_size: {}'.format(batch_size), s)\r\n","\r\n","    # Set training steps, num_steps\r\n","    s = re.sub('num_steps: [0-9]+',\r\n","               'num_steps: {}'.format(num_steps), s)\r\n","    \r\n","    # Set number of classes num_classes.\r\n","    s = re.sub('num_classes: [0-9]+',\r\n","               'num_classes: {}'.format(num_classes), s)\r\n","    \r\n","    #fine-tune checkpoint type\r\n","    s = re.sub(\r\n","        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\r\n","        \r\n","    f.write(s)\r\n","\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/deploy\n","writing custom configuration file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PA8wL-Ni3C_Q","executionInfo":{"status":"ok","timestamp":1611336097327,"user_tz":-60,"elapsed":181262,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"02eccd31-ee10-46b6-b3d8-1fabd9bdd319"},"source":["# #run model evaluation to obtain performance metrics\r\n","!timeout 180s python /content/models/research/object_detection/model_main_tf2.py \\\r\n","    --pipeline_config_path={pipeline_file} \\\r\n","    --checkpoint_dir={model_dir} \\\r\n","    --model_dir={model_dir} \\\r\n","    --alsologtostderr \\\r\n","    --max_number_of_iterations=1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-01-22 17:18:37.591233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0122 17:18:40.480788 139929192109952 model_lib_v2.py:1026] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n","I0122 17:18:40.481025 139929192109952 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0122 17:18:40.481132 139929192109952 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0122 17:18:40.481232 139929192109952 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0122 17:18:40.481356 139929192109952 model_lib_v2.py:1041] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","2021-01-22 17:18:40.491968: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-01-22 17:18:40.493204: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2021-01-22 17:18:40.519519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:18:40.520169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s\n","2021-01-22 17:18:40.520208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 17:18:40.522472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n","2021-01-22 17:18:40.522560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n","2021-01-22 17:18:40.525591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-01-22 17:18:40.525961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-01-22 17:18:40.528581: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-01-22 17:18:40.529975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n","2021-01-22 17:18:40.535249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n","2021-01-22 17:18:40.535398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:18:40.536089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:18:40.536700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-01-22 17:18:40.537160: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-01-22 17:18:40.537348: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-01-22 17:18:40.537507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:18:40.538117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n","coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s\n","2021-01-22 17:18:40.538150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 17:18:40.538197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n","2021-01-22 17:18:40.538226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n","2021-01-22 17:18:40.538252: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-01-22 17:18:40.538278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-01-22 17:18:40.538307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-01-22 17:18:40.538332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n","2021-01-22 17:18:40.538357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n","2021-01-22 17:18:40.538451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:18:40.539109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:18:40.539720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-01-22 17:18:40.539767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","2021-01-22 17:18:41.333649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-01-22 17:18:41.333710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2021-01-22 17:18:41.333732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2021-01-22 17:18:41.334011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:18:41.334753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:18:41.335406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-01-22 17:18:41.336008: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-01-22 17:18:41.336062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14753 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n","I0122 17:18:41.349070 139929192109952 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0122 17:18:41.349263 139929192109952 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n","I0122 17:18:41.349353 139929192109952 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n","I0122 17:18:41.360346 139929192109952 efficientnet_model.py:147] round_filter input=32 output=32\n","I0122 17:18:41.391760 139929192109952 efficientnet_model.py:147] round_filter input=32 output=32\n","I0122 17:18:41.391927 139929192109952 efficientnet_model.py:147] round_filter input=16 output=16\n","I0122 17:18:41.467492 139929192109952 efficientnet_model.py:147] round_filter input=16 output=16\n","I0122 17:18:41.467669 139929192109952 efficientnet_model.py:147] round_filter input=24 output=24\n","I0122 17:18:41.632861 139929192109952 efficientnet_model.py:147] round_filter input=24 output=24\n","I0122 17:18:41.633047 139929192109952 efficientnet_model.py:147] round_filter input=40 output=40\n","I0122 17:18:41.792341 139929192109952 efficientnet_model.py:147] round_filter input=40 output=40\n","I0122 17:18:41.792545 139929192109952 efficientnet_model.py:147] round_filter input=80 output=80\n","I0122 17:18:42.041550 139929192109952 efficientnet_model.py:147] round_filter input=80 output=80\n","I0122 17:18:42.041735 139929192109952 efficientnet_model.py:147] round_filter input=112 output=112\n","I0122 17:18:42.288793 139929192109952 efficientnet_model.py:147] round_filter input=112 output=112\n","I0122 17:18:42.288995 139929192109952 efficientnet_model.py:147] round_filter input=192 output=192\n","I0122 17:18:42.622903 139929192109952 efficientnet_model.py:147] round_filter input=192 output=192\n","I0122 17:18:42.623107 139929192109952 efficientnet_model.py:147] round_filter input=320 output=320\n","I0122 17:18:42.702050 139929192109952 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0122 17:18:42.736118 139929192109952 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:Reading unweighted datasets: ['/content/data/data_test.tfrecord']\n","I0122 17:18:42.808679 139929192109952 dataset_builder.py:148] Reading unweighted datasets: ['/content/data/data_test.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/data/data_test.tfrecord']\n","I0122 17:18:42.808919 139929192109952 dataset_builder.py:77] Reading record datasets for input file: ['/content/data/data_test.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0122 17:18:42.809031 139929192109952 dataset_builder.py:78] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0122 17:18:42.809127 139929192109952 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W0122 17:18:42.810015 139929192109952 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0122 17:18:42.829558 139929192109952 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0122 17:18:46.761666 139929192109952 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0122 17:18:48.313902 139929192109952 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Waiting for new checkpoint at /content/training/\n","I0122 17:18:51.166601 139929192109952 checkpoint_utils.py:139] Waiting for new checkpoint at /content/training/\n","INFO:tensorflow:Found new checkpoint at /content/training/ckpt-51\n","I0122 17:18:51.170104 139929192109952 checkpoint_utils.py:148] Found new checkpoint at /content/training/ckpt-51\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","2021-01-22 17:18:53.590382: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n","2021-01-22 17:18:53.591036: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2000140000 Hz\n","2021-01-22 17:19:20.067173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n","2021-01-22 17:19:20.450506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0122 17:19:22.632714 139929192109952 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Finished eval step 0\n","I0122 17:19:22.641392 139929192109952 model_lib_v2.py:905] Finished eval step 0\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/visualization_utils.py:617: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0122 17:19:22.798823 139929192109952 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/visualization_utils.py:617: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Finished eval step 100\n","I0122 17:19:31.774868 139929192109952 model_lib_v2.py:905] Finished eval step 100\n","INFO:tensorflow:Finished eval step 200\n","I0122 17:19:39.009434 139929192109952 model_lib_v2.py:905] Finished eval step 200\n","INFO:tensorflow:Finished eval step 300\n","I0122 17:19:46.327234 139929192109952 model_lib_v2.py:905] Finished eval step 300\n","INFO:tensorflow:Finished eval step 400\n","I0122 17:19:53.660026 139929192109952 model_lib_v2.py:905] Finished eval step 400\n","INFO:tensorflow:Finished eval step 500\n","I0122 17:20:01.075367 139929192109952 model_lib_v2.py:905] Finished eval step 500\n","INFO:tensorflow:Finished eval step 600\n","I0122 17:20:08.493606 139929192109952 model_lib_v2.py:905] Finished eval step 600\n","INFO:tensorflow:Finished eval step 700\n","I0122 17:20:15.843292 139929192109952 model_lib_v2.py:905] Finished eval step 700\n","INFO:tensorflow:Finished eval step 800\n","I0122 17:20:23.232151 139929192109952 model_lib_v2.py:905] Finished eval step 800\n","INFO:tensorflow:Finished eval step 900\n","I0122 17:20:30.496272 139929192109952 model_lib_v2.py:905] Finished eval step 900\n","INFO:tensorflow:Finished eval step 1000\n","I0122 17:20:37.770543 139929192109952 model_lib_v2.py:905] Finished eval step 1000\n","INFO:tensorflow:Performing evaluation on 1055 images.\n","I0122 17:20:41.519582 139929192109952 coco_evaluation.py:293] Performing evaluation on 1055 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0122 17:20:41.524371 139929192109952 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.06s)\n","I0122 17:20:41.579964 139929192109952 coco_tools.py:138] DONE (t=0.06s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=8.79s).\n","Accumulating evaluation results...\n","DONE (t=1.28s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.610\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.428\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.282\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.440\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.443\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.469\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.537\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n","INFO:tensorflow:Eval metrics at step 50000\n","I0122 17:20:51.756249 139929192109952 model_lib_v2.py:954] Eval metrics at step 50000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.373198\n","I0122 17:20:51.766077 139929192109952 model_lib_v2.py:957] \t+ DetectionBoxes_Precision/mAP: 0.373198\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.609675\n","I0122 17:20:51.767574 139929192109952 model_lib_v2.py:957] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.609675\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.428076\n","I0122 17:20:51.768981 139929192109952 model_lib_v2.py:957] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.428076\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.281809\n","I0122 17:20:51.770338 139929192109952 model_lib_v2.py:957] \t+ DetectionBoxes_Precision/mAP (small): 0.281809\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.440385\n","I0122 17:20:51.771704 139929192109952 model_lib_v2.py:957] \t+ DetectionBoxes_Precision/mAP (medium): 0.440385\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.443199\n","I0122 17:20:51.773016 139929192109952 model_lib_v2.py:957] \t+ DetectionBoxes_Precision/mAP (large): 0.443199\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.149536\n","I0122 17:20:51.774341 139929192109952 model_lib_v2.py:957] \t+ DetectionBoxes_Recall/AR@1: 0.149536\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.468995\n","I0122 17:20:51.775716 139929192109952 model_lib_v2.py:957] \t+ DetectionBoxes_Recall/AR@10: 0.468995\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.496640\n","I0122 17:20:51.777040 139929192109952 model_lib_v2.py:957] \t+ DetectionBoxes_Recall/AR@100: 0.496640\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.344875\n","I0122 17:20:51.778350 139929192109952 model_lib_v2.py:957] \t+ DetectionBoxes_Recall/AR@100 (small): 0.344875\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.537236\n","I0122 17:20:51.779706 139929192109952 model_lib_v2.py:957] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.537236\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.602097\n","I0122 17:20:51.781109 139929192109952 model_lib_v2.py:957] \t+ DetectionBoxes_Recall/AR@100 (large): 0.602097\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.110361\n","I0122 17:20:51.782152 139929192109952 model_lib_v2.py:957] \t+ Loss/localization_loss: 0.110361\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.307956\n","I0122 17:20:51.783237 139929192109952 model_lib_v2.py:957] \t+ Loss/classification_loss: 0.307956\n","INFO:tensorflow:\t+ Loss/regularization_loss: 0.047339\n","I0122 17:20:51.784292 139929192109952 model_lib_v2.py:957] \t+ Loss/regularization_loss: 0.047339\n","INFO:tensorflow:\t+ Loss/total_loss: 0.465656\n","I0122 17:20:51.785359 139929192109952 model_lib_v2.py:957] \t+ Loss/total_loss: 0.465656\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7Vz2vJeCCyZR"},"source":["# Run Inference on Test Images with Custom TensorFlow2 Object Detector"]},{"cell_type":"code","metadata":{"id":"xxtm1NutE5vK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611336303734,"user_tz":-60,"elapsed":3622,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"79ed50e1-58e7-4b57-be33-db30436784b5"},"source":["%cd /content/\n","# !curl -L \"https://public.roboflow.com/ds/ccWLcGOXmC?key=ldfcWY5whn\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n","\n","if dataset == 1:\n","  drive_id = '11nAnbp2Rnb9y1p_FjrkKBE4FWDAKtqh5'  # Hardhat\n","else:\n","  drive_id = '15XRe167DzTYb7S6fNDAVCrnIr05GJ6jf'  # Scratch\n","\n","gdd.download_file_from_google_drive(file_id=drive_id,\n","                                    dest_path='./dataset.zip',\n","                                    unzip=True)\n","!rm dataset.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","Downloading 11nAnbp2Rnb9y1p_FjrkKBE4FWDAKtqh5 into ./dataset.zip... Done.\n","Unzipping...Done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zYpdruHu1HJ4"},"source":["import matplotlib\r\n","import matplotlib.pyplot as plt\r\n","\r\n","import io\r\n","import scipy.misc\r\n","import numpy as np\r\n","from six import BytesIO\r\n","from PIL import Image, ImageDraw, ImageFont\r\n","\r\n","import tensorflow as tf\r\n","\r\n","from object_detection.utils import label_map_util\r\n","from object_detection.utils import config_util\r\n","from object_detection.utils import visualization_utils as viz_utils\r\n","from object_detection.builders import model_builder\r\n","\r\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SfGj95dQ1PLk"},"source":["def load_image_into_numpy_array(path):\r\n","  \"\"\"Load an image from file into a numpy array.\r\n","\r\n","  Puts image into numpy array to feed into tensorflow graph.\r\n","  Note that by convention we put it into a numpy array with shape\r\n","  (height, width, channels), where channels=3 for RGB.\r\n","\r\n","  Args:\r\n","    path: the file path to the image\r\n","\r\n","  Returns:\r\n","    uint8 numpy array with shape (img_height, img_width, 3)\r\n","  \"\"\"\r\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\r\n","  image = Image.open(BytesIO(img_data))\r\n","  (im_width, im_height) = image.size\r\n","  return np.array(image.getdata()).reshape(\r\n","      (im_height, im_width, 3)).astype(np.uint8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bHJVXPpn5zbX","executionInfo":{"status":"ok","timestamp":1611337300349,"user_tz":-60,"elapsed":841,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"2b431ebd-4119-426e-e1d0-9d0d761b9796"},"source":["%ls '/content/training/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["checkpoint                   ckpt-49.data-00000-of-00001\n","ckpt-45.data-00000-of-00001  ckpt-49.index\n","ckpt-45.index                ckpt-50.data-00000-of-00001\n","ckpt-46.data-00000-of-00001  ckpt-50.index\n","ckpt-46.index                ckpt-51.data-00000-of-00001\n","ckpt-47.data-00000-of-00001  ckpt-51.index\n","ckpt-47.index                \u001b[0m\u001b[01;34meval\u001b[0m/\n","ckpt-48.data-00000-of-00001  \u001b[01;34mtrain\u001b[0m/\n","ckpt-48.index\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ijb7vYDM53qA"},"source":["#recover our saved model\r\n","pipeline_config = pipeline_file\r\n","#generally you want to put the last ckpt from training in here\r\n","model_dir = '/content/training/'\r\n","configs = config_util.get_configs_from_pipeline_file(pipeline_config)\r\n","model_config = configs['model']\r\n","detection_model = model_builder.build(\r\n","      model_config=model_config, is_training=False)\r\n","\r\n","# Restore checkpoint\r\n","ckpt = tf.compat.v2.train.Checkpoint(\r\n","      model=detection_model)\r\n","ckpt.restore(os.path.join('/content/training/ckpt-51'))\r\n","\r\n","\r\n","def get_model_detection_function(model):\r\n","  \"\"\"Get a tf.function for detection.\"\"\"\r\n","\r\n","  @tf.function\r\n","  def detect_fn(image):\r\n","    \"\"\"Detect objects in image.\"\"\"\r\n","\r\n","    image, shapes = model.preprocess(image)\r\n","    prediction_dict = model.predict(image, shapes)\r\n","    detections = model.postprocess(prediction_dict, shapes)\r\n","\r\n","    return detections, prediction_dict, tf.reshape(shapes, [-1])\r\n","\r\n","  return detect_fn\r\n","\r\n","detect_fn = get_model_detection_function(detection_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"irRJVt6255HQ"},"source":["#map labels for inference decoding\r\n","label_map_path = configs['eval_input_config'].label_map_path\r\n","label_map = label_map_util.load_labelmap(label_map_path)\r\n","categories = label_map_util.convert_label_map_to_categories(\r\n","    label_map,\r\n","    max_num_classes=label_map_util.get_max_label_map_index(label_map),\r\n","    use_display_name=True)\r\n","category_index = label_map_util.create_category_index(categories)\r\n","label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txdp-a516NUw","executionInfo":{"status":"ok","timestamp":1611336358761,"user_tz":-60,"elapsed":796,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"745a8df9-3b30-4e6f-fbde-9d3727f27eb0"},"source":["#run detector on test image\r\n","#it takes a little longer on the first run and then runs at normal speed. \r\n","import random\r\n","import glob \r\n","\r\n","\r\n","if dataset == 1:\r\n","  PATH_TO_TEST_IMAGES_DIR =  '/content/hardhat_test_images/'\r\n","else:\r\n","  PATH_TO_TEST_IMAGES_DIR =  '/content/scratch_test_images/'\r\n","\r\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.jpg*\"))\r\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\r\n","TEST_IMAGE_PATHS = sorted(TEST_IMAGE_PATHS)\r\n","if dataset != 1:\r\n","  TEST_IMAGE_PATHS = TEST_IMAGE_PATHS[0:15] + TEST_IMAGE_PATHS[45:60] + TEST_IMAGE_PATHS[90:105] + TEST_IMAGE_PATHS[135:150] + TEST_IMAGE_PATHS[180:195] + TEST_IMAGE_PATHS[225:240]\r\n","print(len(TEST_IMAGE_PATHS))\r\n","print(TEST_IMAGE_PATHS)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1055\n","['/content/hardhat_test_images/000007_jpg.rf.8e98fb789dfc011fb526ce49daf8da31.jpg', '/content/hardhat_test_images/000024_jpg.rf.f4dbede31bcaa30e4264e464b2d32266.jpg', '/content/hardhat_test_images/000035_jpg.rf.a3fd81d1d38c11263dc0f6670b50deda.jpg', '/content/hardhat_test_images/000038_jpg.rf.ee7b22dab5abf8252225253d5b7b50cf.jpg', '/content/hardhat_test_images/000045_jpg.rf.f8429e05f94a05b82b3bf7256063c313.jpg', '/content/hardhat_test_images/000052_jpg.rf.629cc4e04ec1578c1e813c84be098fd0.jpg', '/content/hardhat_test_images/000060_jpg.rf.c77953cd46240aa6676f74bbd2cef120.jpg', '/content/hardhat_test_images/000069_jpg.rf.09b9ad6fbe4cdfbe1d38a7d7424868a5.jpg', '/content/hardhat_test_images/000072_jpg.rf.a6086d0ee280ad45b27f1dfb38f08d1f.jpg', '/content/hardhat_test_images/000076_jpg.rf.6e17a0977fc8ac32c1559e1782d550cf.jpg', '/content/hardhat_test_images/000099_jpg.rf.73261a5bc27bf65613d5c6d1596daec5.jpg', '/content/hardhat_test_images/000102_jpg.rf.a547296ebcc407e4c961aa32c85d99a0.jpg', '/content/hardhat_test_images/000112_jpg.rf.0b9c58cb3d0bb12c302dd282143a4d9f.jpg', '/content/hardhat_test_images/000120_jpg.rf.8ae3d79f4828c94ff29ee01c03f92303.jpg', '/content/hardhat_test_images/000121_jpg.rf.458787b3ee0f603b4fb7ee8442ca893f.jpg', '/content/hardhat_test_images/000130_jpg.rf.d7f4949abf806c22b4bb89e9289f607e.jpg', '/content/hardhat_test_images/000136_jpg.rf.bd59a3b1744cd77a24a66294d9cc0ee5.jpg', '/content/hardhat_test_images/000141_jpg.rf.a0083a17eefa1c9b49f5326d7a0ff987.jpg', '/content/hardhat_test_images/000144_jpg.rf.e0e417be34fb7d743870d8d3ca4cd0a3.jpg', '/content/hardhat_test_images/000151_jpg.rf.8f93d9e83e73fe3601ecdc1ca55e9960.jpg', '/content/hardhat_test_images/000152_jpg.rf.f9c2a41a8714cffa2a600796c692024a.jpg', '/content/hardhat_test_images/000163_jpg.rf.b98f656eee2b2ab33bd5d3c7f7b0c8e1.jpg', '/content/hardhat_test_images/000165_jpg.rf.a3607cf9d405d70c75bebf131a5afbf7.jpg', '/content/hardhat_test_images/000183_jpg.rf.996e8b130fb1d4433c2aca837b43bf5e.jpg', '/content/hardhat_test_images/000184_jpg.rf.53563e27c8b7aae0c0e865b365674223.jpg', '/content/hardhat_test_images/000185_jpg.rf.a07c7675c7e6745ad161cedd33de59e6.jpg', '/content/hardhat_test_images/000192_jpg.rf.f14772324b319afb0f69861a1c60b9c0.jpg', '/content/hardhat_test_images/000198_jpg.rf.162703ae30d35d97c6e90eae60cd513e.jpg', '/content/hardhat_test_images/000200_jpg.rf.63a6cd35bae2e4b1ce4b32bf4b5952d0.jpg', '/content/hardhat_test_images/000202_jpg.rf.afb187a78cf40a978f849908794156de.jpg', '/content/hardhat_test_images/000204_jpg.rf.16540caa5a7c26cb16795dc8f579a74f.jpg', '/content/hardhat_test_images/000221_jpg.rf.510d37d3fb860fd638da5fdb3197d29f.jpg', '/content/hardhat_test_images/000238_jpg.rf.8bc7f4c51673e11fd607e6d56963acfd.jpg', '/content/hardhat_test_images/000244_jpg.rf.e3e422f1777fb7026147401932c5eba7.jpg', '/content/hardhat_test_images/000251_jpg.rf.b0221c10f608c75457f51b3f7c065f43.jpg', '/content/hardhat_test_images/000260_jpg.rf.feee3b4e9a138d59f4ede18ce43deecc.jpg', '/content/hardhat_test_images/000264_jpg.rf.ce0a76b59f6a190a8fe6c821b6f10266.jpg', '/content/hardhat_test_images/000266_jpg.rf.14a197fb433df75c609cf6fd3e4f75c8.jpg', '/content/hardhat_test_images/000270_jpg.rf.28434781eaeebf0feab466eed579e8d3.jpg', '/content/hardhat_test_images/000271_jpg.rf.f2ee82907a96bfbe523c94a41b57fc38.jpg', '/content/hardhat_test_images/000272_jpg.rf.259242e59767e664c4e6d63c2e0c92d7.jpg', '/content/hardhat_test_images/000277_jpg.rf.9c4232e077ee8e6a8da932abfa46b6e8.jpg', '/content/hardhat_test_images/000285_jpg.rf.2b30c3c11d90e195e581953e55c68197.jpg', '/content/hardhat_test_images/000296_jpg.rf.35453a8f6d2adf827e47977c5a4e3022.jpg', '/content/hardhat_test_images/000298_jpg.rf.70acf50e281baa87c0ecbf416acde155.jpg', '/content/hardhat_test_images/000304_jpg.rf.b43923673e0b7f4148ca29369557aa42.jpg', '/content/hardhat_test_images/000306_jpg.rf.3cbd4ca0b74f4bb4def03d11075eb9ab.jpg', '/content/hardhat_test_images/000312_jpg.rf.45857a776fb7622eee03f6a089f33cfb.jpg', '/content/hardhat_test_images/000316_jpg.rf.b11da1032cbaaee2d5e2ce05a291b1bf.jpg', '/content/hardhat_test_images/000317_jpg.rf.826ed4f7df3397186f9c91f4985fa7ab.jpg', '/content/hardhat_test_images/000318_jpg.rf.2f89db18fe6d594777afdb120c850586.jpg', '/content/hardhat_test_images/000319_jpg.rf.f201333fd98564d76504d722a8fbb21b.jpg', '/content/hardhat_test_images/000321_jpg.rf.fbb43949847ca2f1c05596f6a6ccb794.jpg', '/content/hardhat_test_images/000327_jpg.rf.5fe068181b6b727c3704a3a487af523e.jpg', '/content/hardhat_test_images/000345_jpg.rf.b5c604f5c9cfa9ee56cac049ba5e565e.jpg', '/content/hardhat_test_images/000349_jpg.rf.68743e4235a259df0df64d16629f4de1.jpg', '/content/hardhat_test_images/000358_jpg.rf.28808a9f7792bcec6621535b75826490.jpg', '/content/hardhat_test_images/000384_jpg.rf.d00312d5626c4585669f89d0b2a51571.jpg', '/content/hardhat_test_images/000388_jpg.rf.89f7877f0cc4a557c9b404fb7e78c11f.jpg', '/content/hardhat_test_images/000394_jpg.rf.962eea1092d7954ceece804bee54d422.jpg', '/content/hardhat_test_images/000417_jpg.rf.232170292dd4577e4c606a5defda193b.jpg', '/content/hardhat_test_images/000437_jpg.rf.4273e362691052615b4fa015f73b3866.jpg', '/content/hardhat_test_images/000460_jpg.rf.58b395d4016f4dcaeac22740f83ea472.jpg', '/content/hardhat_test_images/000464_jpg.rf.dc0e29f72f520e29744650b76c26d35c.jpg', '/content/hardhat_test_images/000471_jpg.rf.8273d5aa5abaf748321a6692121a05bb.jpg', '/content/hardhat_test_images/000472_jpg.rf.199888712b93aa07dcbe307f894f9386.jpg', '/content/hardhat_test_images/000479_jpg.rf.dacd5020315d9afe55e3abd6e7804e64.jpg', '/content/hardhat_test_images/000485_jpg.rf.f4016bc0c2d35aeac985c2c0ddb3b81d.jpg', '/content/hardhat_test_images/000488_jpg.rf.7b01af2b5256ce7e20dbb3456a158120.jpg', '/content/hardhat_test_images/000494_jpg.rf.89bfa23e4f4066ea71951c488d3678bf.jpg', '/content/hardhat_test_images/000497_jpg.rf.75095f7dd10081b8427dd7026589521f.jpg', '/content/hardhat_test_images/000499_jpg.rf.a108113496b32a3e12aeed2f51a7f9bc.jpg', '/content/hardhat_test_images/000515_jpg.rf.29fed21f400f2443de8d0685a9bf3d47.jpg', '/content/hardhat_test_images/000516_jpg.rf.d5ac13eaaee52891fa2170e5f0b7e410.jpg', '/content/hardhat_test_images/000527_jpg.rf.432600b32c78a4d8b23eb0cc4c2bb3e2.jpg', '/content/hardhat_test_images/000537_jpg.rf.91820fee0461c91e85a3e2988f3f2ab1.jpg', '/content/hardhat_test_images/000547_jpg.rf.bcb8c677f52eb2fab2bf8530412b28e6.jpg', '/content/hardhat_test_images/000557_jpg.rf.683f83292db0e1a7e9d8cfbfb2cb27c3.jpg', '/content/hardhat_test_images/000560_jpg.rf.0c7bf997f0ccb3aa4666aae7bacd15e1.jpg', '/content/hardhat_test_images/000561_jpg.rf.2e13c06528475046ce4ef776f15ecb8e.jpg', '/content/hardhat_test_images/000570_jpg.rf.72acf6a516136a1e8b619d4dcf7e19d3.jpg', '/content/hardhat_test_images/000571_jpg.rf.f20cbcf888f37571b6d3c102b5355f32.jpg', '/content/hardhat_test_images/000576_jpg.rf.fec2b59b042e1abf78005dc2a95ce321.jpg', '/content/hardhat_test_images/000577_jpg.rf.e3e8f7b9a05d729006ddda08e233a422.jpg', '/content/hardhat_test_images/000580_jpg.rf.122ae2447b8e1a15b4997ae72778328c.jpg', '/content/hardhat_test_images/000584_jpg.rf.e961c0c2de411c95422e0ef01c01c46f.jpg', '/content/hardhat_test_images/000604_jpg.rf.44abfc42cc2ec03f516d56f966d6ff0c.jpg', '/content/hardhat_test_images/000611_jpg.rf.443b6c7c90929c5b4b6a3155b7feda03.jpg', '/content/hardhat_test_images/000616_jpg.rf.ecd79fc298d2f4f551c849c8bf3479b7.jpg', '/content/hardhat_test_images/000620_jpg.rf.f33000a871ce6e79e9525be731290bc3.jpg', '/content/hardhat_test_images/000621_jpg.rf.eff847cfb8481bcd8653c6a8c2dbc5e0.jpg', '/content/hardhat_test_images/000642_jpg.rf.cc772ca97cdfe9b83b116aa1f2328dd5.jpg', '/content/hardhat_test_images/000643_jpg.rf.d4c1805b71003f073db4ede8b0995754.jpg', '/content/hardhat_test_images/000644_jpg.rf.549944847b61ddcd29461e6eff390d0a.jpg', '/content/hardhat_test_images/000645_jpg.rf.c3a17316f01510e92f685d5e1b8e2d4e.jpg', '/content/hardhat_test_images/000648_jpg.rf.975d66d309b8bc703d683a7795c6502c.jpg', '/content/hardhat_test_images/000654_jpg.rf.a1eadb321a0bfeddc2d61164c2c0f01d.jpg', '/content/hardhat_test_images/000655_jpg.rf.c427b115827e86cada50f01d27f1c074.jpg', '/content/hardhat_test_images/000664_jpg.rf.12bf957101010a2a91548318813bf87c.jpg', '/content/hardhat_test_images/000665_jpg.rf.8869dea9f3417573a081fd86831b8ceb.jpg', '/content/hardhat_test_images/000666_jpg.rf.ebf8f880394bd3d249e670bb18de3fab.jpg', '/content/hardhat_test_images/000671_jpg.rf.dbb49056b6060c79b92d6787102cd5b0.jpg', '/content/hardhat_test_images/000675_jpg.rf.37109af1a6dde7c13cae2c4974abe1ee.jpg', '/content/hardhat_test_images/000703_jpg.rf.b86239184264c9a1aaac1a434a19cb27.jpg', '/content/hardhat_test_images/000710_jpg.rf.f7a50d20382f2b5e24bd43576faa216d.jpg', '/content/hardhat_test_images/000712_jpg.rf.11dd66195ac4cf07544517e584047375.jpg', '/content/hardhat_test_images/000713_jpg.rf.ca7e01f844acc5183efdf06da8937655.jpg', '/content/hardhat_test_images/000720_jpg.rf.696c20c5f1728cb751136c8bfd93e4ec.jpg', '/content/hardhat_test_images/000727_jpg.rf.98fbf7f55932852b21c18218ccd3fee3.jpg', '/content/hardhat_test_images/000731_jpg.rf.1d0b722bdc23c9512f869177c00b1ef6.jpg', '/content/hardhat_test_images/000732_jpg.rf.9688ac3d40f6193dfe22026a8006a986.jpg', '/content/hardhat_test_images/000748_jpg.rf.cfe1062fa8dc695036201607e3b727bf.jpg', '/content/hardhat_test_images/000763_jpg.rf.1fc05e941c5213370bef3797a92c166f.jpg', '/content/hardhat_test_images/000764_jpg.rf.d412e711b94d233fe45048ebb40a8cd5.jpg', '/content/hardhat_test_images/000770_jpg.rf.d76f99df19083e1b6822534ec1448bea.jpg', '/content/hardhat_test_images/000775_jpg.rf.67df4bcacfdd28d835eabef6d1f87909.jpg', '/content/hardhat_test_images/000781_jpg.rf.443693c41a8d0c9be17b1307f45f7361.jpg', '/content/hardhat_test_images/000790_jpg.rf.c2e84dfd23649f0111e5dd9f6a4d1a4b.jpg', '/content/hardhat_test_images/000799_jpg.rf.2583957d9172ab15a81be0fc9182f21c.jpg', '/content/hardhat_test_images/000807_jpg.rf.22226576cbb4082817e84724b4fdeb59.jpg', '/content/hardhat_test_images/000811_jpg.rf.176b64b4dabaeaff6a35578afa0b178f.jpg', '/content/hardhat_test_images/000812_jpg.rf.2e8f310a1f4b12607ad730bc5d27f21e.jpg', '/content/hardhat_test_images/000813_jpg.rf.cf359c5c9afbc71e680e272ca726d204.jpg', '/content/hardhat_test_images/000824_jpg.rf.08401bd9343807441f68d348a4eeec22.jpg', '/content/hardhat_test_images/000827_jpg.rf.42b20179234852bbe8365a473ad5dd48.jpg', '/content/hardhat_test_images/000834_jpg.rf.a916d06781957dfd2174a8c7ae97507c.jpg', '/content/hardhat_test_images/000855_jpg.rf.bbb69654af3f36cc686b7c26b69bd3ef.jpg', '/content/hardhat_test_images/000875_jpg.rf.aea6370e7e7d61d9af01f3ca2461bb02.jpg', '/content/hardhat_test_images/000878_jpg.rf.87bb484ab06e37317f14f64dcd5ddc8d.jpg', '/content/hardhat_test_images/000894_jpg.rf.771221dd01046145154aaa712f57e48d.jpg', '/content/hardhat_test_images/000897_jpg.rf.1f1d148b5b64bccbf1dc1e150ca9794f.jpg', '/content/hardhat_test_images/000899_jpg.rf.c0e676eb43f003f664c85d71719d136f.jpg', '/content/hardhat_test_images/000900_jpg.rf.b7ca3d587318f361f48c749bdc4bf9ee.jpg', '/content/hardhat_test_images/000903_jpg.rf.6b316a0dba08e40bc0d76f616c88cfae.jpg', '/content/hardhat_test_images/000914_jpg.rf.437dc2e9bff3053ccbd2ac520c303f19.jpg', '/content/hardhat_test_images/000919_jpg.rf.06b2e78d2f8d6c5021a4cff7dc5539c4.jpg', '/content/hardhat_test_images/000929_jpg.rf.dc96bde8bf8442bfabde1f542d043d03.jpg', '/content/hardhat_test_images/000930_jpg.rf.2d8109942147548c0ef78c824cd5bb7a.jpg', '/content/hardhat_test_images/000933_jpg.rf.961c4a3f74a117aae993e165e5cfeef2.jpg', '/content/hardhat_test_images/000937_jpg.rf.a20d6a99775521ecf6e094f3a609851e.jpg', '/content/hardhat_test_images/000952_jpg.rf.31d9ea49e83cfdc3396dd138bab0c3e5.jpg', '/content/hardhat_test_images/000963_jpg.rf.0a21cbff0ad496434347bca1321efee5.jpg', '/content/hardhat_test_images/000976_jpg.rf.068dd5285587932507d17b1b77e97fcf.jpg', '/content/hardhat_test_images/000991_jpg.rf.87e4a1f141395a0efef4fefa094fc0e7.jpg', '/content/hardhat_test_images/001003_jpg.rf.04f6ec30ff676a4684fd9f93cbbd8b50.jpg', '/content/hardhat_test_images/001010_jpg.rf.36c0ac2ca330d67e9a05ba913c8a1ade.jpg', '/content/hardhat_test_images/001011_jpg.rf.8e7e19248d48d924298332caecf23deb.jpg', '/content/hardhat_test_images/001024_jpg.rf.c8e71ca3c46c65abe2eefcc251e7d5bc.jpg', '/content/hardhat_test_images/001028_jpg.rf.4b853812431cb44489c5c3f62b50613a.jpg', '/content/hardhat_test_images/001030_jpg.rf.1b3a79f2fa5c77f1df78ab3315bb332b.jpg', '/content/hardhat_test_images/001039_jpg.rf.2a4a768b6ca4d6b04e4f194c3fb9ea3d.jpg', '/content/hardhat_test_images/001057_jpg.rf.93db25f668314206df8651e916123fd2.jpg', '/content/hardhat_test_images/001062_jpg.rf.7d67f1e690fdadd70f44263288622f1e.jpg', '/content/hardhat_test_images/001075_jpg.rf.15fc9f6f0d369a4c69a46ecdd83f5eee.jpg', '/content/hardhat_test_images/001080_jpg.rf.45a6b8583daea51f984d72d9602da630.jpg', '/content/hardhat_test_images/001098_jpg.rf.35f13e2bf5a03797af88f58e95000f42.jpg', '/content/hardhat_test_images/001113_jpg.rf.d1aeb9aed358e0b4e041a6a39f30e379.jpg', '/content/hardhat_test_images/001114_jpg.rf.ce884604425a5ea305c8cceb0e35050a.jpg', '/content/hardhat_test_images/001119_jpg.rf.1b7e3b896780c618ea6047262334221e.jpg', '/content/hardhat_test_images/001129_jpg.rf.05cbec621652d008d29b3673d7a17a05.jpg', '/content/hardhat_test_images/001134_jpg.rf.0c04e0d9acd6dc9a45d2912b32a13a2b.jpg', '/content/hardhat_test_images/001138_jpg.rf.a2043477b1bdd462c8139197184527ac.jpg', '/content/hardhat_test_images/001142_jpg.rf.dcedbacfc6dd1b25543e901f7e560604.jpg', '/content/hardhat_test_images/001146_jpg.rf.5a356f8a3f783851fb68488dfa65bcf0.jpg', '/content/hardhat_test_images/001152_jpg.rf.df78c7da76aaa6803c14ee47d85adeb6.jpg', '/content/hardhat_test_images/001160_jpg.rf.39713bce024ccce9d67ce350962f8a01.jpg', '/content/hardhat_test_images/001173_jpg.rf.27e192032d8482c9fc481fb6045f0c07.jpg', '/content/hardhat_test_images/001182_jpg.rf.d6acbf6af9067bdbb5f27550fad7afee.jpg', '/content/hardhat_test_images/001185_jpg.rf.a9f915d4521eebbfad532c2e53fad788.jpg', '/content/hardhat_test_images/001190_jpg.rf.833269ac235a8c2bc13e340fb8b43388.jpg', '/content/hardhat_test_images/001193_jpg.rf.77cd559ec8b0c00dc4dbb371fff4b58d.jpg', '/content/hardhat_test_images/001201_jpg.rf.d0c5e2c4961367af99b518f6589220d0.jpg', '/content/hardhat_test_images/001207_jpg.rf.f799e73673d5ee94c330e22324ff1c73.jpg', '/content/hardhat_test_images/001211_jpg.rf.10d092294fcd08960d5610fad2190f41.jpg', '/content/hardhat_test_images/001216_jpg.rf.acfb0869d4be844b183b35c4ab4dc364.jpg', '/content/hardhat_test_images/001217_jpg.rf.26de7c7f8831b819b2777cc860faab3e.jpg', '/content/hardhat_test_images/001218_jpg.rf.616a1ed67d2f9d28c3a42fb2ec89bb70.jpg', '/content/hardhat_test_images/001219_jpg.rf.36db2dacfc93c421902b201813c1b637.jpg', '/content/hardhat_test_images/001220_jpg.rf.201a5972d4901d7a88b9fe8c36a0c212.jpg', '/content/hardhat_test_images/001222_jpg.rf.b45aaf4c4a8b55f68bc9a598a5874722.jpg', '/content/hardhat_test_images/001225_jpg.rf.2a2c96ac94fc186c76b7a25930532c91.jpg', '/content/hardhat_test_images/001238_jpg.rf.5499020e563ff33d5d9da5b15af9fedf.jpg', '/content/hardhat_test_images/001241_jpg.rf.c0dc87484db9c3b77d6c0d07801f37d5.jpg', '/content/hardhat_test_images/001243_jpg.rf.eb2f8514762886269e155046013912cd.jpg', '/content/hardhat_test_images/001249_jpg.rf.9d5ac8e10903092a523f85d77064d1bd.jpg', '/content/hardhat_test_images/001255_jpg.rf.2afeb4f03ae4c92d722b662796b904af.jpg', '/content/hardhat_test_images/001265_jpg.rf.2b6838af4a21ad9b3d36b4abf50b614c.jpg', '/content/hardhat_test_images/001274_jpg.rf.497d94ac5a0a42c4c67f6bba42601d0a.jpg', '/content/hardhat_test_images/001283_jpg.rf.316e36bc002ae47d2fb91181ddd27e66.jpg', '/content/hardhat_test_images/001291_jpg.rf.8b2744cbe728a2e69d6b817c01fa558c.jpg', '/content/hardhat_test_images/001298_jpg.rf.856c568a1c9eaea7777f379d9ccf9cbe.jpg', '/content/hardhat_test_images/001313_jpg.rf.9423e9483e49bdb2ebcd81a336225080.jpg', '/content/hardhat_test_images/001327_jpg.rf.56af4b1054e2c82882692b11f60b134a.jpg', '/content/hardhat_test_images/001328_jpg.rf.38f0414bc394ae6a53a525c95b1adca7.jpg', '/content/hardhat_test_images/001329_jpg.rf.a12341ab20d0e5f4be8b76ff633c0093.jpg', '/content/hardhat_test_images/001331_jpg.rf.3d99d3f3eb332295c0901867d078acb8.jpg', '/content/hardhat_test_images/001335_jpg.rf.e6473bb1623354384005555e72cfd392.jpg', '/content/hardhat_test_images/001338_jpg.rf.9238cf12c542c202155e461b01285694.jpg', '/content/hardhat_test_images/001350_jpg.rf.42dca2e9d48887d861b91fe795c24c29.jpg', '/content/hardhat_test_images/001356_jpg.rf.cb8f63ab80ae020d06c5c56e3842bc4d.jpg', '/content/hardhat_test_images/001357_jpg.rf.54310c3085faefedc8ae40275565218e.jpg', '/content/hardhat_test_images/001363_jpg.rf.a9244fea1bb7c51a7d39b662db403a3d.jpg', '/content/hardhat_test_images/001372_jpg.rf.508fa0dafa991213f8f31d9226174f07.jpg', '/content/hardhat_test_images/001381_jpg.rf.f6dfee1604a2c255aedaaf83b282501d.jpg', '/content/hardhat_test_images/001382_jpg.rf.a1a0ba331ad1d7643ef27322dbbca046.jpg', '/content/hardhat_test_images/001399_jpg.rf.64606524947307cf228af16ded86dfed.jpg', '/content/hardhat_test_images/001400_jpg.rf.4df3441c51811aad06355c9fcce4dafd.jpg', '/content/hardhat_test_images/001405_jpg.rf.e9bb33a8cf50aa285cebea54cf7c6a14.jpg', '/content/hardhat_test_images/001419_jpg.rf.3ce27226679084980d81168cfe13a1c2.jpg', '/content/hardhat_test_images/001421_jpg.rf.81015d4ae8e5c4a1a11f1dead6698e19.jpg', '/content/hardhat_test_images/001424_jpg.rf.c4f1403ef716438d41a36737c26b7941.jpg', '/content/hardhat_test_images/001427_jpg.rf.13d569ef8a35f05a7209926717c098d8.jpg', '/content/hardhat_test_images/001449_jpg.rf.6c99e6337849bccc2c407b542ed7712b.jpg', '/content/hardhat_test_images/001457_jpg.rf.19d0132868fe4d35b6837bacda0d46a6.jpg', '/content/hardhat_test_images/001464_jpg.rf.fedbd5ac0328db99f0c67606d1d60eee.jpg', '/content/hardhat_test_images/001485_jpg.rf.e048b702dba285c09db10b456cefa913.jpg', '/content/hardhat_test_images/001488_jpg.rf.85717f93de302d1c43ee7c05585b3b29.jpg', '/content/hardhat_test_images/001491_jpg.rf.3db83f85f63e60cbed589469bd341f9e.jpg', '/content/hardhat_test_images/001493_jpg.rf.9ab6e84b0b992df0c14184f9e3bbc944.jpg', '/content/hardhat_test_images/001495_jpg.rf.2dbaa5f8d2859739a6535451c6ecbb68.jpg', '/content/hardhat_test_images/001498_jpg.rf.9b3004ca5251b0d517f8cd878a19eb30.jpg', '/content/hardhat_test_images/001500_jpg.rf.2908fde55fa71e29b9088e55478e3ed5.jpg', '/content/hardhat_test_images/001510_jpg.rf.1fcf8577580604a242293e8882cc4a77.jpg', '/content/hardhat_test_images/001516_jpg.rf.c6956832c195637c6403410b8a1bb200.jpg', '/content/hardhat_test_images/001523_jpg.rf.4850f6c26e754c0319693dae620aa10d.jpg', '/content/hardhat_test_images/001527_jpg.rf.dc05f604f11ab64c6b54e9a0f7f0fa68.jpg', '/content/hardhat_test_images/001533_jpg.rf.8b728a705dd7c40b97b6c4519d5701b9.jpg', '/content/hardhat_test_images/001536_jpg.rf.33594fde8bd7cf5496c545217fedca8c.jpg', '/content/hardhat_test_images/001538_jpg.rf.b7cde9a7293c9653d1ec781f12a9711c.jpg', '/content/hardhat_test_images/001543_jpg.rf.af063d55125221ee3c133d9019b69531.jpg', '/content/hardhat_test_images/001550_jpg.rf.20edf797c4a1fd08547683fecc15c5fc.jpg', '/content/hardhat_test_images/001555_jpg.rf.b3fd6f7b528609811255a042d2f27519.jpg', '/content/hardhat_test_images/001556_jpg.rf.3358f8e7e6a5030917ee64e348aff85a.jpg', '/content/hardhat_test_images/001564_jpg.rf.314d9d8e6a2bd03c8979c4bc5955ee4c.jpg', '/content/hardhat_test_images/001569_jpg.rf.75af2a1fae1c18ecc378e83adf9b6371.jpg', '/content/hardhat_test_images/001586_jpg.rf.ae54e393f7f6fd3fd0f42c43cdd362d7.jpg', '/content/hardhat_test_images/001601_jpg.rf.814a01a62f79883314844c89401d333b.jpg', '/content/hardhat_test_images/001608_jpg.rf.26d1ff668b4c013c51dcb6699e15c708.jpg', '/content/hardhat_test_images/001611_jpg.rf.a09dd14e77baa147e524e3f0fcae6eec.jpg', '/content/hardhat_test_images/001617_jpg.rf.8c08aa11e39d581d4161e0dbb3ab62ca.jpg', '/content/hardhat_test_images/001630_jpg.rf.09de3ff12cc1b6b5258d6c7f1ca02b8c.jpg', '/content/hardhat_test_images/001632_jpg.rf.93a8c43ea720e434d15b451be2d7e1b8.jpg', '/content/hardhat_test_images/001637_jpg.rf.1aca1d9f1a46cb1a4af7cdeef5d064e2.jpg', '/content/hardhat_test_images/001644_jpg.rf.5eb0bd73b2f832712b450de5d8c653a1.jpg', '/content/hardhat_test_images/001645_jpg.rf.7c0bca5a8b0150b17269b6ff264baf0a.jpg', '/content/hardhat_test_images/001646_jpg.rf.9cd6bc6419ce9425f1eff7235086547b.jpg', '/content/hardhat_test_images/001648_jpg.rf.a503e525faf5ce2325e8a76c36d72215.jpg', '/content/hardhat_test_images/001651_jpg.rf.514975b7f82d6caf0eac8f9c5c1008ac.jpg', '/content/hardhat_test_images/001667_jpg.rf.ed49c0a5a5f020fe09bd1fb7597aa838.jpg', '/content/hardhat_test_images/001669_jpg.rf.ad67f165268e78a0c4ad8db01012ff85.jpg', '/content/hardhat_test_images/001699_jpg.rf.655f06e45885b7c0a901fe376667c90b.jpg', '/content/hardhat_test_images/001701_jpg.rf.9b01066f088389127c1c41b2b3261e1c.jpg', '/content/hardhat_test_images/001712_jpg.rf.0f0a9da59dea7c98d12efbf794f12769.jpg', '/content/hardhat_test_images/001716_jpg.rf.15d36d44649c4178c2658722be136c0c.jpg', '/content/hardhat_test_images/001717_jpg.rf.0759e96aa190ac6b5889d3d0cbcf6f91.jpg', '/content/hardhat_test_images/001723_jpg.rf.ebd3589f2e5ca81a72016c3819a9a6f8.jpg', '/content/hardhat_test_images/001735_jpg.rf.8acd261197ca509b902da54c26359bed.jpg', '/content/hardhat_test_images/001741_jpg.rf.e06e2e9e53287e112552b327d2f43215.jpg', '/content/hardhat_test_images/001757_jpg.rf.845951840408104ba3948be2e72c75f4.jpg', '/content/hardhat_test_images/001763_jpg.rf.49fb68ff262fe36774faddb17b877980.jpg', '/content/hardhat_test_images/001769_jpg.rf.d574fcd384fe43c974e21c37a77105d6.jpg', '/content/hardhat_test_images/001780_jpg.rf.22752aac6b3346edce0c5512536fa9e3.jpg', '/content/hardhat_test_images/001792_jpg.rf.74c16edf6c85d10a38a56d76f096fe5d.jpg', '/content/hardhat_test_images/001799_jpg.rf.f6efe73dc134a06470dd27b76476d556.jpg', '/content/hardhat_test_images/001819_jpg.rf.9ee2532205b6e7db5434164e5133d088.jpg', '/content/hardhat_test_images/001836_jpg.rf.3ff2a3a7552bc5161a7a11d61849a6dd.jpg', '/content/hardhat_test_images/001837_jpg.rf.2cc5ef9bb959b462cc2ddbb2585f06d8.jpg', '/content/hardhat_test_images/001854_jpg.rf.dc91f8b2b7e69e84ea0d08aad68c3325.jpg', '/content/hardhat_test_images/001855_jpg.rf.ac735d8409932c96c14ce181217f9374.jpg', '/content/hardhat_test_images/001870_jpg.rf.d001c648b10f03bd906cd54b8ac72be4.jpg', '/content/hardhat_test_images/001872_jpg.rf.3b3411713106bda5dc1cb022f7aafaf3.jpg', '/content/hardhat_test_images/001876_jpg.rf.759ea5e3ee143bdc0a77be3c17e5a018.jpg', '/content/hardhat_test_images/001881_jpg.rf.cab9b8efd3707bff8de8262ababb8701.jpg', '/content/hardhat_test_images/001882_jpg.rf.62306ee582eeaf9d7dc3e088fa7f356a.jpg', '/content/hardhat_test_images/001888_jpg.rf.1ec04978b4423bf3c84ddd41dead1941.jpg', '/content/hardhat_test_images/001893_jpg.rf.c058b8a5fc4c9b7b4e5e8d3c6f4a8c63.jpg', '/content/hardhat_test_images/001896_jpg.rf.6329dfd689d5cbe70e2a64bb8110810f.jpg', '/content/hardhat_test_images/001904_jpg.rf.bf3a63b32311da97f26f128c706992cc.jpg', '/content/hardhat_test_images/001907_jpg.rf.6bda74b7c9e7badeb6d497b20aff934a.jpg', '/content/hardhat_test_images/001913_jpg.rf.86a80cd2d736ef07d2d5c9aefa51fccb.jpg', '/content/hardhat_test_images/001928_jpg.rf.11f30c8c1d59731b49e78db21466cdd9.jpg', '/content/hardhat_test_images/001929_jpg.rf.a8ab918e7e6146083ca11200d2d49ced.jpg', '/content/hardhat_test_images/001936_jpg.rf.18f60efed2a95452045226a8978bb18f.jpg', '/content/hardhat_test_images/001941_jpg.rf.d09a9c30a1eb42b2c44318a8e600001c.jpg', '/content/hardhat_test_images/001943_jpg.rf.df6ea5088a63ce4a5cdf643eb799e4f2.jpg', '/content/hardhat_test_images/001957_jpg.rf.f3ee4848df529e491aad27e28e03317f.jpg', '/content/hardhat_test_images/001960_jpg.rf.c429c50158182356847e1fffe5ef0679.jpg', '/content/hardhat_test_images/001962_jpg.rf.be964faaf85fd86eb84d0ec125bea2f0.jpg', '/content/hardhat_test_images/001964_jpg.rf.171b4f05d52eae6326116a0e3bae2a5a.jpg', '/content/hardhat_test_images/001968_jpg.rf.e4e77c3daadcacce808077fed08b9c16.jpg', '/content/hardhat_test_images/001989_jpg.rf.bb5769390aa0729f2f73795f77f40af6.jpg', '/content/hardhat_test_images/001993_jpg.rf.fc5e8e6914a7d2d233fcc910140b9222.jpg', '/content/hardhat_test_images/001994_jpg.rf.28aaa1bc61d0539c4d85ef2d10c45ceb.jpg', '/content/hardhat_test_images/002008_jpg.rf.da54d2e2e660f5841b4882c35b127896.jpg', '/content/hardhat_test_images/002025_jpg.rf.78db4e6fe31b8ba2eb273ed9eda1a56a.jpg', '/content/hardhat_test_images/002030_jpg.rf.d7eadc5715eddae5ce90a54dc46a4bf5.jpg', '/content/hardhat_test_images/002038_jpg.rf.407b60a23c013447e6d3ea7416295058.jpg', '/content/hardhat_test_images/002039_jpg.rf.18c69d0ea6e526cba87be4080cda2ea6.jpg', '/content/hardhat_test_images/002052_jpg.rf.57dd17eb8400a84ac503e210faeda0a3.jpg', '/content/hardhat_test_images/002054_jpg.rf.e408de4b073e483d2e2fc1a3d566ece1.jpg', '/content/hardhat_test_images/002056_jpg.rf.d9a14644e796438479d3590093471738.jpg', '/content/hardhat_test_images/002065_jpg.rf.dde4e683a01d357b47a28491b72bdd14.jpg', '/content/hardhat_test_images/002076_jpg.rf.2ed02eb710ad8064c08675513131bea8.jpg', '/content/hardhat_test_images/002095_jpg.rf.69144da1d69ff998fbbb6ba74c1575ca.jpg', '/content/hardhat_test_images/002106_jpg.rf.ce887b13677d1b0f6015783b4a4a8de4.jpg', '/content/hardhat_test_images/002124_jpg.rf.eefa2b270734f301a51ab3f717307d01.jpg', '/content/hardhat_test_images/002127_jpg.rf.bd0cbbc61a377c354a95d56001fecf5d.jpg', '/content/hardhat_test_images/002132_jpg.rf.2b6ac8c84b2ecc085638606449d7dda4.jpg', '/content/hardhat_test_images/002161_jpg.rf.2137d545a593fa5cf248f6992e98a3de.jpg', '/content/hardhat_test_images/002166_jpg.rf.21c8f3f8e9f1ed1e42a1ac2270dbe350.jpg', '/content/hardhat_test_images/002176_jpg.rf.cf401bd67105613cc3d8d319fa5acce8.jpg', '/content/hardhat_test_images/002184_jpg.rf.dd0f66ad6902c82f1cbc268c4e58e7d9.jpg', '/content/hardhat_test_images/002188_jpg.rf.f3ac02876b8cf615d0ec075c31787f00.jpg', '/content/hardhat_test_images/002191_jpg.rf.fe19fe774c9191fd22fc5af32145e61f.jpg', '/content/hardhat_test_images/002200_jpg.rf.14f0eefc0c153e8267896ac7ea72706b.jpg', '/content/hardhat_test_images/002204_jpg.rf.1a963489869d4745bbb4bdc60f27c0c3.jpg', '/content/hardhat_test_images/002210_jpg.rf.f5de9ac056da3c452ba8e353e98b48cb.jpg', '/content/hardhat_test_images/002213_jpg.rf.3b7ed8686bcc3f10f56296f8fae7f1ea.jpg', '/content/hardhat_test_images/002224_jpg.rf.078adc35dddab4bfba1498a473ff53d7.jpg', '/content/hardhat_test_images/002226_jpg.rf.58685b04eb02ebb0247b3c64c7b1efb6.jpg', '/content/hardhat_test_images/002238_jpg.rf.7d7e7058258f25fe35d348484eac2d58.jpg', '/content/hardhat_test_images/002246_jpg.rf.3ce112eaca21deb8c82c747fcdfcb3a0.jpg', '/content/hardhat_test_images/002250_jpg.rf.c5438de72350876512fd715a3e29b994.jpg', '/content/hardhat_test_images/002252_jpg.rf.bf53c799bb966891a09a1883dab56849.jpg', '/content/hardhat_test_images/002253_jpg.rf.ba103258c17e255d5001efd8783728e6.jpg', '/content/hardhat_test_images/002256_jpg.rf.7cb8a98faec04d8dee1f79464bcbc126.jpg', '/content/hardhat_test_images/002257_jpg.rf.1c57e664c95e5cbfc191b82d7febead3.jpg', '/content/hardhat_test_images/002269_jpg.rf.76558dd58ad5152741e5cae01705013f.jpg', '/content/hardhat_test_images/002274_jpg.rf.e8e7d256d9f2e97ff1435c92762c0a13.jpg', '/content/hardhat_test_images/002288_jpg.rf.1340fa6163ce62bc3803d6a8a921f25e.jpg', '/content/hardhat_test_images/002291_jpg.rf.a9001f847a61c6455db2066d11675795.jpg', '/content/hardhat_test_images/002294_jpg.rf.f6aae798da8398df7be3d82949efeea2.jpg', '/content/hardhat_test_images/002297_jpg.rf.1554f92b398cc7617ff575fc2fe4e07b.jpg', '/content/hardhat_test_images/002307_jpg.rf.9e4d798f6c16e603088f3e9c2e506e14.jpg', '/content/hardhat_test_images/002313_jpg.rf.0e28018efc082081890a8ef3b2e241f2.jpg', '/content/hardhat_test_images/002322_jpg.rf.89663fa6cfc66ee5fb74d97593cb7c49.jpg', '/content/hardhat_test_images/002325_jpg.rf.3259141499ec13cd0f3e8498553f46c3.jpg', '/content/hardhat_test_images/002327_jpg.rf.ff64ef13a4ae7446baf78024885d1197.jpg', '/content/hardhat_test_images/002330_jpg.rf.96163a6cd13103cf2f980b30ca722b3f.jpg', '/content/hardhat_test_images/002332_jpg.rf.c0c4cccb7352e4bd6e0cbcbbb53e54c9.jpg', '/content/hardhat_test_images/002336_jpg.rf.0ca4ec6f6ebaabe8df1781814ea731d9.jpg', '/content/hardhat_test_images/002344_jpg.rf.37ab1f81f7933cffb7c1373c61ea4783.jpg', '/content/hardhat_test_images/002361_jpg.rf.294b9debd391dc143a593014c9747e8e.jpg', '/content/hardhat_test_images/002372_jpg.rf.ff9ffa0a36e0bbe749541649c95ea05b.jpg', '/content/hardhat_test_images/002374_jpg.rf.73df30709f0020e56a21fe85e988df4d.jpg', '/content/hardhat_test_images/002388_jpg.rf.f08a21eb44ddf2361b94a5833c646fc3.jpg', '/content/hardhat_test_images/002392_jpg.rf.7d556e702251c006d14d6ffa2a51bcbb.jpg', '/content/hardhat_test_images/002394_jpg.rf.2deadca2a0891a92f1af84b7e6fce4aa.jpg', '/content/hardhat_test_images/002402_jpg.rf.ae6baf61589c0160a09289fe07e5e80e.jpg', '/content/hardhat_test_images/002409_jpg.rf.91e3034e8421cecca73e6be144e53167.jpg', '/content/hardhat_test_images/002412_jpg.rf.4dc16d55612616e6e7634ee20856fc39.jpg', '/content/hardhat_test_images/002422_jpg.rf.f1a8838a5fee9ebccdde8195f1b2fe2c.jpg', '/content/hardhat_test_images/002423_jpg.rf.561706b3d1fd56d0a110ddd898fa5315.jpg', '/content/hardhat_test_images/002435_jpg.rf.00da910a5373447d586e796f39ad74b0.jpg', '/content/hardhat_test_images/002438_jpg.rf.818e8ddd8ffff36828a7e12ba674d91c.jpg', '/content/hardhat_test_images/002439_jpg.rf.3c833e7aebf4e06650f359db9345d477.jpg', '/content/hardhat_test_images/002440_jpg.rf.99ecaab76c725adbe12493c18d8bd289.jpg', '/content/hardhat_test_images/002448_jpg.rf.b3ffa331e77608180396476bb9342c86.jpg', '/content/hardhat_test_images/002450_jpg.rf.b4fa16fa69a17149d5b2b4d33f8b3b50.jpg', '/content/hardhat_test_images/002457_jpg.rf.3fd63fe5ea9143973c6b086c958e06c4.jpg', '/content/hardhat_test_images/002465_jpg.rf.00b1704fb0c92d32f9b782ae874046a1.jpg', '/content/hardhat_test_images/002468_jpg.rf.2913ce738bdd94c927161de9cd0b23af.jpg', '/content/hardhat_test_images/002486_jpg.rf.b876cb8d21ede0d74e54a86f900b3052.jpg', '/content/hardhat_test_images/002487_jpg.rf.15789b8e89feffd31cbd73b2d56774f8.jpg', '/content/hardhat_test_images/002496_jpg.rf.9b1bd46c8b473450ac64dd7855693b10.jpg', '/content/hardhat_test_images/002498_jpg.rf.f1b7ca3057c71660a572bbb3470ff599.jpg', '/content/hardhat_test_images/002506_jpg.rf.a47ba214029b0e37cc46916f1633f537.jpg', '/content/hardhat_test_images/002515_jpg.rf.1df6c8103adecdb3416e9b19008776e6.jpg', '/content/hardhat_test_images/002526_jpg.rf.f70d7acc9b7c02eae212d3e031601db9.jpg', '/content/hardhat_test_images/002544_jpg.rf.7d0835ad27e63784011a1ee9177059f1.jpg', '/content/hardhat_test_images/002547_jpg.rf.d35fb872d72013dfdaf5b747851da215.jpg', '/content/hardhat_test_images/002549_jpg.rf.358ed3347a8f5e59fa95e7d8b01d548d.jpg', '/content/hardhat_test_images/002550_jpg.rf.fabcbac31ffa132c757290679a2b1146.jpg', '/content/hardhat_test_images/002567_jpg.rf.d97f7e51d68e28a15d6b058f06428987.jpg', '/content/hardhat_test_images/002577_jpg.rf.1c8705c3fbaa2f3ae084ce6381a569fd.jpg', '/content/hardhat_test_images/002591_jpg.rf.896f2e74776b4fea14d2c1157d8dfca5.jpg', '/content/hardhat_test_images/002598_jpg.rf.2c8c905669b6fea957a117d3c5c5d4e5.jpg', '/content/hardhat_test_images/002602_jpg.rf.00aad77a4454ddeb36bbf17bb3b3a8af.jpg', '/content/hardhat_test_images/002603_jpg.rf.8b7ab7fef6bbced548f8bf9d7b3c95c7.jpg', '/content/hardhat_test_images/002609_jpg.rf.fc96945f3c5271c4d61ae9e8da67b77b.jpg', '/content/hardhat_test_images/002616_jpg.rf.8e235a00f71be1aa588cb0b04685ce21.jpg', '/content/hardhat_test_images/002621_jpg.rf.0dd6d0df6995604296b9342026da1b3d.jpg', '/content/hardhat_test_images/002636_jpg.rf.610d0d9a984b0694714bd2decad118ea.jpg', '/content/hardhat_test_images/002637_jpg.rf.9952a65cf2b65a9e977939b1970f531d.jpg', '/content/hardhat_test_images/002641_jpg.rf.cb44c2ea9035558298076b86558614bb.jpg', '/content/hardhat_test_images/002655_jpg.rf.687cf27afedba59ec118a59c7dbef635.jpg', '/content/hardhat_test_images/002660_jpg.rf.6ea67300f33c9a6f160c9803409ac8f2.jpg', '/content/hardhat_test_images/002665_jpg.rf.ed273d054d14b4b4c99dad2ff861ec5f.jpg', '/content/hardhat_test_images/002668_jpg.rf.9bf83c2b08aabfbc54da6c5e3c9aa041.jpg', '/content/hardhat_test_images/002676_jpg.rf.6b4a8a82e4b83d75d5cad2d919b6ae19.jpg', '/content/hardhat_test_images/002691_jpg.rf.3617bf6185b9628b780884f97400fd16.jpg', '/content/hardhat_test_images/002699_jpg.rf.3f2c35763923eceee88c2185667eb661.jpg', '/content/hardhat_test_images/002708_jpg.rf.d013471fb0e61ed383d51c630bc04f7b.jpg', '/content/hardhat_test_images/002710_jpg.rf.adce3d286fc2e52f00d1759527f64b15.jpg', '/content/hardhat_test_images/002727_jpg.rf.68365d9bc4a40ba39803f36de9d751be.jpg', '/content/hardhat_test_images/002728_jpg.rf.2c2b45965dd6e9594ba18bde64fa437c.jpg', '/content/hardhat_test_images/002729_jpg.rf.78d5f1f94f36c1f2ab0df2a43fe650a4.jpg', '/content/hardhat_test_images/002735_jpg.rf.6c3f13003c72ede2d54af6a71b51f228.jpg', '/content/hardhat_test_images/002743_jpg.rf.208138271d5e1c9a89c47a34a4c55fb6.jpg', '/content/hardhat_test_images/002763_jpg.rf.b141a834eb082ea594e935751bdaa282.jpg', '/content/hardhat_test_images/002764_jpg.rf.2394eb1dcad7feb7f15f98264f03fce0.jpg', '/content/hardhat_test_images/002766_jpg.rf.f21eddf5d98681088ec722adf96596f7.jpg', '/content/hardhat_test_images/002767_jpg.rf.bd352b4f909272665160879002ecc45b.jpg', '/content/hardhat_test_images/002771_jpg.rf.94d00ed841a26dc61358baf6e3cf140c.jpg', '/content/hardhat_test_images/002776_jpg.rf.4fe55e0c34e7c7a37db58ec5b929690f.jpg', '/content/hardhat_test_images/002786_jpg.rf.e7f621acb64b1ca4e29acdced53ae87e.jpg', '/content/hardhat_test_images/002789_jpg.rf.43f6a8099b606629295d14d5bca05bb6.jpg', '/content/hardhat_test_images/002791_jpg.rf.3efc1b48ca3e47a049dfb6371f5ed0fe.jpg', '/content/hardhat_test_images/002795_jpg.rf.d81523e73ce940dd4674c85992be0c7e.jpg', '/content/hardhat_test_images/002814_jpg.rf.6c697219cd70ee18ebe3d6c08ecb6f64.jpg', '/content/hardhat_test_images/002817_jpg.rf.0bd2d7f64a3fcc5ca1c8622c762a4b96.jpg', '/content/hardhat_test_images/002822_jpg.rf.45f355a8a37d3089666deb602a449a92.jpg', '/content/hardhat_test_images/002823_jpg.rf.8dac3387952a2861d0aa3b7ff8e5d0da.jpg', '/content/hardhat_test_images/002836_jpg.rf.97107f1a38561b4d0c8e7b033b9c50f2.jpg', '/content/hardhat_test_images/002847_jpg.rf.209f86962f31c86e221e105f26849e68.jpg', '/content/hardhat_test_images/002853_jpg.rf.4217581a68b445ed3abfba4d9391407f.jpg', '/content/hardhat_test_images/002860_jpg.rf.4a1889e2e44b4de8b3cd8a69f74314cc.jpg', '/content/hardhat_test_images/002864_jpg.rf.84846531fa4e52363347a1703cff5462.jpg', '/content/hardhat_test_images/002883_jpg.rf.344bf34bf81ce308e947e888ecaa94d1.jpg', '/content/hardhat_test_images/002888_jpg.rf.8094d5e88064d05717311d6b6cca2fee.jpg', '/content/hardhat_test_images/002893_jpg.rf.cdca01b10166773b289309bfc1a3171f.jpg', '/content/hardhat_test_images/002897_jpg.rf.64d09adb28fc566004803803ba2775a2.jpg', '/content/hardhat_test_images/002900_jpg.rf.520fa1521c74ed300f37923a2060e8f2.jpg', '/content/hardhat_test_images/002913_jpg.rf.a843c05a4cd9d856a27380431b0a5b37.jpg', '/content/hardhat_test_images/002915_jpg.rf.2b44ec4535714edfc9694e1c3c4725a3.jpg', '/content/hardhat_test_images/002935_jpg.rf.e1c9a722f405913278872f1bbb26f176.jpg', '/content/hardhat_test_images/002937_jpg.rf.831ecd3d9e588b71cec8a4da695a0d48.jpg', '/content/hardhat_test_images/002945_jpg.rf.5187be3f77a7d4de842c9fe739f55973.jpg', '/content/hardhat_test_images/002950_jpg.rf.be728994743c84d7dde217c5ed27bfb3.jpg', '/content/hardhat_test_images/002952_jpg.rf.e50a2a5c8b7c8becad371a9ef15c6dfd.jpg', '/content/hardhat_test_images/002953_jpg.rf.ac93d6028ef80106cd56bac2a46492ff.jpg', '/content/hardhat_test_images/002965_jpg.rf.7098fe97654bde95923abc6aedb8fc4a.jpg', '/content/hardhat_test_images/002985_jpg.rf.77156fefb43cfb7c53dc2f17080723a9.jpg', '/content/hardhat_test_images/002995_jpg.rf.cee4a79a0be3643ef2e458fbf5ab2980.jpg', '/content/hardhat_test_images/003001_jpg.rf.e884387b8887a7d04363e030c014d141.jpg', '/content/hardhat_test_images/003021_jpg.rf.287888756b5fbf7aa787971f76665076.jpg', '/content/hardhat_test_images/003027_jpg.rf.fee2743920bf6a0802246b452b061c4c.jpg', '/content/hardhat_test_images/003028_jpg.rf.ff83319ed5289bde4dd244486b55927c.jpg', '/content/hardhat_test_images/003035_jpg.rf.d0fdf613969f2cb9646beea9f90ef87f.jpg', '/content/hardhat_test_images/003037_jpg.rf.aa5437becdb3549d4802d23397212bb8.jpg', '/content/hardhat_test_images/003049_jpg.rf.9706dcfaec7a2e16beb35f2b45418555.jpg', '/content/hardhat_test_images/003060_jpg.rf.643f8852e2980a5c31c04c13ae827da9.jpg', '/content/hardhat_test_images/003063_jpg.rf.02642793102bafd5f797360f96447fc0.jpg', '/content/hardhat_test_images/003067_jpg.rf.f458bc1fed4232addcee2d3bb1603652.jpg', '/content/hardhat_test_images/003107_jpg.rf.46644fdec9d5b9060c4669db880d0044.jpg', '/content/hardhat_test_images/003115_jpg.rf.232543912c5eeac16c8c1a319332f399.jpg', '/content/hardhat_test_images/003116_jpg.rf.409cef3b71cbe53fe63b7a659a24e7a6.jpg', '/content/hardhat_test_images/003127_jpg.rf.18f052e51bcc284b929e56c92133bfef.jpg', '/content/hardhat_test_images/003130_jpg.rf.065899a949781c0ba3c27eeab53e9db4.jpg', '/content/hardhat_test_images/003133_jpg.rf.c6653326af042ffea6d57b4aa4f4094f.jpg', '/content/hardhat_test_images/003134_jpg.rf.e21c3edccfa7d34ef1db3af76bf797f3.jpg', '/content/hardhat_test_images/003146_jpg.rf.37802c8a471c87cc8c383d9057707646.jpg', '/content/hardhat_test_images/003151_jpg.rf.9bb443cde26788dba3decc2de18c2267.jpg', '/content/hardhat_test_images/003171_jpg.rf.11190c184104c3e4fa93b499dd6ccb55.jpg', '/content/hardhat_test_images/003172_jpg.rf.41bb3de94c791de182664d69f960e16d.jpg', '/content/hardhat_test_images/003177_jpg.rf.a8389d1928c727f5a3adec47b42f6b20.jpg', '/content/hardhat_test_images/003182_jpg.rf.ba3b3102aad5969c895019886b3cddc7.jpg', '/content/hardhat_test_images/003194_jpg.rf.16bb008dbd8a085bd79be907ca1eaa61.jpg', '/content/hardhat_test_images/003197_jpg.rf.568ee5bee1b9f3c4043e0bd920e7e1f3.jpg', '/content/hardhat_test_images/003203_jpg.rf.9e062fe6c136aa463a88e1ab30dc2904.jpg', '/content/hardhat_test_images/003210_jpg.rf.37934021ab4a141791d0726ac0bcee5a.jpg', '/content/hardhat_test_images/003213_jpg.rf.70414fed8d8423bd7ba876fd07faa00a.jpg', '/content/hardhat_test_images/003215_jpg.rf.cf4d88d3a2937cfd2d4102465b432f60.jpg', '/content/hardhat_test_images/003217_jpg.rf.f8a98ca02101078a426874fbd1c6ab9c.jpg', '/content/hardhat_test_images/003226_jpg.rf.92a3a2001d5b8ebcad83e5e414d6a448.jpg', '/content/hardhat_test_images/003254_jpg.rf.50a5f717b50222ed36f9c68f05bd0d6e.jpg', '/content/hardhat_test_images/003262_jpg.rf.3458b657bd78f0c9518cb293e53b533e.jpg', '/content/hardhat_test_images/003264_jpg.rf.9b56dd2ac2ba04bbbf18adc15c059108.jpg', '/content/hardhat_test_images/003265_jpg.rf.8a1b97cc1b09c7fe85531d56ccd2ed4d.jpg', '/content/hardhat_test_images/003275_jpg.rf.c64a3a1d76b8159686749a615c3356f4.jpg', '/content/hardhat_test_images/003278_jpg.rf.17bee8f9f51c863b1b5c77b62a938f8b.jpg', '/content/hardhat_test_images/003288_jpg.rf.090d869e6a4665a0e1035e531a248ffe.jpg', '/content/hardhat_test_images/003291_jpg.rf.b7777807167fb054d05e1f0e43fd32a3.jpg', '/content/hardhat_test_images/003304_jpg.rf.f9fc1e818c4999d099443e93d0ce60fb.jpg', '/content/hardhat_test_images/003308_jpg.rf.d5b54d04777a49397d3e3bbf44cb0c9d.jpg', '/content/hardhat_test_images/003311_jpg.rf.2d5989370ea6f02c66fe9e2a20f6fa22.jpg', '/content/hardhat_test_images/003319_jpg.rf.e2a145710c1bfaa7b2650d3429c9e268.jpg', '/content/hardhat_test_images/003329_jpg.rf.b688dfdc13855c4130f0a6bd1d2bc60f.jpg', '/content/hardhat_test_images/003333_jpg.rf.3cb44c9738b7e06ef2e6aa47afa81b43.jpg', '/content/hardhat_test_images/003344_jpg.rf.4122ce45de7a8f7e918cf8be9dbde310.jpg', '/content/hardhat_test_images/003345_jpg.rf.f22300acd1e8fc2fc8f1f6abc477b63f.jpg', '/content/hardhat_test_images/003360_jpg.rf.583768bbb603a9c02e726932489c098e.jpg', '/content/hardhat_test_images/003364_jpg.rf.9abe83342ff31e7012dd007e085077a8.jpg', '/content/hardhat_test_images/003375_jpg.rf.c4cc7afaf4c93b9ea68ca009e34452d0.jpg', '/content/hardhat_test_images/003377_jpg.rf.b73fc80edd3175bc9781f67ff6a90366.jpg', '/content/hardhat_test_images/003395_jpg.rf.ec8947313da36a4dc65e5e09390b0ee7.jpg', '/content/hardhat_test_images/003397_jpg.rf.95466c4a61cb6c5382e1b365fa3e4446.jpg', '/content/hardhat_test_images/003407_jpg.rf.292ee1476a4190ba3deaaf51fd8784b1.jpg', '/content/hardhat_test_images/003413_jpg.rf.0452d5649381c6a65562fd67cbbed76d.jpg', '/content/hardhat_test_images/003423_jpg.rf.52e53ed6f3597ea8be62e994999bff3f.jpg', '/content/hardhat_test_images/003463_jpg.rf.2b72d180474069ca1a15e252a0f0e912.jpg', '/content/hardhat_test_images/003464_jpg.rf.817b4f9eccd37381422fecfdbf5955b4.jpg', '/content/hardhat_test_images/003469_jpg.rf.95899a7baf39886a9e272f443910d219.jpg', '/content/hardhat_test_images/003473_jpg.rf.61da5c43f648238b0a59d222668f3683.jpg', '/content/hardhat_test_images/003481_jpg.rf.0b98c8806e38a10918b194b1d77fe96b.jpg', '/content/hardhat_test_images/003483_jpg.rf.b549643277e517ceb90d4777569ac379.jpg', '/content/hardhat_test_images/003493_jpg.rf.e206135016e06dbaf7f6a544242f6875.jpg', '/content/hardhat_test_images/003494_jpg.rf.7e0bcad39122eb24f771365e36da55d0.jpg', '/content/hardhat_test_images/003496_jpg.rf.99218cbc76ed0a153268e6de2d3127c8.jpg', '/content/hardhat_test_images/003504_jpg.rf.32dccaf053087334eb227e3546f94ead.jpg', '/content/hardhat_test_images/003509_jpg.rf.e47536fa15ffcb1404d8797a49efb793.jpg', '/content/hardhat_test_images/003515_jpg.rf.c54859ed9a9d704d569d45a52180ba9c.jpg', '/content/hardhat_test_images/003517_jpg.rf.f5c946c8bd996bae7877d4815f04c568.jpg', '/content/hardhat_test_images/003524_jpg.rf.f79d0ebe0121b87b254bc76c6e651516.jpg', '/content/hardhat_test_images/003527_jpg.rf.f0258778620a269620e74421729e17f6.jpg', '/content/hardhat_test_images/003528_jpg.rf.fecb421f4f5de3933680f3b0e4ab306e.jpg', '/content/hardhat_test_images/003538_jpg.rf.26f0374cb4735b3353a6bcb974a4a748.jpg', '/content/hardhat_test_images/003542_jpg.rf.a02eddcb2c143e508b4d587f2345d390.jpg', '/content/hardhat_test_images/003543_jpg.rf.5483851a18e6be07977f82af50128ec5.jpg', '/content/hardhat_test_images/003576_jpg.rf.51c2601219110045c7945182340bb890.jpg', '/content/hardhat_test_images/003591_jpg.rf.a61b2841733b2fc8fe1668ba6d398a3a.jpg', '/content/hardhat_test_images/003595_jpg.rf.b7bb15c0a3f524dac218b84b554e04b7.jpg', '/content/hardhat_test_images/003605_jpg.rf.59547b52f324c07cde5d5008f8cd363f.jpg', '/content/hardhat_test_images/003607_jpg.rf.a7a71d361cf1e0c2a659feca5e8f1c13.jpg', '/content/hardhat_test_images/003616_jpg.rf.1e3cc3b03ba323564b9fc96b6883d5e6.jpg', '/content/hardhat_test_images/003623_jpg.rf.90fd5cdc7e407698b77d9a3696bef5a2.jpg', '/content/hardhat_test_images/003624_jpg.rf.3f972d1cd3a8ea095e66afd26a7aea00.jpg', '/content/hardhat_test_images/003632_jpg.rf.c832de23f9115abdee7cb051bebba8de.jpg', '/content/hardhat_test_images/003637_jpg.rf.a071123ba74ed477d20e5d9ae8c4df11.jpg', '/content/hardhat_test_images/003642_jpg.rf.3fa59971aa2b7d878a6755ab8c9d591e.jpg', '/content/hardhat_test_images/003644_jpg.rf.7197f0a56fde323803dd0af4052d5781.jpg', '/content/hardhat_test_images/003650_jpg.rf.bbf4780101f4c51f574741d8c8f36bbe.jpg', '/content/hardhat_test_images/003652_jpg.rf.9d0074ef16fb1ec5376f3de10015919f.jpg', '/content/hardhat_test_images/003655_jpg.rf.963ba11a3f1444f7798fdad7238c644f.jpg', '/content/hardhat_test_images/003657_jpg.rf.a12b45770dad998e45a690768467e477.jpg', '/content/hardhat_test_images/003664_jpg.rf.533c005855b3961be9fd35d68b4b2321.jpg', '/content/hardhat_test_images/003666_jpg.rf.898405a9d0c1d64b510adb7b4d27c981.jpg', '/content/hardhat_test_images/003672_jpg.rf.cbea2bbc993ff4883e7d8c5af5d220d2.jpg', '/content/hardhat_test_images/003675_jpg.rf.713dfdb8dc4f4c20e1858c5ee8eeb3cc.jpg', '/content/hardhat_test_images/003676_jpg.rf.3e0589f3a3c1efb4a4379ebfd0e33519.jpg', '/content/hardhat_test_images/003679_jpg.rf.5dd651b1716565b9dd49b6a742496aea.jpg', '/content/hardhat_test_images/003691_jpg.rf.3252d3f7eb5dc2de1652852e3e80887d.jpg', '/content/hardhat_test_images/003703_jpg.rf.3ecabebfc1792c9f0577f7298e2fc45d.jpg', '/content/hardhat_test_images/003704_jpg.rf.97e3150ab030b62651a7c59ad7da070a.jpg', '/content/hardhat_test_images/003709_jpg.rf.f0511ce8b11584b594eeb52f818f5434.jpg', '/content/hardhat_test_images/003713_jpg.rf.9a7ab5653a2e87bf3b972aad38189123.jpg', '/content/hardhat_test_images/003714_jpg.rf.4dc6caca383d334316acd82b3ccf21b7.jpg', '/content/hardhat_test_images/003716_jpg.rf.867cbf1b2caa4ba7c16d9ddee0045fe7.jpg', '/content/hardhat_test_images/003719_jpg.rf.73ccb25c75aa1d55f5c61d7c7b9bd0cb.jpg', '/content/hardhat_test_images/003720_jpg.rf.090d34bc9977a15f6dba5d452c6cec02.jpg', '/content/hardhat_test_images/003726_jpg.rf.aba581a1dd7201dc3ed766f6932bc14e.jpg', '/content/hardhat_test_images/003740_jpg.rf.0726e2e189284c55c274ed1ec1a52161.jpg', '/content/hardhat_test_images/003754_jpg.rf.086c01a538b01f4c1042c3fdc44872c6.jpg', '/content/hardhat_test_images/003758_jpg.rf.61f084fea209e6ce1ce2934502ad5633.jpg', '/content/hardhat_test_images/003764_jpg.rf.ef17df91e9f184e1ce90d11981ee8072.jpg', '/content/hardhat_test_images/003769_jpg.rf.8fb7ca80615bb56b43b7423c0c0dec5d.jpg', '/content/hardhat_test_images/003772_jpg.rf.5ce0cf2329e3a4650290c4429cbb87dc.jpg', '/content/hardhat_test_images/003776_jpg.rf.452a233cd565c9457a3c94a9da685d49.jpg', '/content/hardhat_test_images/003778_jpg.rf.c7511f3d6e2d0b93dc7b27d2debd5ce0.jpg', '/content/hardhat_test_images/003790_jpg.rf.715d82a71008e45f3a635d35529d6c73.jpg', '/content/hardhat_test_images/003809_jpg.rf.a03aa790c91d46c931d0be8cc19b5f4d.jpg', '/content/hardhat_test_images/003811_jpg.rf.4503f3c8c4c9f3fa85a0014f64b9f187.jpg', '/content/hardhat_test_images/003814_jpg.rf.1776db9e62c58075145ee07c9d254b36.jpg', '/content/hardhat_test_images/003829_jpg.rf.a21f9a7d56b2760e37ad11c7c18fc672.jpg', '/content/hardhat_test_images/003841_jpg.rf.bc99bb7d1f7c945194a3bd868d23000f.jpg', '/content/hardhat_test_images/003842_jpg.rf.173b0fc9e92be870fda8dba6b935f087.jpg', '/content/hardhat_test_images/003844_jpg.rf.145329b02ffa916dfd7eb76864269384.jpg', '/content/hardhat_test_images/003854_jpg.rf.7e1214ba2aded17289fec73bf5356431.jpg', '/content/hardhat_test_images/003864_jpg.rf.87b8c306bee2f7d8be63a1092d8e0be3.jpg', '/content/hardhat_test_images/003866_jpg.rf.3854e9230bacd49996b93b52f9575a05.jpg', '/content/hardhat_test_images/003867_jpg.rf.14c4ff69f39bd8867c266a7b12d3e94d.jpg', '/content/hardhat_test_images/003878_jpg.rf.370b8c63f787bcad9705506c29b0902b.jpg', '/content/hardhat_test_images/003887_jpg.rf.4096d9555beb9a80b10bf113b5b3c7c3.jpg', '/content/hardhat_test_images/003895_jpg.rf.799a110cdb4c39374463eaab64fba96d.jpg', '/content/hardhat_test_images/003933_jpg.rf.caa735697f881357e2ee136d084e324c.jpg', '/content/hardhat_test_images/003938_jpg.rf.d319582d3cbe702dc666c7bb2ff27bfc.jpg', '/content/hardhat_test_images/003940_jpg.rf.b04905ed0341111d155683e71480730e.jpg', '/content/hardhat_test_images/003943_jpg.rf.a37ae05a21bfa29fb84c6dabcab659c4.jpg', '/content/hardhat_test_images/003948_jpg.rf.ada9ecd003e99e79eb871dc8fe1f3965.jpg', '/content/hardhat_test_images/003958_jpg.rf.1f97498678b90fec9d5da965daa85dd5.jpg', '/content/hardhat_test_images/003971_jpg.rf.bd559bdc372079b09b9e1fac7bb54875.jpg', '/content/hardhat_test_images/003973_jpg.rf.8dd069f12cf7908aed34050cc9d8e66a.jpg', '/content/hardhat_test_images/003989_jpg.rf.ac1e54468f9e13aa9e09005bda796656.jpg', '/content/hardhat_test_images/003991_jpg.rf.212db8eeba530aa58443af427ac5f86a.jpg', '/content/hardhat_test_images/004002_jpg.rf.f6936fe862859363bcd5f92c14415143.jpg', '/content/hardhat_test_images/004007_jpg.rf.39a8a23033b1ec9387231e12a292bc93.jpg', '/content/hardhat_test_images/004010_jpg.rf.a2298091e3e095c2b334a3bd584500ba.jpg', '/content/hardhat_test_images/004023_jpg.rf.79bf7e77453c5fc0988a781a5ba9e80d.jpg', '/content/hardhat_test_images/004043_jpg.rf.0b1506d9cf49f94fe0a536b2d9ffdc7b.jpg', '/content/hardhat_test_images/004070_jpg.rf.6bee80b3707ce151b28888883feca864.jpg', '/content/hardhat_test_images/004073_jpg.rf.1fa8d6e667647a1a9658451715a52113.jpg', '/content/hardhat_test_images/004080_jpg.rf.59efbf01c9ef05ba0b16cc0c95571dc9.jpg', '/content/hardhat_test_images/004098_jpg.rf.157db8c5db80b4efde7f7abf566f1984.jpg', '/content/hardhat_test_images/004099_jpg.rf.185ecc987e9931c65c1bb6b8a854896e.jpg', '/content/hardhat_test_images/004109_jpg.rf.438e338d9a1d3da1c35990fe03d468ac.jpg', '/content/hardhat_test_images/004117_jpg.rf.6bbb777f4daede56a9fa0c3d3f1fa339.jpg', '/content/hardhat_test_images/004124_jpg.rf.bae9454f2241b61d9038c09eb0d3c895.jpg', '/content/hardhat_test_images/004127_jpg.rf.9c6987b5a6c3435551872811c77b20f9.jpg', '/content/hardhat_test_images/004130_jpg.rf.987302c532b5c26f36bb4e140bcd9242.jpg', '/content/hardhat_test_images/004138_jpg.rf.7c24ed95bee49dde14aba70482b4571a.jpg', '/content/hardhat_test_images/004139_jpg.rf.5cdc4471903e484bcc7d338a7ec44635.jpg', '/content/hardhat_test_images/004141_jpg.rf.b3c6786c4a4469883fdadc21002060f5.jpg', '/content/hardhat_test_images/004154_jpg.rf.ae479d166685d71c57a3b0c8e46f7d08.jpg', '/content/hardhat_test_images/004159_jpg.rf.928999a4bfecb509241f9c68b3458061.jpg', '/content/hardhat_test_images/004167_jpg.rf.4933a12e7f4c7f38dec4b1920e2c54b6.jpg', '/content/hardhat_test_images/004173_jpg.rf.e0113173e30d95ed6457d3e7ea7e952f.jpg', '/content/hardhat_test_images/004175_jpg.rf.060d17903175bf45a1415ac6f18fc7bb.jpg', '/content/hardhat_test_images/004177_jpg.rf.9e6c2109ddacb081db417b7fbf60239d.jpg', '/content/hardhat_test_images/004184_jpg.rf.99c0dcc0741954d20153313f7863b50f.jpg', '/content/hardhat_test_images/004188_jpg.rf.cdcb7e71c9b50761928e26740415bd41.jpg', '/content/hardhat_test_images/004202_jpg.rf.437d8101735f5670588130f0f7168af9.jpg', '/content/hardhat_test_images/004203_jpg.rf.4c44b721f7a7da690cedc03140b50fd4.jpg', '/content/hardhat_test_images/004204_jpg.rf.f302a91b60d1561bf8044301deae793e.jpg', '/content/hardhat_test_images/004211_jpg.rf.37f089e6481029fac727ea3f5497dc64.jpg', '/content/hardhat_test_images/004212_jpg.rf.3e43f96213b9c0c3cef117a31f681788.jpg', '/content/hardhat_test_images/004213_jpg.rf.38474e75a6d6d06e28e1f0e568d7a4bd.jpg', '/content/hardhat_test_images/004225_jpg.rf.5588b5703b67f7c28e080ab1c24ed10b.jpg', '/content/hardhat_test_images/004233_jpg.rf.4b4e42eb0de9517561d47d3c757693b2.jpg', '/content/hardhat_test_images/004241_jpg.rf.84ae9b6766d33f3290ca4ae97aab8f1a.jpg', '/content/hardhat_test_images/004249_jpg.rf.815c3b1ddc34694cd69ccf6e4fc5961d.jpg', '/content/hardhat_test_images/004250_jpg.rf.648a6e0fb29c0adc26b9a0efff8479b8.jpg', '/content/hardhat_test_images/004259_jpg.rf.a0ea160a8c1cbb918715b4b8b0f68849.jpg', '/content/hardhat_test_images/004261_jpg.rf.7347af5fd6f5fa737e43d6039fe8612c.jpg', '/content/hardhat_test_images/004268_jpg.rf.1a00eda046636e4f90f9feee10a70fef.jpg', '/content/hardhat_test_images/004272_jpg.rf.724564fb74efdfca2e7a52f3280b0c32.jpg', '/content/hardhat_test_images/004292_jpg.rf.84e2f675c1e63aa992f1b7c536323499.jpg', '/content/hardhat_test_images/004315_jpg.rf.bfe488fb6b8ff3ae461fc67cdc8f9d33.jpg', '/content/hardhat_test_images/004321_jpg.rf.7b86ebfb28c666425c82d16249ec4a28.jpg', '/content/hardhat_test_images/004322_jpg.rf.9e587b6e056699ccfcb3ef110a22d9b0.jpg', '/content/hardhat_test_images/004324_jpg.rf.20839e98dae5d26119165438e41b3a0a.jpg', '/content/hardhat_test_images/004331_jpg.rf.924f5945ed4b5611d2cfe465ccc848d3.jpg', '/content/hardhat_test_images/004338_jpg.rf.94ad9beffd70308929a084e3998280da.jpg', '/content/hardhat_test_images/004343_jpg.rf.e3572f497cc3e43e9fbdbb3b4a2fd968.jpg', '/content/hardhat_test_images/004346_jpg.rf.aad1627d8c85be023e37ec42b3bc2953.jpg', '/content/hardhat_test_images/004358_jpg.rf.d94670d96778d7956e9bcb666be80663.jpg', '/content/hardhat_test_images/004359_jpg.rf.4378c77a8f9ac95099aaa8743e44a516.jpg', '/content/hardhat_test_images/004362_jpg.rf.95c084b29b25dc69539e0fae177c3880.jpg', '/content/hardhat_test_images/004368_jpg.rf.264c3a9e1a0fa6212e7e9469f4218f86.jpg', '/content/hardhat_test_images/004371_jpg.rf.ded048c94a2cf906cf9aedddf8a3f303.jpg', '/content/hardhat_test_images/004384_jpg.rf.65e31355223e9d4dcdd440c769c8e834.jpg', '/content/hardhat_test_images/004416_jpg.rf.878586f3343728583dff650985d480fd.jpg', '/content/hardhat_test_images/004417_jpg.rf.6a59462caf35245a5f0dabba5adef83c.jpg', '/content/hardhat_test_images/004420_jpg.rf.98acd1a42acf916299d4923ae2229d99.jpg', '/content/hardhat_test_images/004446_jpg.rf.5a627390adbc7fb814718e4c895f9ed2.jpg', '/content/hardhat_test_images/004460_jpg.rf.07a5de179034b48293ba767c6d67ace0.jpg', '/content/hardhat_test_images/004468_jpg.rf.6292e09e32ca97734b52089a4878a901.jpg', '/content/hardhat_test_images/004491_jpg.rf.2417eb72f4da3fcb24f49bea5528fbd1.jpg', '/content/hardhat_test_images/004498_jpg.rf.1e351152c8ec624c7e95b1e1ef248200.jpg', '/content/hardhat_test_images/004505_jpg.rf.99784662171d75596b8580fa39359934.jpg', '/content/hardhat_test_images/004506_jpg.rf.8e82318f553612ffbcddd53820f057cb.jpg', '/content/hardhat_test_images/004514_jpg.rf.5ebcc571242635c073d2d2fa417dfac3.jpg', '/content/hardhat_test_images/004515_jpg.rf.4f269740c8c02ccf5e84b3b79bd64be9.jpg', '/content/hardhat_test_images/004521_jpg.rf.274b034b65a31d0c023a4ede00a7cbe1.jpg', '/content/hardhat_test_images/004525_jpg.rf.1b3822628670f6bb86db750825ed0b9a.jpg', '/content/hardhat_test_images/004531_jpg.rf.8288d93a92bc917c3c9e2ef806950389.jpg', '/content/hardhat_test_images/004533_jpg.rf.d42c1991485e2653164b878381ddcadc.jpg', '/content/hardhat_test_images/004537_jpg.rf.e062b9ddfcc1c9b36556812730be0f25.jpg', '/content/hardhat_test_images/004545_jpg.rf.5135b18f212de1cf13973b6304ccd204.jpg', '/content/hardhat_test_images/004547_jpg.rf.8cdfba3cb4454ed2ffdd2d0b5f228fca.jpg', '/content/hardhat_test_images/004565_jpg.rf.ac475a2391d1eaa6cabc81d8fb460497.jpg', '/content/hardhat_test_images/004566_jpg.rf.1674be24299f90e7d59ad403974ea6e3.jpg', '/content/hardhat_test_images/004573_jpg.rf.b0641a0cfe78ea9cc267ed0ceb79a798.jpg', '/content/hardhat_test_images/004578_jpg.rf.8fed603b943fb9b993c2342a9343bf87.jpg', '/content/hardhat_test_images/004582_jpg.rf.0f142ce72424e291af1d2c061704eaf9.jpg', '/content/hardhat_test_images/004585_jpg.rf.07f33e04baaa6bf5574e52814b4d7ca3.jpg', '/content/hardhat_test_images/004588_jpg.rf.1b5f1094f90565efa71a4c74a06191e2.jpg', '/content/hardhat_test_images/004594_jpg.rf.c2684f55525c530e644f5dc7e5163cc9.jpg', '/content/hardhat_test_images/004606_jpg.rf.70ddd3d1be5a8e2d386a43e16f81df7a.jpg', '/content/hardhat_test_images/004609_jpg.rf.9b4888abe2a51f5b5dc606cfc144ec4c.jpg', '/content/hardhat_test_images/004612_jpg.rf.577929b889019710b5d6b31932bcf0e8.jpg', '/content/hardhat_test_images/004618_jpg.rf.d6ef26bab5758845e9668ad488decc4b.jpg', '/content/hardhat_test_images/004622_jpg.rf.cb620cb055d3b172f836ee9253ff4332.jpg', '/content/hardhat_test_images/004625_jpg.rf.e99ee319197ad533cf6262d557dbab44.jpg', '/content/hardhat_test_images/004627_jpg.rf.ebea0351f6bce6c734fb47ced97932fe.jpg', '/content/hardhat_test_images/004632_jpg.rf.527ce9a1ad347534a73ea80d5928003d.jpg', '/content/hardhat_test_images/004656_jpg.rf.6f83545ceedb6bf177beab4ae36420e6.jpg', '/content/hardhat_test_images/004659_jpg.rf.49e3fa5ee8c9ad4cfde2c697827a96ad.jpg', '/content/hardhat_test_images/004662_jpg.rf.75386041277a3b7027283ea8bd4635a4.jpg', '/content/hardhat_test_images/004668_jpg.rf.753363a798cf5e5150bf08d5b264de88.jpg', '/content/hardhat_test_images/004673_jpg.rf.833a7f40f776ad3056bddf275c66e537.jpg', '/content/hardhat_test_images/004681_jpg.rf.6cd3d9b0b48f923a669ce78ad8da5afc.jpg', '/content/hardhat_test_images/004686_jpg.rf.3c7417721dcd278f51ffbc7990a3e909.jpg', '/content/hardhat_test_images/004696_jpg.rf.428dc26337eb658c04fa0d358b7b9868.jpg', '/content/hardhat_test_images/004697_jpg.rf.8b5058a66efbd8014254fe6c5df7b233.jpg', '/content/hardhat_test_images/004715_jpg.rf.83dfcd2ff0b4d4d373e3ae63a50c6317.jpg', '/content/hardhat_test_images/004721_jpg.rf.ef212c8b27fffda4d6436873993e1018.jpg', '/content/hardhat_test_images/004729_jpg.rf.2cae3291379b756db5c38be2169ab721.jpg', '/content/hardhat_test_images/004731_jpg.rf.064d9a1a78dd55697eb53981adc76098.jpg', '/content/hardhat_test_images/004735_jpg.rf.fa172d7e35f3f17528fa3724e4ed08c0.jpg', '/content/hardhat_test_images/004739_jpg.rf.c4b150bf9850bbf4f71161ad98839d0b.jpg', '/content/hardhat_test_images/004754_jpg.rf.beddf70e339d3934f8619419f97486c9.jpg', '/content/hardhat_test_images/004765_jpg.rf.a2023e0f74a795034b0647b43d2969d3.jpg', '/content/hardhat_test_images/004770_jpg.rf.527ee97c9a1274340f05ea3b6c32e803.jpg', '/content/hardhat_test_images/004780_jpg.rf.a16e8b59afbffd5942c5b509cd42a7bd.jpg', '/content/hardhat_test_images/004782_jpg.rf.d088f373fbb73aec6590aafbeb06c64f.jpg', '/content/hardhat_test_images/004785_jpg.rf.002ffb29898b3cba483a76e8b73d91a8.jpg', '/content/hardhat_test_images/004787_jpg.rf.1045207a7b1a1cb8ad6cb942d89e8c44.jpg', '/content/hardhat_test_images/004789_jpg.rf.2b40ecc07e4c21a84c5f64c71a2bd4f9.jpg', '/content/hardhat_test_images/004793_jpg.rf.1dd2716f90f4b8ac1158fb502e6700b0.jpg', '/content/hardhat_test_images/004808_jpg.rf.04aeeff09cec8c2e2aa659e966a23394.jpg', '/content/hardhat_test_images/004812_jpg.rf.9fe213c9239c4238c8ef302799fe8d40.jpg', '/content/hardhat_test_images/004818_jpg.rf.77a1ba8908c4c680852579974c62d8ea.jpg', '/content/hardhat_test_images/004833_jpg.rf.72b6c7f127240869a895ef15cd9fd782.jpg', '/content/hardhat_test_images/004844_jpg.rf.00f6f05b98fae010d47cdeebd51b057b.jpg', '/content/hardhat_test_images/004849_jpg.rf.712b9a675ad8de01a1f1415de7ff8db0.jpg', '/content/hardhat_test_images/004851_jpg.rf.465deda51b92fe6a8033d8a6ba924339.jpg', '/content/hardhat_test_images/004859_jpg.rf.485fa34e56bf1689e9f205965b09ef2d.jpg', '/content/hardhat_test_images/004862_jpg.rf.3ea881a418def549d2f984608725a15c.jpg', '/content/hardhat_test_images/004873_jpg.rf.75ccd1b69fd9bee8b2cba14872da379e.jpg', '/content/hardhat_test_images/004874_jpg.rf.7b876c81b85099d1ec6a4cc9042b54ba.jpg', '/content/hardhat_test_images/004884_jpg.rf.cf5116e945e162f05d8cd589217e4f29.jpg', '/content/hardhat_test_images/004886_jpg.rf.e2fec3553feeaa2d8f658eade829f96e.jpg', '/content/hardhat_test_images/004896_jpg.rf.696e3f9af41762c030e9db82a4700185.jpg', '/content/hardhat_test_images/004905_jpg.rf.1e69585e748982cc672e8ddbb39ffd9e.jpg', '/content/hardhat_test_images/004906_jpg.rf.f4de239a5ccef28ff021c47dbb48c1dc.jpg', '/content/hardhat_test_images/004916_jpg.rf.731826924d6a76e3ee36546b64a81138.jpg', '/content/hardhat_test_images/004918_jpg.rf.c4b21fe466ffe2b17967b1be09e90aba.jpg', '/content/hardhat_test_images/004922_jpg.rf.0fb742eaf66aa75229e931f228caa3f2.jpg', '/content/hardhat_test_images/004944_jpg.rf.f64a43e630d59952670d320987e9c761.jpg', '/content/hardhat_test_images/004947_jpg.rf.5722a68502704119c31cd3c2371ac27f.jpg', '/content/hardhat_test_images/004949_jpg.rf.b87e6329a85cf9eae30b9b531b894d35.jpg', '/content/hardhat_test_images/004957_jpg.rf.09dcc585cf12340025aec6507372e3ea.jpg', '/content/hardhat_test_images/004965_jpg.rf.11ee7cdd405cb2590c65b0be30534ff2.jpg', '/content/hardhat_test_images/004985_jpg.rf.4e7ab5e2b43b9ded880ede29ac0654dd.jpg', '/content/hardhat_test_images/004988_jpg.rf.e34b8cefab46dbd23426077a03d21edc.jpg', '/content/hardhat_test_images/004991_jpg.rf.e42b3934bd3dd7257ca3a4bd643c131a.jpg', '/content/hardhat_test_images/004995_jpg.rf.c85d0f1be36707a3209fd6fbbd4af7ab.jpg', '/content/hardhat_test_images/005001_jpg.rf.bb1300cfa714e769d821efb6d0f8038e.jpg', '/content/hardhat_test_images/005005_jpg.rf.7135c8cf76d4ce490e07638f7cc9e786.jpg', '/content/hardhat_test_images/005010_jpg.rf.bf79f4b180ae05f2a5ca7e7ee08e87aa.jpg', '/content/hardhat_test_images/005015_jpg.rf.b758c2e5e27b1f36019017cf49bafebe.jpg', '/content/hardhat_test_images/005021_jpg.rf.c22fc606830d5c274f65e1f2569fb23e.jpg', '/content/hardhat_test_images/005025_jpg.rf.3fad6029fd28735da548b3df2f7d23e8.jpg', '/content/hardhat_test_images/005031_jpg.rf.2340eee7205d06b3c0fdd22ae836d958.jpg', '/content/hardhat_test_images/005045_jpg.rf.16ab5ad1ca2dc980359f6a9b9a14c527.jpg', '/content/hardhat_test_images/005047_jpg.rf.aae201a457236be1eb5bc38cf91959cc.jpg', '/content/hardhat_test_images/005048_jpg.rf.a266f216f133f5e4f9172844b02ca265.jpg', '/content/hardhat_test_images/005075_jpg.rf.c2ca7680085ce43dd06099eb14abcf98.jpg', '/content/hardhat_test_images/005079_jpg.rf.a9b26ae86b988ed0af90ed185316a7c0.jpg', '/content/hardhat_test_images/005086_jpg.rf.4e814b92e1afeba95203b5045f262dbf.jpg', '/content/hardhat_test_images/005092_jpg.rf.7f80a25f48e0bf6b81c522e857e7a476.jpg', '/content/hardhat_test_images/005093_jpg.rf.b25a33edd21f9fd2b20e7f96cdc9223d.jpg', '/content/hardhat_test_images/005120_jpg.rf.23c2b2b251d4cc81a880463a53f2ae17.jpg', '/content/hardhat_test_images/005126_jpg.rf.e71a902b2f06e31c376e513232a4f6f7.jpg', '/content/hardhat_test_images/005139_jpg.rf.27244ece7fdda3313e5224c2ca69da21.jpg', '/content/hardhat_test_images/005143_jpg.rf.0398fcb0a5586a7c28baa8df35cb281a.jpg', '/content/hardhat_test_images/005144_jpg.rf.c02995664a51830ae4dadcae6362d0fa.jpg', '/content/hardhat_test_images/005147_jpg.rf.1c5c77d0189344291ee4fcc331fe16de.jpg', '/content/hardhat_test_images/005148_jpg.rf.08adc851b05b8c70aa994a9c3794fedf.jpg', '/content/hardhat_test_images/005151_jpg.rf.d1b1209388b4f11b645b99442fc9cca4.jpg', '/content/hardhat_test_images/005154_jpg.rf.c04a08b6d9639c0af18bb788bc59c185.jpg', '/content/hardhat_test_images/005168_jpg.rf.a3d63356892f2837bf4a6c7dce65dad6.jpg', '/content/hardhat_test_images/005176_jpg.rf.c86ba35581db04aa7786d5bde60e417d.jpg', '/content/hardhat_test_images/005193_jpg.rf.c9b3b5e221d2458fda6249a961db6886.jpg', '/content/hardhat_test_images/005195_jpg.rf.9911aec067d3c359b4b8be2200dd8297.jpg', '/content/hardhat_test_images/005205_jpg.rf.94223bb82e73994bcb643c7cf0143a20.jpg', '/content/hardhat_test_images/005210_jpg.rf.d74feb1b241bf0c68a2cb66abe03350c.jpg', '/content/hardhat_test_images/005213_jpg.rf.a9576710c94d2f32c5927f6f0864dd3f.jpg', '/content/hardhat_test_images/005217_jpg.rf.2b400899023a952adce4d78cc31d3efd.jpg', '/content/hardhat_test_images/005221_jpg.rf.7ea236291ac43ea4f5ff07fa3efc1324.jpg', '/content/hardhat_test_images/005223_jpg.rf.44e5e13262af7f83a09c6fa5a25ea241.jpg', '/content/hardhat_test_images/005227_jpg.rf.710cf6d3db68618a089f06dc289e9367.jpg', '/content/hardhat_test_images/005236_jpg.rf.43404463aee0785949260b5d761fadce.jpg', '/content/hardhat_test_images/005240_jpg.rf.64441d717661d524fe948e237e9590bb.jpg', '/content/hardhat_test_images/005244_jpg.rf.165891f96aaef094c370463f61e67843.jpg', '/content/hardhat_test_images/005249_jpg.rf.a58203fe22e5963bc488e7f6092249f0.jpg', '/content/hardhat_test_images/005251_jpg.rf.2e42f60c1cab8ef33c3e13310de94281.jpg', '/content/hardhat_test_images/005266_jpg.rf.cb267ecdb256b79f17a7c067a79bd5b2.jpg', '/content/hardhat_test_images/005269_jpg.rf.30ee57bf2f7017421ae7f7029b7bfa8c.jpg', '/content/hardhat_test_images/005275_jpg.rf.3d26fb4cb2c26ffa81974aa74a546735.jpg', '/content/hardhat_test_images/005284_jpg.rf.ce36d85cea76acfdd93fdf6823550795.jpg', '/content/hardhat_test_images/005290_jpg.rf.72f0711622d78bedee4976ad7703b909.jpg', '/content/hardhat_test_images/005297_jpg.rf.84c9d79a97d377470c9aae94b9cd2274.jpg', '/content/hardhat_test_images/005327_jpg.rf.7ac2e444fcb36d45bed1585055b3d53c.jpg', '/content/hardhat_test_images/005329_jpg.rf.78fa54f030de5bdd33eab3b7425595fa.jpg', '/content/hardhat_test_images/005345_jpg.rf.8b594f8b30f1b5881959f4a41ba37288.jpg', '/content/hardhat_test_images/005348_jpg.rf.fe5c35e067b60bdf75d8bb5f9ce17817.jpg', '/content/hardhat_test_images/005351_jpg.rf.ed2d454b2e059fc13f901bcc62947bfa.jpg', '/content/hardhat_test_images/005354_jpg.rf.66ac8412f01e08a6146d5bc63bbb158c.jpg', '/content/hardhat_test_images/005357_jpg.rf.df51ca15e87c9aa7faace47e8ee5a572.jpg', '/content/hardhat_test_images/005358_jpg.rf.8529a6fd49e7f907817f667a038095be.jpg', '/content/hardhat_test_images/005361_jpg.rf.e37d7954e38e9ab2a17aa43d39ac7a7b.jpg', '/content/hardhat_test_images/005365_jpg.rf.10b71063ca52946d889bbadd73b80ec5.jpg', '/content/hardhat_test_images/005373_jpg.rf.d141221dad87e6a6a30cc016fa0d07e5.jpg', '/content/hardhat_test_images/005374_jpg.rf.ecef5686e5c7e32a253d47cb7ef720d2.jpg', '/content/hardhat_test_images/005375_jpg.rf.44f4df2d90ee26ecdab495150ab4e158.jpg', '/content/hardhat_test_images/005377_jpg.rf.07395f9bb00674b13e06dc1ab1c63fa1.jpg', '/content/hardhat_test_images/005385_jpg.rf.aa3ca01ed31ce9c709f480c7b4293342.jpg', '/content/hardhat_test_images/005386_jpg.rf.fd587ee7b6b0091c4ac6dfdffe68a5e8.jpg', '/content/hardhat_test_images/005397_jpg.rf.eb518c5ace162681763b07ddc5f5fbee.jpg', '/content/hardhat_test_images/005400_jpg.rf.22477b9a2785d64cc93c4019726a55d1.jpg', '/content/hardhat_test_images/005402_jpg.rf.092b7eb110ed5225a3312a4d11cce4e4.jpg', '/content/hardhat_test_images/005403_jpg.rf.571bb8063c0d0e463945ecf72d9fda9f.jpg', '/content/hardhat_test_images/005404_jpg.rf.d0ecbd207447aed70d9bb79583224403.jpg', '/content/hardhat_test_images/005412_jpg.rf.41fde57412f3f6a10e1aa8591753f4ee.jpg', '/content/hardhat_test_images/005419_jpg.rf.840bd7a55e0b64e996d35bba2badcfec.jpg', '/content/hardhat_test_images/005421_jpg.rf.1e8c7eeb6c5a92343ac99da1b7ab78ac.jpg', '/content/hardhat_test_images/005427_jpg.rf.c111ec152d931cfbb01691cb8ae72e47.jpg', '/content/hardhat_test_images/005429_jpg.rf.03d5c9f2fe7a9318bf4cd52f15f468a4.jpg', '/content/hardhat_test_images/005434_jpg.rf.892d5b833c1fc2db208a33fd18829758.jpg', '/content/hardhat_test_images/005438_jpg.rf.054318a426ef0f2081f60c08354a0e5d.jpg', '/content/hardhat_test_images/005443_jpg.rf.5c55c848babfe657cf21f0deb8d1b2cd.jpg', '/content/hardhat_test_images/005446_jpg.rf.b0d027f5828afab526e3d01f9b53dd42.jpg', '/content/hardhat_test_images/005447_jpg.rf.ceed8e8a08e08d5f77fb0e0cd04b4832.jpg', '/content/hardhat_test_images/005449_jpg.rf.cfe4bfc64892e38108a521142a14f3b0.jpg', '/content/hardhat_test_images/005452_jpg.rf.0c8dc3a911981ec503fb6b7de5fccc93.jpg', '/content/hardhat_test_images/005454_jpg.rf.c17836917bde6e5892942779e6f20a40.jpg', '/content/hardhat_test_images/005462_jpg.rf.63558b2abbf1fcbd21a90f8ce06a2960.jpg', '/content/hardhat_test_images/005473_jpg.rf.40f57b23b95d5b21bc73e531f539d49d.jpg', '/content/hardhat_test_images/005480_jpg.rf.9b29ab5deaffec984fa146637c38cb02.jpg', '/content/hardhat_test_images/005493_jpg.rf.33fe2a23fb8543c1ca54ba9f372f8002.jpg', '/content/hardhat_test_images/005497_jpg.rf.07c717ffbb7e5ab36a621fab548c266b.jpg', '/content/hardhat_test_images/005502_jpg.rf.6bb85d534e215648d985eb8c4d118311.jpg', '/content/hardhat_test_images/005516_jpg.rf.348b0234feb21b04c84f5ba847d496ca.jpg', '/content/hardhat_test_images/005532_jpg.rf.a8255ee4c3b73bb6ac2a3b299852579e.jpg', '/content/hardhat_test_images/005539_jpg.rf.1df50099b72b096b523031cffb375786.jpg', '/content/hardhat_test_images/005542_jpg.rf.15dd4624efa361018be106cad24e73cb.jpg', '/content/hardhat_test_images/005543_jpg.rf.a9ec2b73ae338797f252127a72ce9d84.jpg', '/content/hardhat_test_images/005552_jpg.rf.063f04fa6ac4db2fefe71c3e5e4c7579.jpg', '/content/hardhat_test_images/005558_jpg.rf.5c743c4f8e14f4e38c29512a95410965.jpg', '/content/hardhat_test_images/005563_jpg.rf.b8b976eab04e6eed20d86c0e4c811ea8.jpg', '/content/hardhat_test_images/005568_jpg.rf.2c0be83baa51570120bffbae1f7a2586.jpg', '/content/hardhat_test_images/005569_jpg.rf.f6c72448120eef6b0ae0b240334930f5.jpg', '/content/hardhat_test_images/005572_jpg.rf.70c2107cd01e012e32186628b0c99817.jpg', '/content/hardhat_test_images/005590_jpg.rf.6d5e7e2aa827b4776b57f3f9667aec01.jpg', '/content/hardhat_test_images/005593_jpg.rf.cedb1b73032cfd2151c588fd7f235755.jpg', '/content/hardhat_test_images/005595_jpg.rf.b830d59b7b1f8161eb91c6b6fbcb393f.jpg', '/content/hardhat_test_images/005599_jpg.rf.1a95045d118da177f22f65270f472e40.jpg', '/content/hardhat_test_images/005601_jpg.rf.566e14d858154c59b5d6f9cdc7570e68.jpg', '/content/hardhat_test_images/005603_jpg.rf.fe7076261f2ab99b99111f70dbd49a44.jpg', '/content/hardhat_test_images/005612_jpg.rf.6d75099865eb963eacbd17a851e58631.jpg', '/content/hardhat_test_images/005614_jpg.rf.9ed30b95e4e99efa75ff46d4ef2cd587.jpg', '/content/hardhat_test_images/005615_jpg.rf.6e162f4858ff761a094660fe62d64e2a.jpg', '/content/hardhat_test_images/005617_jpg.rf.2fb495c5980618efab9c86af9791bf82.jpg', '/content/hardhat_test_images/005619_jpg.rf.b41e0c51de7b640e3e2401bd98357d3e.jpg', '/content/hardhat_test_images/005623_jpg.rf.205f4528ecb4cce3807b4ef8846a22a7.jpg', '/content/hardhat_test_images/005630_jpg.rf.a0a1b4aade1849e0dae6ee34bba64b2b.jpg', '/content/hardhat_test_images/005655_jpg.rf.81bd3463d5cc3c952d65b7a8d16d07d2.jpg', '/content/hardhat_test_images/005656_jpg.rf.f47ed23a2b3d0e3bc67811342785a3a2.jpg', '/content/hardhat_test_images/005693_jpg.rf.349863c80aba23501766ecbc78136978.jpg', '/content/hardhat_test_images/005694_jpg.rf.b29cc8348a44d8f0f4d4975d2459e167.jpg', '/content/hardhat_test_images/005699_jpg.rf.8e5dc8a7420795b53801d29025b270bb.jpg', '/content/hardhat_test_images/005702_jpg.rf.3fa05acc638d6db059b1abf8a538f501.jpg', '/content/hardhat_test_images/005706_jpg.rf.8bde0af977a085346ce3715d1022b6e1.jpg', '/content/hardhat_test_images/005710_jpg.rf.b961bd1ae559e6c2e2a40660966cb4e3.jpg', '/content/hardhat_test_images/005717_jpg.rf.7b272b197c78df3a310bc1243ef4f122.jpg', '/content/hardhat_test_images/005719_jpg.rf.7ffb259f4857d193fe300112ccbeeb1c.jpg', '/content/hardhat_test_images/005725_jpg.rf.c77a28d66f8da5abf44e8e8e4acce48d.jpg', '/content/hardhat_test_images/005727_jpg.rf.db990c971b4163508bd9f63bb07dcc6d.jpg', '/content/hardhat_test_images/005736_jpg.rf.9610a60cbe99d3f3fc7abf92f502797d.jpg', '/content/hardhat_test_images/005739_jpg.rf.ea9483d1d6f740fd0dc2a1f539ebd276.jpg', '/content/hardhat_test_images/005746_jpg.rf.3ba1a2eeeb6c932bb016c3b6c6e3a0a4.jpg', '/content/hardhat_test_images/005748_jpg.rf.cdd189a5571dda9690772224f198800e.jpg', '/content/hardhat_test_images/005766_jpg.rf.f6834c4cbbcdf44c98bc164bbfde00c5.jpg', '/content/hardhat_test_images/005773_jpg.rf.937b3da80a0bd7df33ab43d0af034d40.jpg', '/content/hardhat_test_images/005786_jpg.rf.63fabe3ba60b302a049592ae02e3be28.jpg', '/content/hardhat_test_images/005790_jpg.rf.809528b52e84ae16e01948ea41025d6d.jpg', '/content/hardhat_test_images/005801_jpg.rf.e3511461b670d47fdaa76d9328ad8f79.jpg', '/content/hardhat_test_images/005804_jpg.rf.663753b94384b05aa9d96735de0cddb1.jpg', '/content/hardhat_test_images/005808_jpg.rf.a362aa82fd76c4375b4caed2a1b2e3d8.jpg', '/content/hardhat_test_images/005810_jpg.rf.d95da55ceca4b57b13dafd02ab65b61b.jpg', '/content/hardhat_test_images/005811_jpg.rf.0a8accf9ff2e859ab9fa67b29bdc61f8.jpg', '/content/hardhat_test_images/005812_jpg.rf.9e158f8976451feffd96a1c90ddf2a07.jpg', '/content/hardhat_test_images/005824_jpg.rf.aad29450a8b43ae73a2546a0054f468d.jpg', '/content/hardhat_test_images/005830_jpg.rf.37187bf36f944ffe937799811d0457a9.jpg', '/content/hardhat_test_images/005835_jpg.rf.426b6132e5e13cdf58624a349fcf5046.jpg', '/content/hardhat_test_images/005847_jpg.rf.734fd658b41cc2decb3e76f91f29055a.jpg', '/content/hardhat_test_images/005848_jpg.rf.ad9b514ce11ddc0d1324147c6b2e65c5.jpg', '/content/hardhat_test_images/005849_jpg.rf.85c3ed66e23f81cc542b316f6530132c.jpg', '/content/hardhat_test_images/005857_jpg.rf.ec016647a5d1ac9d29c9ee67ce874573.jpg', '/content/hardhat_test_images/005863_jpg.rf.81c69134d471bd814a9cd7464d609a4a.jpg', '/content/hardhat_test_images/005869_jpg.rf.f357b5e961033807962c85c696f11963.jpg', '/content/hardhat_test_images/005870_jpg.rf.6638e005f5e5791b54babcf25af7f2ba.jpg', '/content/hardhat_test_images/005875_jpg.rf.9b7ba2ace053d0ff071812fd00c12f66.jpg', '/content/hardhat_test_images/005898_jpg.rf.84f5c103ed21a24f11a1a9dbe13256dd.jpg', '/content/hardhat_test_images/005899_jpg.rf.8a45e787f211ecc53242e3ff21e4c848.jpg', '/content/hardhat_test_images/005907_jpg.rf.1e95541aeb5a8a6e618b4cbee7271233.jpg', '/content/hardhat_test_images/005956_jpg.rf.f1b441b924cc544cc1a8f33772508839.jpg', '/content/hardhat_test_images/005957_jpg.rf.2d6f45f654ce2c96872e72e3515298cb.jpg', '/content/hardhat_test_images/005958_jpg.rf.e5193d76f92f331130a1a62c57de7970.jpg', '/content/hardhat_test_images/005971_jpg.rf.dc5a9ac743bf8cd4b6303a48c7989255.jpg', '/content/hardhat_test_images/005972_jpg.rf.3c99d419d8bc15179519e6c4f701c37a.jpg', '/content/hardhat_test_images/005986_jpg.rf.b131cdf3de6e3a88164ba2724193fbfa.jpg', '/content/hardhat_test_images/005989_jpg.rf.b586c546c8ab1b496d7d5c7096f3f00d.jpg', '/content/hardhat_test_images/005990_jpg.rf.077c29af00a0ccf8f3ec43b68c3fd78a.jpg', '/content/hardhat_test_images/006000_jpg.rf.4f3bb32192ac663072de7dec2e9271fd.jpg', '/content/hardhat_test_images/006008_jpg.rf.a04dff2f01978d65f35c7e8913f06442.jpg', '/content/hardhat_test_images/006009_jpg.rf.6be50b25a2dfb8cdbb3877004dbbbe6c.jpg', '/content/hardhat_test_images/006012_jpg.rf.b91c4d9c6eddd59ea2bfa7598899d168.jpg', '/content/hardhat_test_images/006013_jpg.rf.046a20c3d31383dd7d86094a2562224e.jpg', '/content/hardhat_test_images/006018_jpg.rf.5b1c47127de72073a7773d17dfe87640.jpg', '/content/hardhat_test_images/006026_jpg.rf.0675a5b9d915727461d12fc644c03d5c.jpg', '/content/hardhat_test_images/006028_jpg.rf.47eea583d98b4f259dc44ededd303c46.jpg', '/content/hardhat_test_images/006037_jpg.rf.5fb0a105710524884dd6db0d5ddf257b.jpg', '/content/hardhat_test_images/006039_jpg.rf.79c08b082c3eb38b424b287970d81774.jpg', '/content/hardhat_test_images/006042_jpg.rf.ba9f28d93c57a0f3576377c3ee431fd2.jpg', '/content/hardhat_test_images/006058_jpg.rf.eeb6d33c816ad6cf96c17cfd7277ebf5.jpg', '/content/hardhat_test_images/006061_jpg.rf.41fa462aab6362818bc18d001eb75fb7.jpg', '/content/hardhat_test_images/006062_jpg.rf.c4cbdec3016cbf1cf07c79f93953fafc.jpg', '/content/hardhat_test_images/006065_jpg.rf.da9c363bbbf635081d842f77e21e8d95.jpg', '/content/hardhat_test_images/006069_jpg.rf.599431db6cd915a97cb70aac768dccd2.jpg', '/content/hardhat_test_images/006073_jpg.rf.da448032f15e4ed848fa4a129a9a4240.jpg', '/content/hardhat_test_images/006083_jpg.rf.614204d9dc0726ddf1bba929b91d5280.jpg', '/content/hardhat_test_images/006089_jpg.rf.97557bd7f46ac9e7ff2617352bb66409.jpg', '/content/hardhat_test_images/006090_jpg.rf.e51e7ee2568c151bc49d6149ebfcf7b5.jpg', '/content/hardhat_test_images/006115_jpg.rf.e8c80ed3c1d21ac40f8091745fc309a2.jpg', '/content/hardhat_test_images/006117_jpg.rf.c872386bfab876e6afb3e384f5ea0780.jpg', '/content/hardhat_test_images/006143_jpg.rf.ecfe182ec5c8224d9a46ec3ccd866e75.jpg', '/content/hardhat_test_images/006144_jpg.rf.076ce2cf1f2d78d196f61bedba3ebd5a.jpg', '/content/hardhat_test_images/006145_jpg.rf.b675cd8a262c423209407d22ec73564e.jpg', '/content/hardhat_test_images/006149_jpg.rf.8c5929d16c8c89301ee503e1b4be384a.jpg', '/content/hardhat_test_images/006153_jpg.rf.351de1577fd9c2fc91cc4a121dfd8627.jpg', '/content/hardhat_test_images/006154_jpg.rf.5b5307a3220194c6e960302d092fdc57.jpg', '/content/hardhat_test_images/006157_jpg.rf.b5dee8d3507943b38c43025638e56390.jpg', '/content/hardhat_test_images/006162_jpg.rf.c2dafd2447e89aa47c1f6379bd867498.jpg', '/content/hardhat_test_images/006170_jpg.rf.fd2077959d3ae7201f3ba8c4784b8b18.jpg', '/content/hardhat_test_images/006171_jpg.rf.37df6b66405ac88c9fa287f39f3a4845.jpg', '/content/hardhat_test_images/006179_jpg.rf.d0cfe68d66bf9e97618e1a019ac02102.jpg', '/content/hardhat_test_images/006180_jpg.rf.84c902d12dceb3fcab134ea2eada2a94.jpg', '/content/hardhat_test_images/006183_jpg.rf.16b6e368471526049717d2ccdf1d75aa.jpg', '/content/hardhat_test_images/006186_jpg.rf.de7b649bd962967b4a1b88611d7b9311.jpg', '/content/hardhat_test_images/006189_jpg.rf.11016e768285c5309a3046d0e3de1f01.jpg', '/content/hardhat_test_images/006191_jpg.rf.1460973fd8da7ec55c6ac35bd3595be5.jpg', '/content/hardhat_test_images/006192_jpg.rf.f33fc34b83c80880d932703de99e84c9.jpg', '/content/hardhat_test_images/006195_jpg.rf.e741c5cdc2dadfbd8598e8e8fb81bfdf.jpg', '/content/hardhat_test_images/006197_jpg.rf.1ee6f1e8be1d1e4fe9390fc13da30614.jpg', '/content/hardhat_test_images/006206_jpg.rf.4d9ffda4472c2aa6968067c9c01520d4.jpg', '/content/hardhat_test_images/006212_jpg.rf.edd8338ef79ae380a9aa1959d4f3fcb2.jpg', '/content/hardhat_test_images/006213_jpg.rf.081c16ceec86e4fb37b56d120e1bb18c.jpg', '/content/hardhat_test_images/006216_jpg.rf.07a2588862aa10a7e068245fec3932e0.jpg', '/content/hardhat_test_images/006221_jpg.rf.d69a61ed947e5d31af4a3d408ca5f954.jpg', '/content/hardhat_test_images/006224_jpg.rf.fd2a2fd8d970b59428da3dc23d2999d6.jpg', '/content/hardhat_test_images/006225_jpg.rf.f0d282bc8a5633bfa358c45a262a4561.jpg', '/content/hardhat_test_images/006244_jpg.rf.b9ebe4b41b87dbc91effc8fc81f42bb5.jpg', '/content/hardhat_test_images/006250_jpg.rf.8ee9f0298da28778b0a6e42fbabb9b7f.jpg', '/content/hardhat_test_images/006254_jpg.rf.487671a4234c32e8cae3fcf3582724e1.jpg', '/content/hardhat_test_images/006255_jpg.rf.66d29aca05a0c6d58af1266b3d535adc.jpg', '/content/hardhat_test_images/006258_jpg.rf.bfd622d7ca223055343686607d33d4cd.jpg', '/content/hardhat_test_images/006265_jpg.rf.a4ade5df60f98e9c8394fce2743e19fd.jpg', '/content/hardhat_test_images/006267_jpg.rf.2e1101319e827b3d5beb7911bbb886aa.jpg', '/content/hardhat_test_images/006271_jpg.rf.26152bd99f01ddbe18d6f27b8bc991c4.jpg', '/content/hardhat_test_images/006272_jpg.rf.ee262969853b294f7fe3515aaea1381f.jpg', '/content/hardhat_test_images/006278_jpg.rf.7f686469b6a2af4e2433df43e7c741a6.jpg', '/content/hardhat_test_images/006300_jpg.rf.cc6cda7b0c3f86b01880e2572b6b9191.jpg', '/content/hardhat_test_images/006301_jpg.rf.63e271e31593ab069c8e52caf3ade566.jpg', '/content/hardhat_test_images/006307_jpg.rf.c4bf0aaa68b9738cdd0f758be0a92c48.jpg', '/content/hardhat_test_images/006316_jpg.rf.6ac45dd2feb8a9ac9d14eed92f9f4253.jpg', '/content/hardhat_test_images/006317_jpg.rf.c51bbf75169574234e6638e2dfd31515.jpg', '/content/hardhat_test_images/006322_jpg.rf.f9ccf52f637fffbfb9d60401674830f3.jpg', '/content/hardhat_test_images/006327_jpg.rf.25bc0be173ff31e9c2b496bf3dee178a.jpg', '/content/hardhat_test_images/006329_jpg.rf.61f08d9a6e46c18d6636de8dabe36ccb.jpg', '/content/hardhat_test_images/006331_jpg.rf.8f648d5ce859b0e299b4ee9fbd63da21.jpg', '/content/hardhat_test_images/006336_jpg.rf.aa6e30cf27ecbf45e21e1e00f435c454.jpg', '/content/hardhat_test_images/006344_jpg.rf.a5e692359e2f4105af75c4a293e9ece1.jpg', '/content/hardhat_test_images/006349_jpg.rf.8815f6cc57f04f0befa105da8044eb01.jpg', '/content/hardhat_test_images/006361_jpg.rf.136026d4acd49c79c0a54293314f5447.jpg', '/content/hardhat_test_images/006362_jpg.rf.f3201bf03326631e5f1977be2592983d.jpg', '/content/hardhat_test_images/006364_jpg.rf.2c6206efd28d56d050508ddbff9232de.jpg', '/content/hardhat_test_images/006373_jpg.rf.275220399fc2237bc32fc90d4ea93386.jpg', '/content/hardhat_test_images/006384_jpg.rf.8fecabcb729d28f5429e3d1bbc4f8751.jpg', '/content/hardhat_test_images/006396_jpg.rf.b9315486e82c5f132435ccb78fc40e75.jpg', '/content/hardhat_test_images/006398_jpg.rf.d76821f14f5b307f7e188a879a2d992a.jpg', '/content/hardhat_test_images/006410_jpg.rf.bc6eb1c50dddd7b24da72dc53c34714a.jpg', '/content/hardhat_test_images/006411_jpg.rf.0130d0a1a0788d95a6ead90f0dfd015e.jpg', '/content/hardhat_test_images/006420_jpg.rf.d8d82a7d07a0d5b824a4dee0ad1da943.jpg', '/content/hardhat_test_images/006424_jpg.rf.f43e4ec5c2cb3bd1c484aba759afaa4c.jpg', '/content/hardhat_test_images/006425_jpg.rf.642c6eb18ab7e7d2e7e2df94448e14c2.jpg', '/content/hardhat_test_images/006428_jpg.rf.8b5533ff9d7a126081622a8feadbc5d5.jpg', '/content/hardhat_test_images/006435_jpg.rf.23f1c47d018c3006810631482e497b89.jpg', '/content/hardhat_test_images/006442_jpg.rf.30fd4fe36e6658f46a5531db49ccaf4f.jpg', '/content/hardhat_test_images/006458_jpg.rf.e72eb8d46b94c6bccf9bfe3a488fb12e.jpg', '/content/hardhat_test_images/006459_jpg.rf.a4266180957dc4b987a3bb8c4fea4541.jpg', '/content/hardhat_test_images/006466_jpg.rf.a02f93ef70a63e7699e6f2596588ff7e.jpg', '/content/hardhat_test_images/006467_jpg.rf.91487fc86989217a96869c76cc752a19.jpg', '/content/hardhat_test_images/006470_jpg.rf.94ffb679d4d722b60902503c10bda875.jpg', '/content/hardhat_test_images/006471_jpg.rf.9e9e9eb41d551009a16de8beb28c7e0d.jpg', '/content/hardhat_test_images/006473_jpg.rf.adfc8da063ccc33fdaf8ee38788aadd1.jpg', '/content/hardhat_test_images/006476_jpg.rf.94ca8e3d151aa9d006295ffb38f8eb3e.jpg', '/content/hardhat_test_images/006482_jpg.rf.229baa2dcf8be5b07fb76db1879795ef.jpg', '/content/hardhat_test_images/006494_jpg.rf.8f8e23de33f6bfc37c4fa97d2c9094bf.jpg', '/content/hardhat_test_images/006500_jpg.rf.78cf1031a6536e16cd1aea4dd0d8dc4d.jpg', '/content/hardhat_test_images/006504_jpg.rf.74e068fa2feb6d971969fdececcd3507.jpg', '/content/hardhat_test_images/006513_jpg.rf.80633cc45bb22de2fc74850672c96267.jpg', '/content/hardhat_test_images/006520_jpg.rf.43e34b52aec8463d4da415f95fa116e6.jpg', '/content/hardhat_test_images/006523_jpg.rf.a4cfdf27d730b8e74cc60b643a0d7e88.jpg', '/content/hardhat_test_images/006525_jpg.rf.4c85a5b6ca424eace302a113cfec5f46.jpg', '/content/hardhat_test_images/006534_jpg.rf.991e1bc7c6933c66bb8a6d9afdb9781e.jpg', '/content/hardhat_test_images/006542_jpg.rf.81c27fb5e3974480c0e580cf03c78754.jpg', '/content/hardhat_test_images/006548_jpg.rf.e951e271f17378446699ac44ef9f95e5.jpg', '/content/hardhat_test_images/006570_jpg.rf.e62d241ced80784c332138b380a8dabb.jpg', '/content/hardhat_test_images/006575_jpg.rf.b3e85a8cf7c79b1c90c108b39a163241.jpg', '/content/hardhat_test_images/006577_jpg.rf.eb2d5bbf5b2d143fdc8000213c40ff61.jpg', '/content/hardhat_test_images/006594_jpg.rf.0649e8447424300f131dd3e3d3ea24cf.jpg', '/content/hardhat_test_images/006597_jpg.rf.ad701d4832539eb18d7a95ad146dd76b.jpg', '/content/hardhat_test_images/006607_jpg.rf.ea82572d0b67a40add1aa7763035cc40.jpg', '/content/hardhat_test_images/006614_jpg.rf.5398dfa85cb985ffdb62225d1be9e5ea.jpg', '/content/hardhat_test_images/006619_jpg.rf.2b4571557ffe5c6d93e348dc57f85c62.jpg', '/content/hardhat_test_images/006629_jpg.rf.8ff3d5c583d0c009e65a4b1cf9d2063b.jpg', '/content/hardhat_test_images/006632_jpg.rf.8e371a00434e96a2e39d1eff821d4c9e.jpg', '/content/hardhat_test_images/006633_jpg.rf.ac9700ba1e8f77cb0128de94eac11c70.jpg', '/content/hardhat_test_images/006637_jpg.rf.012e99d80844459254e586c7aa45adac.jpg', '/content/hardhat_test_images/006639_jpg.rf.e18c47e2296d33871ca2a3fdf0d5ccd5.jpg', '/content/hardhat_test_images/006643_jpg.rf.17e657e845d54370ccf3d5a48a461813.jpg', '/content/hardhat_test_images/006659_jpg.rf.dfd208678e625b3bced901b51e347192.jpg', '/content/hardhat_test_images/006662_jpg.rf.2cd341b4ec7e24c9370da8714f05a06f.jpg', '/content/hardhat_test_images/006669_jpg.rf.a2def9ae6f4d6c935f9bbf22d4c55dd4.jpg', '/content/hardhat_test_images/006671_jpg.rf.2a078403b2db8b2c40c12fcf7b607c27.jpg', '/content/hardhat_test_images/006674_jpg.rf.19d62ff37a30b940bc78b461f4389533.jpg', '/content/hardhat_test_images/006687_jpg.rf.d479034b72af8476ec65ca354843ab91.jpg', '/content/hardhat_test_images/006690_jpg.rf.5c8a91a7057f167e2ed74ae625961b29.jpg', '/content/hardhat_test_images/006698_jpg.rf.a5345a3b73849ad146d512810158d783.jpg', '/content/hardhat_test_images/006704_jpg.rf.4066997e688ef93a79b3d36a42cfe8ac.jpg', '/content/hardhat_test_images/006705_jpg.rf.86c014d12ceb9e79528827a7a0f5344a.jpg', '/content/hardhat_test_images/006710_jpg.rf.0f33d5f6056de9586a6a13c76b3dfc03.jpg', '/content/hardhat_test_images/006716_jpg.rf.82df0775b5b239dc75e190b5ee6fb24a.jpg', '/content/hardhat_test_images/006727_jpg.rf.e49f2e0d7d046bca5f8192e61e35ce18.jpg', '/content/hardhat_test_images/006754_jpg.rf.e2a6640bf1d8480fbe1601fde8d8dc31.jpg', '/content/hardhat_test_images/006765_jpg.rf.6d350b64a50ae0b46e091886b6df9db9.jpg', '/content/hardhat_test_images/006767_jpg.rf.7d1348b5eddc4e2c469272ddfca31c88.jpg', '/content/hardhat_test_images/006776_jpg.rf.631276325cd7ce81bf9b507810493695.jpg', '/content/hardhat_test_images/006777_jpg.rf.9f2081eff0af9dc58a321ab33aee740b.jpg', '/content/hardhat_test_images/006779_jpg.rf.ab314d22d3d5a07102816d10691256bc.jpg', '/content/hardhat_test_images/006781_jpg.rf.f2b70b8a7af40635ade1d797fdc42c15.jpg', '/content/hardhat_test_images/006782_jpg.rf.02eb7d9a12ae654f6633c105eaaca0cc.jpg', '/content/hardhat_test_images/006788_jpg.rf.f0f6632f2bb959237e56ae8337b915ae.jpg', '/content/hardhat_test_images/006790_jpg.rf.cd6d3c19da633b24a06a600c39b6250f.jpg', '/content/hardhat_test_images/006795_jpg.rf.8064999eecc78b7dd963399d3f3cd583.jpg', '/content/hardhat_test_images/006809_jpg.rf.94212ce392dd061b623ea0d4823e0088.jpg', '/content/hardhat_test_images/006815_jpg.rf.5dff0abff662071d7ffc932c02ddd523.jpg', '/content/hardhat_test_images/006821_jpg.rf.998886a5e56065fbced66d0f7a80b4b2.jpg', '/content/hardhat_test_images/006822_jpg.rf.b17466d116368a4c8aa8846c59ce47b1.jpg', '/content/hardhat_test_images/006829_jpg.rf.078a3d279506b1645a485cf7c07f5381.jpg', '/content/hardhat_test_images/006832_jpg.rf.adad68dac7a53ecc74c17fd12373fca7.jpg', '/content/hardhat_test_images/006853_jpg.rf.2f8523f9605ed5a9f454fd64f9ffacde.jpg', '/content/hardhat_test_images/006859_jpg.rf.c739862d7bf09715bae776afe016a722.jpg', '/content/hardhat_test_images/006869_jpg.rf.f8ce4adb0656ff4ca263b91845f49923.jpg', '/content/hardhat_test_images/006870_jpg.rf.81334f52ad19eaa6a7ff3bec7fef01d0.jpg', '/content/hardhat_test_images/006878_jpg.rf.76e577494ab2204f80e02984baed51a7.jpg', '/content/hardhat_test_images/006897_jpg.rf.c208ff14a5a2fc31b1b20797a6e67e4f.jpg', '/content/hardhat_test_images/006898_jpg.rf.96faf6afd78a5880f973d9fd9b3097c4.jpg', '/content/hardhat_test_images/006899_jpg.rf.611ead1f9f5cbeee63d7bef584e7677c.jpg', '/content/hardhat_test_images/006914_jpg.rf.f1d1d5e08f0af30ea5ec7a4afe608fdf.jpg', '/content/hardhat_test_images/006915_jpg.rf.0cd73858a9eecb7a121d96bbbfa9698b.jpg', '/content/hardhat_test_images/006934_jpg.rf.7f1d1bef347b8567a5caa0b899477740.jpg', '/content/hardhat_test_images/006939_jpg.rf.b781b1e71f47c05f6c3e0ed842896a08.jpg', '/content/hardhat_test_images/006964_jpg.rf.685c4f73c4410931e9c15f55f5ec9165.jpg', '/content/hardhat_test_images/006981_jpg.rf.d61136fa9b11d75e45490dea1800eb81.jpg', '/content/hardhat_test_images/006984_jpg.rf.709c61978da32a98e9b0a447f76465d8.jpg', '/content/hardhat_test_images/006986_jpg.rf.de1d122bab900be651587ea3e88a5906.jpg', '/content/hardhat_test_images/006991_jpg.rf.e4388e5673b305a1c8cb116e2b177e26.jpg', '/content/hardhat_test_images/006992_jpg.rf.9618d35aaf4dacb261998c6327f37d61.jpg', '/content/hardhat_test_images/006994_jpg.rf.c13ac0a9af65085b4ee85dbe3ad154c9.jpg', '/content/hardhat_test_images/006996_jpg.rf.eb55eebfe3abd31084c1ba82d9492515.jpg', '/content/hardhat_test_images/006997_jpg.rf.2c668355190de4dad5e1d80d0b76e60f.jpg', '/content/hardhat_test_images/007001_jpg.rf.7f69c63ba90227b353fbceab05de0d29.jpg', '/content/hardhat_test_images/007007_jpg.rf.4dea58330eac57952b8f56528320121d.jpg', '/content/hardhat_test_images/007019_jpg.rf.80b23461101ec8d1547df8cddc5f2d55.jpg', '/content/hardhat_test_images/007020_jpg.rf.2ad9227fcac462c9c52a5fb9138bd671.jpg', '/content/hardhat_test_images/007027_jpg.rf.ab38faecd47f0c844323fc9f0ec16f5f.jpg', '/content/hardhat_test_images/007030_jpg.rf.bb30bbf482e03ddf9003204b4c92d5b8.jpg', '/content/hardhat_test_images/007032_jpg.rf.564e7b38f6e3462502d53b550d0af762.jpg', '/content/hardhat_test_images/007037_jpg.rf.6ae5db65009651dd60256902caf059b2.jpg', '/content/hardhat_test_images/007039_jpg.rf.b73b2016c832ecef8893aeb1be781197.jpg', '/content/hardhat_test_images/007056_jpg.rf.7c1a3682380bc6e8de40b760fafd7032.jpg', '/content/hardhat_test_images/007063_jpg.rf.0d7faa35f8635ed83d6704bb1e1acf4b.jpg']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1T17RKSB7WeO","executionInfo":{"status":"ok","timestamp":1611337725356,"user_tz":-60,"elapsed":355228,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"a993e4e0-e186-4d5e-cf6e-a9c74b191838"},"source":["from tqdm import tqdm\r\n","\r\n","for image_path in TEST_IMAGE_PATHS[:100]:\r\n","    image_np = load_image_into_numpy_array(image_path)\r\n","\r\n","    # Things to try:\r\n","    # Flip horizontally\r\n","    # image_np = np.fliplr(image_np).copy()\r\n","\r\n","    # Convert image to grayscale\r\n","    # image_np = np.tile(\r\n","    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\r\n","\r\n","    input_tensor = tf.convert_to_tensor(\r\n","        np.expand_dims(image_np, 0), dtype=tf.float32)\r\n","    detections, predictions_dict, shapes = detect_fn(input_tensor)\r\n","\r\n","    label_id_offset = 1\r\n","    image_np_with_detections = image_np.copy()\r\n","\r\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\r\n","          image_np_with_detections,\r\n","          detections['detection_boxes'][0].numpy(),\r\n","          (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\r\n","          detections['detection_scores'][0].numpy(),\r\n","          category_index,\r\n","          use_normalized_coordinates=True,\r\n","          max_boxes_to_draw=200,\r\n","          min_score_thresh=.5,\r\n","          agnostic_mode=False,\r\n","          line_thickness=4\r\n","    )\r\n","\r\n","    plt.figure(figsize=(12,8))\r\n","    plt.imshow(image_np_with_detections)\r\n","    # plt.show()\r\n","    save_name = '.'.join(image_path.split('.')[:-1]) + '_prediction.jpg'\r\n","    plt.savefig(save_name, bbox_inches='tight')\r\n","    plt.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 6 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 6 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 7 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 7 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 9 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 9 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 14 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 14 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 15 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 15 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 16 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 16 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 17 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 17 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 14 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 14 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 15 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 15 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 16 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 16 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 17 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 17 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 14 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 14 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 14 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 14 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 12 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 13 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 11 calls to <function get_model_detection_function.<locals>.detect_fn at 0x7fbb902132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EDOtDZ8p8Frx","executionInfo":{"status":"ok","timestamp":1611336742259,"user_tz":-60,"elapsed":286850,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"ed67e0bf-2ea9-47c3-a8c2-f8d7fb6363d9"},"source":["#take a look at the kind of GPU we have\r\n","!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fri Jan 22 17:32:22 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    39W / 300W |   2527MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"F4IaWA6v8L2x","executionInfo":{"status":"ok","timestamp":1611337730621,"user_tz":-60,"elapsed":5233,"user":{"displayName":"Bertalan Kovacs","photoUrl":"","userId":"15941432609724417475"}},"outputId":"19269f51-24d9-462f-e1f3-87a1e9a68b8e"},"source":["# Download files and images\r\n","\r\n","from google.colab import files\r\n","\r\n","!mkdir /content/result_images\r\n","!cp /content/hardhat_test_images/*_prediction.jpg /content/result_images/\r\n","!cp /content/scratch_test_images/*_prediction.jpg /content/result_images/\r\n","\r\n","\r\n","!zip -r /content/efficientdet.zip /content/fine_tuned_model/ /content/result_images\r\n","files.download(\"/content/efficientdet.zip\")\r\n","\r\n","\r\n","# !zip -r /content/efficientdet_img_results.zip /content/result_images\r\n","# files.download(\"/content/efficientdet_img_results.zip\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/content/result_images’: File exists\n","cp: cannot stat '/content/scratch_test_images/*_prediction.jpg': No such file or directory\n","  adding: content/fine_tuned_model/ (stored 0%)\n","  adding: content/fine_tuned_model/checkpoint/ (stored 0%)\n","  adding: content/fine_tuned_model/checkpoint/ckpt-0.index (deflated 80%)\n","  adding: content/fine_tuned_model/checkpoint/checkpoint (deflated 40%)\n","  adding: content/fine_tuned_model/checkpoint/ckpt-0.data-00000-of-00001 (deflated 36%)\n","  adding: content/fine_tuned_model/pipeline.config (deflated 68%)\n","  adding: content/fine_tuned_model/saved_model/ (stored 0%)\n","  adding: content/fine_tuned_model/saved_model/assets/ (stored 0%)\n","  adding: content/fine_tuned_model/saved_model/saved_model.pb (deflated 93%)\n","  adding: content/fine_tuned_model/saved_model/variables/ (stored 0%)\n","  adding: content/fine_tuned_model/saved_model/variables/variables.index (deflated 77%)\n","  adding: content/fine_tuned_model/saved_model/variables/variables.data-00000-of-00001 (deflated 36%)\n","  adding: content/result_images/ (stored 0%)\n","  adding: content/result_images/000264_jpg.rf.ce0a76b59f6a190a8fe6c821b6f10266_prediction.jpg (deflated 2%)\n","  adding: content/result_images/000121_jpg.rf.458787b3ee0f603b4fb7ee8442ca893f_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000312_jpg.rf.45857a776fb7622eee03f6a089f33cfb_prediction.jpg (deflated 0%)\n","  adding: content/result_images/000576_jpg.rf.fec2b59b042e1abf78005dc2a95ce321_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000537_jpg.rf.91820fee0461c91e85a3e2988f3f2ab1_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000471_jpg.rf.8273d5aa5abaf748321a6692121a05bb_prediction.jpg (deflated 3%)\n","  adding: content/result_images/000616_jpg.rf.ecd79fc298d2f4f551c849c8bf3479b7_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000136_jpg.rf.bd59a3b1744cd77a24a66294d9cc0ee5_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000643_jpg.rf.d4c1805b71003f073db4ede8b0995754_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000499_jpg.rf.a108113496b32a3e12aeed2f51a7f9bc_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000384_jpg.rf.d00312d5626c4585669f89d0b2a51571_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000060_jpg.rf.c77953cd46240aa6676f74bbd2cef120_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000655_jpg.rf.c427b115827e86cada50f01d27f1c074_prediction.jpg (deflated 2%)\n","  adding: content/result_images/000238_jpg.rf.8bc7f4c51673e11fd607e6d56963acfd_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000266_jpg.rf.14a197fb433df75c609cf6fd3e4f75c8_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000141_jpg.rf.a0083a17eefa1c9b49f5326d7a0ff987_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000319_jpg.rf.f201333fd98564d76504d722a8fbb21b_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000547_jpg.rf.bcb8c677f52eb2fab2bf8530412b28e6_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000437_jpg.rf.4273e362691052615b4fa015f73b3866_prediction.jpg (deflated 0%)\n","  adding: content/result_images/000272_jpg.rf.259242e59767e664c4e6d63c2e0c92d7_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000358_jpg.rf.28808a9f7792bcec6621535b75826490_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000666_jpg.rf.ebf8f880394bd3d249e670bb18de3fab_prediction.jpg (deflated 84%)\n","  adding: content/result_images/000527_jpg.rf.432600b32c78a4d8b23eb0cc4c2bb3e2_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000515_jpg.rf.29fed21f400f2443de8d0685a9bf3d47_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000277_jpg.rf.9c4232e077ee8e6a8da932abfa46b6e8_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000144_jpg.rf.e0e417be34fb7d743870d8d3ca4cd0a3_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000076_jpg.rf.6e17a0977fc8ac32c1559e1782d550cf_prediction.jpg (deflated 3%)\n","  adding: content/result_images/000648_jpg.rf.975d66d309b8bc703d683a7795c6502c_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000304_jpg.rf.b43923673e0b7f4148ca29369557aa42_prediction.jpg (deflated 2%)\n","  adding: content/result_images/000671_jpg.rf.dbb49056b6060c79b92d6787102cd5b0_prediction.jpg (deflated 84%)\n","  adding: content/result_images/000163_jpg.rf.b98f656eee2b2ab33bd5d3c7f7b0c8e1_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000296_jpg.rf.35453a8f6d2adf827e47977c5a4e3022_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000394_jpg.rf.962eea1092d7954ceece804bee54d422_prediction.jpg (deflated 2%)\n","  adding: content/result_images/000388_jpg.rf.89f7877f0cc4a557c9b404fb7e78c11f_prediction.jpg (deflated 3%)\n","  adding: content/result_images/000644_jpg.rf.549944847b61ddcd29461e6eff390d0a_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000130_jpg.rf.d7f4949abf806c22b4bb89e9289f607e_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000200_jpg.rf.63a6cd35bae2e4b1ce4b32bf4b5952d0_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000516_jpg.rf.d5ac13eaaee52891fa2170e5f0b7e410_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000560_jpg.rf.0c7bf997f0ccb3aa4666aae7bacd15e1_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000184_jpg.rf.53563e27c8b7aae0c0e865b365674223_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000152_jpg.rf.f9c2a41a8714cffa2a600796c692024a_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000497_jpg.rf.75095f7dd10081b8427dd7026589521f_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000038_jpg.rf.ee7b22dab5abf8252225253d5b7b50cf_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000317_jpg.rf.826ed4f7df3397186f9c91f4985fa7ab_prediction.jpg (deflated 3%)\n","  adding: content/result_images/000345_jpg.rf.b5c604f5c9cfa9ee56cac049ba5e565e_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000561_jpg.rf.2e13c06528475046ce4ef776f15ecb8e_prediction.jpg (deflated 3%)\n","  adding: content/result_images/000120_jpg.rf.8ae3d79f4828c94ff29ee01c03f92303_prediction.jpg (deflated 0%)\n","  adding: content/result_images/000151_jpg.rf.8f93d9e83e73fe3601ecdc1ca55e9960_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000007_jpg.rf.8e98fb789dfc011fb526ce49daf8da31_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000052_jpg.rf.629cc4e04ec1578c1e813c84be098fd0_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000251_jpg.rf.b0221c10f608c75457f51b3f7c065f43_prediction.jpg (deflated 2%)\n","  adding: content/result_images/000285_jpg.rf.2b30c3c11d90e195e581953e55c68197_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000464_jpg.rf.dc0e29f72f520e29744650b76c26d35c_prediction.jpg (deflated 2%)\n","  adding: content/result_images/000099_jpg.rf.73261a5bc27bf65613d5c6d1596daec5_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000202_jpg.rf.afb187a78cf40a978f849908794156de_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000045_jpg.rf.f8429e05f94a05b82b3bf7256063c313_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000112_jpg.rf.0b9c58cb3d0bb12c302dd282143a4d9f_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000645_jpg.rf.c3a17316f01510e92f685d5e1b8e2d4e_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000584_jpg.rf.e961c0c2de411c95422e0ef01c01c46f_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000260_jpg.rf.feee3b4e9a138d59f4ede18ce43deecc_prediction.jpg (deflated 2%)\n","  adding: content/result_images/000654_jpg.rf.a1eadb321a0bfeddc2d61164c2c0f01d_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000270_jpg.rf.28434781eaeebf0feab466eed579e8d3_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000024_jpg.rf.f4dbede31bcaa30e4264e464b2d32266_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000580_jpg.rf.122ae2447b8e1a15b4997ae72778328c_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000479_jpg.rf.dacd5020315d9afe55e3abd6e7804e64_prediction.jpg (deflated 5%)\n","  adding: content/result_images/000183_jpg.rf.996e8b130fb1d4433c2aca837b43bf5e_prediction.jpg (deflated 4%)\n","  adding: content/result_images/000072_jpg.rf.a6086d0ee280ad45b27f1dfb38f08d1f_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000244_jpg.rf.e3e422f1777fb7026147401932c5eba7_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000035_jpg.rf.a3fd81d1d38c11263dc0f6670b50deda_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000494_jpg.rf.89bfa23e4f4066ea71951c488d3678bf_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000306_jpg.rf.3cbd4ca0b74f4bb4def03d11075eb9ab_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000221_jpg.rf.510d37d3fb860fd638da5fdb3197d29f_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000620_jpg.rf.f33000a871ce6e79e9525be731290bc3_prediction.jpg (deflated 0%)\n","  adding: content/result_images/000571_jpg.rf.f20cbcf888f37571b6d3c102b5355f32_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000185_jpg.rf.a07c7675c7e6745ad161cedd33de59e6_prediction.jpg (deflated 8%)\n","  adding: content/result_images/000204_jpg.rf.16540caa5a7c26cb16795dc8f579a74f_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000165_jpg.rf.a3607cf9d405d70c75bebf131a5afbf7_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000642_jpg.rf.cc772ca97cdfe9b83b116aa1f2328dd5_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000604_jpg.rf.44abfc42cc2ec03f516d56f966d6ff0c_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000621_jpg.rf.eff847cfb8481bcd8653c6a8c2dbc5e0_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000665_jpg.rf.8869dea9f3417573a081fd86831b8ceb_prediction.jpg (deflated 3%)\n","  adding: content/result_images/000460_jpg.rf.58b395d4016f4dcaeac22740f83ea472_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000192_jpg.rf.f14772324b319afb0f69861a1c60b9c0_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000102_jpg.rf.a547296ebcc407e4c961aa32c85d99a0_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000472_jpg.rf.199888712b93aa07dcbe307f894f9386_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000577_jpg.rf.e3e8f7b9a05d729006ddda08e233a422_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000198_jpg.rf.162703ae30d35d97c6e90eae60cd513e_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000069_jpg.rf.09b9ad6fbe4cdfbe1d38a7d7424868a5_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000488_jpg.rf.7b01af2b5256ce7e20dbb3456a158120_prediction.jpg (deflated 2%)\n","  adding: content/result_images/000298_jpg.rf.70acf50e281baa87c0ecbf416acde155_prediction.jpg (deflated 4%)\n","  adding: content/result_images/000485_jpg.rf.f4016bc0c2d35aeac985c2c0ddb3b81d_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000271_jpg.rf.f2ee82907a96bfbe523c94a41b57fc38_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000664_jpg.rf.12bf957101010a2a91548318813bf87c_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000557_jpg.rf.683f83292db0e1a7e9d8cfbfb2cb27c3_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000327_jpg.rf.5fe068181b6b727c3704a3a487af523e_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000611_jpg.rf.443b6c7c90929c5b4b6a3155b7feda03_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000318_jpg.rf.2f89db18fe6d594777afdb120c850586_prediction.jpg (deflated 2%)\n","  adding: content/result_images/000321_jpg.rf.fbb43949847ca2f1c05596f6a6ccb794_prediction.jpg (deflated 3%)\n","  adding: content/result_images/000570_jpg.rf.72acf6a516136a1e8b619d4dcf7e19d3_prediction.jpg (deflated 2%)\n","  adding: content/result_images/000316_jpg.rf.b11da1032cbaaee2d5e2ce05a291b1bf_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000417_jpg.rf.232170292dd4577e4c606a5defda193b_prediction.jpg (deflated 1%)\n","  adding: content/result_images/000349_jpg.rf.68743e4235a259df0df64d16629f4de1_prediction.jpg (deflated 1%)\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_1405c4c5-7078-413a-83bc-8687cb5d6325\", \"efficientdet.zip\", 41527533)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"K-1EBHYuIxqk"},"source":[""],"execution_count":null,"outputs":[]}]}